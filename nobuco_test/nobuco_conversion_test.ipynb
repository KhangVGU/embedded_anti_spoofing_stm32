{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM7hpto6Pqa7eb4wsaEomPX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhangVGU/embedded_anti_spoofing_stm32/blob/main/nobuco_test/nobuco_conversion_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the repository"
      ],
      "metadata": {
        "id": "Pr7NxK0sW9D2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfFmpgK0Wooz",
        "outputId": "60697430-10b9-4c24-a467-97ea90fed9dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'aasist'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 38 (delta 9), reused 3 (delta 3), pack-reused 16 (from 1)\u001b[K\n",
            "Receiving objects: 100% (38/38), 1.43 MiB | 5.07 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/clovaai/aasist.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install dependencies"
      ],
      "metadata": {
        "id": "XET-7SLAXYKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/aasist/\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA0wrck6XaWW",
        "outputId": "07f3dde5-48ee-4f01-f3ef-18a859c583be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/aasist\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Collecting torchcontrib (from -r requirements.txt (line 2))\n",
            "  Downloading torchcontrib-0.0.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->-r requirements.txt (line 4)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 4)) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torchcontrib\n",
            "  Building wheel for torchcontrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-py3-none-any.whl size=7516 sha256=52314c7a6faf92bb2e2121716314fe15d4474f3bfc090463b30eade63773b7fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/87/f6/b3c995670297d282da49c39ea210c39fc8089c27f453bc1c42\n",
            "Successfully built torchcontrib\n",
            "Installing collected packages: torchcontrib, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchcontrib-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download dataset"
      ],
      "metadata": {
        "id": "lpFrHbWIX6jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/aasist/\n",
        "!python ./download_dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuJ6gZw7X75M",
        "outputId": "346595e5-68ce-4371-b83c-fbed2eeb45f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7787040.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2924301.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9249366.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3442936.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7772915.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5569336.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7773607.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7813281.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9705954.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2427464.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1000273.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5263550.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1642109.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1339848.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9495857.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6668228.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8141252.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7272849.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5298518.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6840648.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5545259.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1269067.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9630978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1408187.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4369294.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2289990.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1384763.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6352635.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3433526.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4894348.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A9760674.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9770507.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6421520.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5066936.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A3109618.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9942993.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4977002.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9816956.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8166571.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8311281.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7347536.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3979386.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3334821.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4884718.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8547012.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A2217302.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5383935.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8140013.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2962131.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2934751.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3392516.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9437523.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3432767.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5167546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9927190.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9941346.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3624584.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7703856.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8725919.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1204557.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2708688.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5007875.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1477873.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5941898.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7305315.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7619790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3460847.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6381301.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9497493.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8901009.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4679632.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6061100.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8145641.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1152362.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3207170.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7988753.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4171593.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5474666.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6018920.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6056789.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3906721.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9928635.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3229022.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5850811.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4110080.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4681955.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4961586.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4012625.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4506690.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9340225.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9892843.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8944045.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7572321.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3729191.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3987573.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2458885.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8146981.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8024525.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7923943.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8575026.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4905278.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4284986.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9474907.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8753673.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3614077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5180192.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7853923.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4087064.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3643905.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8078748.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3759769.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8876743.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4940234.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2726735.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6298757.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9793939.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2247680.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9005729.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6126706.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9100649.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2119485.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8949362.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9283166.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7005655.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3408363.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8469367.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4362067.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9013307.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9778072.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1401349.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2764546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3092056.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9761603.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5963455.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6018865.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8116366.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9014568.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5094749.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A8945198.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2356259.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1018706.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8563058.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3972876.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8909086.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6521357.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6319722.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8324120.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2825737.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1881464.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5922909.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4959445.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2598056.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1304770.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4708805.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3940907.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6957650.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9727960.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9163737.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6158949.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7447248.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8981919.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3408733.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6556790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7583621.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4021903.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8256487.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4408850.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4348875.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1152227.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8468825.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1644462.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5784488.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9948022.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8306401.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4039963.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2017203.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6327220.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8471757.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3001686.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7471680.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7008964.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4037584.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5873367.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5377734.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7787555.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9945610.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9217423.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9179290.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7256803.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3096015.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1419283.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5607090.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A3770777.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2073512.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1721250.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7478858.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3651892.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7131438.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7271623.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7692966.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7373086.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8588010.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9118629.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1169177.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7300951.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1253199.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5626667.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1378451.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7112358.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A7344985.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6361913.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8085284.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1300363.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7701187.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9015683.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8285449.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4442710.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2188268.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9206398.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8935413.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2198141.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7302346.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2405283.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8621157.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5847141.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9420823.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2524346.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8175561.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6478373.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5512044.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4458034.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9069371.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2879673.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2781269.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3597021.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2683136.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9517832.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3702042.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6184058.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4265643.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7359314.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6741948.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6738492.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1258556.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9200165.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3899176.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9548570.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8775468.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3586630.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9889833.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7121711.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6729779.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7855377.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3184433.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2623086.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6229275.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5989575.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1491136.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8466641.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5293138.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9032289.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1210282.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6777483.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9651354.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2538735.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5361930.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6163463.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4952823.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6958726.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9039996.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7554585.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7063250.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7912434.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3542091.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3200089.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5655430.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4749220.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3121781.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4782324.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4024982.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6605124.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6807906.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6361769.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7542451.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8626738.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3483300.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2467915.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4371098.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5911013.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1907854.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2668484.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5030593.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9672967.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1730338.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9777807.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3697977.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6821137.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1689261.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4540766.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2805552.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3542838.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4073859.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3070815.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7646447.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2410081.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5356710.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6187674.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9458612.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2071256.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1910692.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7012313.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2099432.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9033532.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5156427.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2808360.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5551076.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8620316.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7703339.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2036677.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4107483.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1906316.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1766108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1116303.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8921283.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6542803.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8517030.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2636284.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2158609.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4094998.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7992098.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9146300.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7480416.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9068130.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7814682.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2886678.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3521946.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6646546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3201698.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8701729.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8471184.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7971819.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1724681.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7214959.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6493291.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7522753.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4270011.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7835425.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9028684.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9990423.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4198620.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3817897.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7152680.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8043224.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9634741.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4701848.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6487397.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2573788.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2601118.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4377459.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9128509.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4051494.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8504309.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7736098.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5620926.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2227644.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9776650.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6702995.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5943775.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9057366.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4830891.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3415697.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6554938.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6294148.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8027535.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2734134.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3307838.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6771042.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5302008.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1647472.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9410579.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3568495.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8648998.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8417217.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7155515.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1069429.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1577091.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6043708.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9724970.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5502551.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2940693.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6980848.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9079664.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2609482.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1070608.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6782590.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8823563.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2132940.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9550455.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9060445.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2258719.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9566834.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9387181.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7293276.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3964367.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5833345.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7579644.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1430678.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4928290.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1504415.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5787162.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6389418.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8559775.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A3033742.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3251439.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8383169.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9297349.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7477492.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4972083.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7828702.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9407316.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3179813.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5972028.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2100098.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3623538.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3712804.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7413383.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5550372.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1350341.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9395016.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4004122.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9538737.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9278712.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2089577.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1467259.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3175133.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3648426.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4188335.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9147004.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5168060.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3957407.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1213912.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3683488.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9473954.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4204645.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8015917.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1033790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5856245.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3441863.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4075962.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6111619.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3908945.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1334000.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1935533.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8240695.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5555520.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4659904.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6781646.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7069718.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8946701.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9578129.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5314975.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8430164.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3048485.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9219651.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4046701.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1727412.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2783741.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4861467.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5864334.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6419375.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6372000.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1692991.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5428305.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8759065.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7878868.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4137804.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8052911.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8325879.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4157205.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5135892.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7781360.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9846145.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9045286.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2630262.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2190013.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2783736.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3953960.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9111243.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3047707.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2749920.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7690613.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6638292.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6973544.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4633285.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7743946.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5139448.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2662912.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8219377.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8749966.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1553940.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6858576.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9965547.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3526348.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8748674.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2039849.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4794638.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7447403.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8395160.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5460081.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7092727.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3915603.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9269524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3148790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1252439.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8639906.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2992938.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2000677.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3222863.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7230067.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8429298.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6994485.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8113685.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4410778.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5285074.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3384636.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8112997.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3831194.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1310178.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4385647.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6670546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6347293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2121248.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4755761.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8630674.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1929137.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1109594.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5626885.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9214444.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3222530.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6687487.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3911210.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3671696.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5909511.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1013351.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7328365.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5538067.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4653187.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1154042.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5880504.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2200813.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7217744.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1323248.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2365372.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9173486.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4319698.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3253920.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7433312.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3511938.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8335879.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1831235.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8216981.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3716830.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3914012.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1145653.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5007678.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6301559.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8922964.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3179537.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1286298.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5290276.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1140001.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6331045.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5711197.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6234125.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7605814.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9827905.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6706108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6263857.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4532091.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8239391.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6418143.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6536373.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9749164.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3682344.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4332462.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4541946.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7150330.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7823093.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2468681.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2355394.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1225857.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6224826.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2665384.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8299671.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6376034.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7344414.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7493758.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7655359.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7603539.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3507946.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2895536.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6017572.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9889002.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9243435.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4624110.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1634982.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2052404.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1960158.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6868986.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6744394.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2750347.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3265404.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9333140.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2997686.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2373619.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9793364.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6596386.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2696713.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7110191.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8847340.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1604821.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1302450.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8725201.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7445982.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6539593.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2368405.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3823146.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4100331.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1174948.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4795496.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7174680.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5740527.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1235441.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5254592.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8905251.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4967219.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5903059.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6555348.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1163274.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A5208875.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8799238.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7167556.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4732349.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7940630.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3091174.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3961407.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A9847831.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7155077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2682750.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2803808.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6997616.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7312331.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6965886.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3418197.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9269932.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7425229.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1783579.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2373249.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4721135.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6427745.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4711079.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A1709351.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7803999.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5006985.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9995206.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5252915.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7215796.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9607810.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7676086.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4978945.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3848408.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5899230.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7775931.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5706347.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8918199.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9256322.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4022122.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3513143.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2175100.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2445110.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1244152.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4080105.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5431061.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3916869.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1685665.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2562802.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3359609.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4467350.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7982515.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7075609.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6011449.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4215166.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6939242.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7377661.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9219763.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4935590.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7029464.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5593324.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2754754.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6889839.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5701178.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9864872.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4379125.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9630630.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5509385.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5146000.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8045368.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9879743.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5379024.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6910085.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3756668.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3559350.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6178258.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9090373.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7841713.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6971596.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2933325.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1998383.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3324293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8375621.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4720724.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9269031.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7538283.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8054129.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8993683.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4455671.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8676852.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5152043.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6281278.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3697003.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3087809.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2672504.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1330872.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8169535.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1643503.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9635598.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7598763.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8138490.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3801467.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7626732.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8999774.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3225133.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3877598.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3274096.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6760448.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1686730.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4436975.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9404721.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8744591.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8258114.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5175019.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9930337.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1846534.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4090386.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4903271.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5765813.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9802124.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7217178.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4835888.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1876478.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8254834.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1738456.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6327607.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3734384.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7530963.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9468400.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3122359.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4330633.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4987734.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1498419.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4116066.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1554440.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1122851.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4482886.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1256616.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3405875.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6953234.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3431429.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2407949.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4708521.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5406938.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5359611.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3436246.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3892464.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9393273.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7367548.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6350690.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3768043.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1783200.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5624787.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5216132.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3423947.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6467788.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5834361.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6374635.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4664562.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9410762.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A3821822.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8632976.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1483255.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5141815.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9848337.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9879893.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4605071.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8355014.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6550799.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3351813.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8493549.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9760435.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6808554.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4664098.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8331705.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2349071.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8557120.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5712884.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1438053.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7855880.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8992211.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5404456.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2714799.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4133328.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6907890.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6980700.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3462948.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7640337.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A5839270.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8021300.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3381658.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9364648.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4096252.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8602093.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2089296.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3855113.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1792942.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1759846.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5262789.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9632174.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4350531.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1099036.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6874225.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8667890.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1727259.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6621375.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8904339.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6636849.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2893374.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2873120.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7251718.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6286694.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4465414.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5133679.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4431249.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3555959.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1963148.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4838613.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3770189.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2217840.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9063588.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2129044.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9817776.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9586482.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6737069.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1255190.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6489038.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4788477.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3302572.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3026582.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1482444.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9661146.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7502541.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6226724.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2140167.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9987542.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5682649.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9980287.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2730696.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6970807.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9954975.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3038066.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7721116.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5420559.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4782580.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7429573.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4325061.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4529848.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8817227.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1011803.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1399433.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8129002.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7334829.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2940871.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6014098.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3692082.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9812574.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8372367.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9781565.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8778041.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8572281.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3254565.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2363025.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7080960.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7871433.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2172503.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5488466.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9020806.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9363532.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1842062.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1858896.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4727777.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5768667.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7493888.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8221172.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1932002.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4312607.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7545025.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9082821.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7252972.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1517167.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2314118.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4877747.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2518931.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1662032.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5182137.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2721592.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3971391.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7384425.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8824951.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8463208.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9972902.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9191895.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2781588.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4409670.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2411171.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6923970.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3021752.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2038022.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5986531.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5262336.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7790208.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1908543.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7405109.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9138207.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4594626.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7776921.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1813597.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8955789.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6453668.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4443199.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1868870.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4196425.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1222412.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9564254.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2431894.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6919861.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9290678.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4739339.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9448059.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2825255.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9258853.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5585566.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3839727.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4210108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8239811.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9419406.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4610336.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8626523.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1667660.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8166506.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7815772.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7242421.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5837408.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9543824.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3337779.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5304328.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9849463.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7078257.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1067293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3255374.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9488711.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3829377.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7368652.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2604044.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3471722.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3601717.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4263076.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6889706.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1327821.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8718343.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9532967.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6139191.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1281674.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5844576.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3739109.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9405976.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9050207.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1265930.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6252520.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9990268.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9418647.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2501213.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7304573.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4941147.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5669314.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7641463.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2588164.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3703448.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8441379.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7926720.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8125534.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4607559.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7889257.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3633666.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6394174.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A9344861.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8880908.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1946343.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8203453.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9964585.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3704227.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4660937.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7587750.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2076622.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7448826.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9173255.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3710634.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3485535.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1540546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3464873.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8995491.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9845440.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9813220.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2273717.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8992354.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5713329.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5484015.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2006520.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7318100.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4532212.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3990384.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2901891.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3818979.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1375701.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4766282.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8139147.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8679162.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9121925.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9387725.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5331965.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6133436.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2257248.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4266624.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5542441.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5855737.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5803157.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6722400.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7294439.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8279472.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3832215.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3265146.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4014102.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7220030.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7695915.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6646073.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8414948.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8699418.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3605979.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3687111.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7935788.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6682282.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7471566.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7509136.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2738834.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3449120.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3395973.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9085063.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4812539.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3611890.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9776670.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8823113.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7618772.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1719130.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A3424299.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1092011.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9179176.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1786669.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6096798.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6313860.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1419165.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6391008.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4596836.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6992506.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1154445.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4353126.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9171546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4707545.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6400877.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9279089.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5263209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3299761.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7827984.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9918923.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1487884.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8978389.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7079738.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3068013.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5822574.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7022290.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8036754.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4909017.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9712531.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5032561.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8969062.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6618673.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9327441.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2827815.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7761860.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6122159.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9992081.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6399068.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8708894.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8436090.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5341919.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5246844.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3738935.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2301434.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5008020.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7970394.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9188499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4705128.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9986492.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2190947.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2755057.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4474897.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3949069.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8513116.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5558298.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3525860.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3661291.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6891048.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4818837.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9353700.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7623422.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3994543.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8374821.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6836797.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4080447.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2259082.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4873929.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5582077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9562857.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3721647.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6014309.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8822702.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8033805.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8370531.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8464349.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3340490.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2551323.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7016665.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3321183.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4646782.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5630906.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5558762.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5830119.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4984323.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4473201.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9698758.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2097549.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2147499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7668923.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5046270.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1320433.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5516861.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8219320.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7639886.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3426587.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9856811.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4916618.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3211207.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7197610.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3797623.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4811745.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2876549.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5725535.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1854698.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4743748.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6547267.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5243345.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9272295.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4908606.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5622192.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4808564.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5225469.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2000270.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8280954.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8952332.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3656048.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7037568.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9205652.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8156221.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1039352.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8277529.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2323050.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3148728.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9507111.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9148294.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7279819.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8823955.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4391346.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7495264.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8946234.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5375953.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6755881.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2454306.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3874530.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4739552.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2497632.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2014376.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4517737.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8445551.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7100596.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2378002.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8748336.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1774545.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1210308.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1315268.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2459534.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5231095.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3356401.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2047714.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9280910.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4150578.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8453485.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5180331.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9213293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A3998756.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7023194.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2212896.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5157216.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4693227.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1205809.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4772853.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9340439.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6798502.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4822863.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3289624.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9653349.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2957033.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3261040.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4919152.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3169425.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8597146.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7777408.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6971191.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2364471.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4762150.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9398311.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5385654.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4544705.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6795330.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2786426.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9011033.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8056513.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1496329.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8483637.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1781840.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4693677.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6354407.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1125443.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2064424.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8775018.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7818681.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8391031.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6387563.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4744961.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2388256.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7955936.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6475998.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6201379.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3258287.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4077093.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8203238.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3542818.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4707400.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5251397.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1107162.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9355791.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3631460.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3475809.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4075554.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5137114.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6399087.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6206146.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7979859.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1901559.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2811531.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1072750.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9560186.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4208703.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7468252.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4214720.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1086117.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5784781.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9177884.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9088344.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2076419.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3458224.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5361013.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1913837.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8757493.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2168765.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1647517.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4852262.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9787720.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1893300.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9570885.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9978267.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8954659.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9422097.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3253832.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1238224.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8777926.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1590465.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2431656.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3914100.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6233658.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4086086.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9725707.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9208826.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1354267.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8989373.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2911653.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9582615.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9485748.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9101351.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3717630.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4594734.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6502047.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1397883.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1268343.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6487972.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1465478.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4543613.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1560518.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3719507.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7396859.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1099431.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6713561.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5511832.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2238657.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8877871.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5322758.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4404500.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8747240.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1333589.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9692093.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3917405.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9643963.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4774657.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6299865.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6111455.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5959564.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2689262.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4400810.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4621980.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4777978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4322209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4199338.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8670251.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4978292.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9023791.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1923351.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3233819.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3383262.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9089386.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5192926.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3229147.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9207053.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1759811.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2526072.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4282521.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8070708.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3898897.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4260748.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8023690.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2392088.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9690104.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1761897.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4620738.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7069104.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1399034.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9151666.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8148116.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7962595.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4309509.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4128499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9323394.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1572876.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4224816.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5695972.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6759288.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1691558.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6505628.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7067819.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7561468.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2237408.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7844395.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9828432.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2027695.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8350241.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5207774.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7504138.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4464602.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6252598.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6953633.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5505522.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1766201.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4909781.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1755998.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7804972.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5186066.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5436823.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2742907.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9503781.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4155900.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1934494.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4456289.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5224014.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2003630.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2533620.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3811349.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7355194.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9614912.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7318012.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7919521.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6978099.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9710760.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2694450.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7986278.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8676385.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8239000.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5608345.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4124510.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7758062.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8077864.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8983457.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9283845.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6975351.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1056126.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7997193.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1135290.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1672570.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7051881.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9665152.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3987800.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6478979.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5278629.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4778224.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9440828.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1554417.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9437915.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9000858.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3452150.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4623114.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9838432.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6655433.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1447159.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4432432.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7282781.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4272775.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2162411.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9465265.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4742765.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7257361.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3599336.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2933958.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3231577.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4113233.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7502845.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8206313.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2856239.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2120662.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8266912.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5254746.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4540195.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7065127.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1994524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3038898.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6128692.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7306149.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7588108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3187403.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9821306.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9086835.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8270829.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6203082.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3150524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4873753.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9327768.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7814134.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3698964.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9543170.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1871305.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7106784.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1247545.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7227576.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8785020.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4126192.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2017366.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8822978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6767335.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5340522.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8368382.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7524832.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6966438.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8371459.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4498530.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6139596.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3156809.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8401160.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7365037.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2162554.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2087660.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3945699.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9927919.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7524998.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9842278.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5307103.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4416028.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7246435.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4095096.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6431150.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2866230.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8491036.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8780388.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4045674.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6085767.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7977328.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7872248.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4675631.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9842782.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8710724.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1383086.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3296617.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3795537.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7801336.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7596815.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2993554.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5103277.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8795020.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5528319.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7161343.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9828127.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5117664.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7289572.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8667828.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5930502.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7437185.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4861294.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6216280.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6276881.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8172142.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5116976.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1720524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6183181.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6551560.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3987416.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8635358.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8569160.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8202215.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6019242.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1065703.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7841482.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1615508.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A3406491.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2934771.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7551031.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4710003.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8308080.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1628276.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8154420.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7075432.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6440443.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6477730.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3019783.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7671981.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7208665.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1080305.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2764073.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9965269.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4020774.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8361009.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5591088.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3803661.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8834005.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5139366.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7534998.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6614129.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7507201.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7277692.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2254599.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8411160.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9678625.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5605961.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8764035.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9219108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8491935.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2244960.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1935790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2450980.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6168960.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5212063.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6398100.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1257115.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1541750.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4058729.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6613183.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5039291.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2987782.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6689122.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1993832.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8730107.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1167299.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4679487.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1909893.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1522511.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8548502.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8107687.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2909330.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9644926.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1411810.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6765934.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8925219.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8347204.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9390388.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2721750.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4772900.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2529057.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7237649.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4924285.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1685761.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9738066.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3130519.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5859186.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6016772.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3429664.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9910406.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1604026.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5327720.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5582431.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3081070.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2663641.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6553662.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6977815.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8619108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3477434.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8575786.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4386883.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8936435.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1859546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5516877.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2864831.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2779987.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1452121.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6214028.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2575390.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4508968.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6297752.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3683514.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6129703.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2421355.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1350377.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1951644.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1255217.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3689119.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9463431.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6952608.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5791080.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2084689.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9056541.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8338359.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1012151.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5567037.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3788893.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4082196.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7469140.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6546933.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2102569.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3454704.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3939687.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3870973.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4220286.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6955437.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6026794.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3996568.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A1478713.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8042403.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9442696.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9280843.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3383448.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3189688.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1814090.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6035442.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6723207.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9261505.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9364465.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8365375.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6926549.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4108605.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3543209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6536762.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9734045.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1216225.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1433961.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6557271.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2782166.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9356847.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8972268.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4396883.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6336391.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4875941.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2693415.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3393018.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2395864.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4067969.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5132615.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5502567.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5843071.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6780061.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4716712.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6935365.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6382262.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2199789.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7802625.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7829575.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8890363.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4944187.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9346144.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3819503.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7975180.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4332589.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1915449.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9192981.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1769674.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9355292.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9767427.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5960189.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5589787.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5075156.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1943383.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3664986.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9282487.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3058519.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4108255.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5818473.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9854093.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6446352.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3465059.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5063578.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1075596.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2564978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4745720.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8320293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6706149.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4451366.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1597359.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4245386.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4316486.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5154569.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5323299.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7255126.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1887210.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6961168.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7474288.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9712177.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A4039519.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6618235.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4613222.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5629232.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4783016.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6480464.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3631533.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9459873.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9657259.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9752339.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3525175.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5540344.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5598483.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2691097.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3995651.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1571935.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6851653.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4797110.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6422156.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5326074.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1396857.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9378850.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7972700.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7296107.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6450793.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2093459.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4882496.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7322396.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3752390.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2603406.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8265152.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2260316.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3934959.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8218462.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5219455.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8168735.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7676497.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4979246.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3263968.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8280104.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8354994.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3304234.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1726370.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7824202.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6149114.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1137468.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4817238.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1045435.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3913329.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1605288.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6231389.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3216868.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9567655.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7124876.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4238209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6652533.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9005965.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3455050.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4608481.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2288122.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7458758.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5875905.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1679900.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1077114.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5775782.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6083830.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3807008.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6152758.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7479005.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A3345148.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3097848.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8284844.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7895059.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6321842.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2203792.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2512612.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9074575.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3373759.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2639517.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2057702.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4744977.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5053822.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3716037.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1698915.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2843754.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1472981.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6857787.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8454706.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4717046.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3064499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5562720.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2825582.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9181211.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2684295.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7586696.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4205824.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1481803.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8601884.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7581153.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3987396.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1293034.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6448659.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1152568.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6377371.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6372489.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4508987.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2361665.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1433127.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6324713.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3576901.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9686245.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4998603.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8928094.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3982194.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3186592.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4345908.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4164898.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9586210.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5239519.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9448274.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3326345.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8432180.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5164999.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9895826.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1948520.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2583155.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4185474.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3968667.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7513192.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6489700.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8498597.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4587677.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3105342.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9078556.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4908305.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7521519.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3395123.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2424012.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9413676.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7030254.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1150105.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4120396.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4015640.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6917701.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1297974.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4122651.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3353615.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1482686.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4352664.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7213603.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9095130.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1651986.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7526726.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8035181.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9483720.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5291563.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6263050.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7547235.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6038335.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3052952.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1308765.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9357493.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8937418.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2384849.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2009381.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8415420.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2802472.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8206305.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4389449.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1687863.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1576989.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8105985.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6439433.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5179978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5872813.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1516672.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6752578.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2106316.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5292066.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9847129.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1868427.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5619112.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2468156.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6326954.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4595563.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3203410.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2409445.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6739466.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7210306.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3636560.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2525648.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6610193.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2203511.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6375966.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1917618.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1659636.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2197902.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8527263.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7310434.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7288230.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4207233.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3924689.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6022041.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6525322.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8744180.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8518520.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9187516.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9131122.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3031206.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A1974946.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7999898.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4732021.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6739036.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8883723.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5488831.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2628185.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4779970.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5412890.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3411877.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7289071.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9784663.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1485790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9857129.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3679822.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7313648.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9798640.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4571324.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2619288.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6824929.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3665801.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8683795.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5073714.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6721056.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3402308.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3858760.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2453206.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8032097.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7860326.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6732380.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4534368.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1399022.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6964805.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7936624.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5029854.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4876951.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8308583.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5859240.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1010300.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5533406.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8007623.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9968508.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9040303.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5918984.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1275834.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2489513.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3043990.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7810024.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5285259.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7184616.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8987402.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8263205.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6640627.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5679210.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4334631.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6812118.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4017104.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5680635.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1079389.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A8972377.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9569562.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A2926096.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8831704.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7169620.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4340823.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7629605.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9297543.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9958014.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9392423.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1441131.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8677582.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8505312.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1171121.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6440140.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1009571.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1573322.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3258911.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4087052.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7233935.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1108901.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5941841.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8747256.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5691024.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5494111.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1391042.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3683328.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9698172.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6086448.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A2840122.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7774818.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7753287.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7860799.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4565388.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3372324.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4487779.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2917457.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6013209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6361499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7077049.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5130852.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8323796.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9238643.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7170114.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A4850706.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9890848.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2302577.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4367746.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5218478.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8142448.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1895104.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8330440.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6564792.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9307798.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1157156.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4194009.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9202302.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5039012.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2426243.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5574532.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1791293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3040200.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3892833.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9846387.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8002564.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7195142.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2464030.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7384464.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6781109.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7424615.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5557252.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1734571.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9105492.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9958501.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2313366.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1252301.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4923239.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2827229.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1801912.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2107012.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4811180.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8858298.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5150603.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6189060.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4220005.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1109756.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6090123.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4203765.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7507647.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4350065.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3200729.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1480087.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4649318.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6822111.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1774695.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7640663.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5660524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1975462.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8887275.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5282573.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1510749.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1381804.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7047555.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7305773.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9770531.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9338171.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7070626.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3553120.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9345441.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8563828.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5872956.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6488687.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4645291.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3050200.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5926993.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3945375.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8888929.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2502887.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6188221.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3601756.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5850124.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7150058.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9828998.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5547252.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6842643.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7947788.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9954522.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1457909.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8287507.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8526864.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1624613.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4283799.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1184462.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9491571.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2960993.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4631979.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6448966.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2028599.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3315219.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6832541.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3273657.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2501252.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6421845.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2312577.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7425004.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4897801.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1140739.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8580103.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6473765.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6932273.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4223629.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3739518.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8165691.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4392340.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4542151.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9193040.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7989524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8039264.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5303855.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4882300.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1556129.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9699626.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6031728.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7741310.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1626784.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5664137.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3576794.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8443755.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6055039.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6106739.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9765733.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6995056.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1054048.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4852018.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8002837.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8107957.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1298044.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1735730.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4993389.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9404275.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6703432.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8101180.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9162405.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5645390.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8055145.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2744257.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3673717.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3165152.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2450611.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3482065.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8131218.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8835086.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2385560.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1564776.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4604949.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4573821.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9257030.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1723430.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5445273.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2399543.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3476622.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4918217.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1226294.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7916553.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7380309.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1542214.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7576180.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5717956.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6682739.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7904997.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5372691.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6039436.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3555220.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1753732.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2959083.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4795195.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6114883.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5005653.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7058024.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6628284.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2304677.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6892275.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9634370.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5475295.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9352500.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7036338.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6580301.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3364927.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1696819.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1742089.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6083888.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1820432.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2285252.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8354886.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7609088.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5522885.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5879567.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9298874.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3409285.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1061582.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3704118.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9265511.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2462330.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3288131.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6509076.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6093471.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6284980.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6459859.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1525329.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5004412.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1978084.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8163591.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5758414.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7833085.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2770708.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4211975.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2656108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3719680.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5473711.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9748299.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8111354.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9635131.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5767357.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1499588.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7051655.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8514692.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1437975.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3651666.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4864254.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9423628.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4493014.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2123799.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8472726.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5205837.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7502691.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5961665.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1668700.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6026239.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8977894.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8503854.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6069382.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5826576.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8315889.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2584278.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7442247.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8689459.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3242274.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9247030.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9551675.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1189987.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1998680.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9392618.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2759035.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7862570.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2289271.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2617804.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3308305.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1139564.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8720853.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7059635.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9407727.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7072565.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1401144.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5905524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7993257.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9685982.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9471908.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6029066.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8687914.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5068699.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3023000.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5254838.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9489395.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8918530.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3857704.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9298177.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7844012.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3949182.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4596524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6426457.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1937095.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2627948.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6880248.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2988420.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1515635.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7321447.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8856814.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1551984.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1418670.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9300266.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7130161.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5645902.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7685811.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1986671.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1427133.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9389111.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2105644.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6508372.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2461009.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6232458.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6570440.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9084776.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5180370.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9916993.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5794390.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6442653.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3397149.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5062781.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7263556.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2577745.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9904557.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7613190.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8197293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3361733.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6297210.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8047343.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A5759463.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3169464.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8353705.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3040191.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4404668.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3030769.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3815432.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4620000.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6918509.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4694409.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9316218.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3453079.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7934137.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4990264.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7423241.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5758101.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7572086.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8186528.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5452559.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5814112.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2789792.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1650769.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7784031.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7514250.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9019442.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5978151.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2123776.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9011072.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3025992.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6397172.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4512124.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1870739.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3748230.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2470248.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2408829.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4047464.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3409790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4195423.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7920877.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6959506.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8115602.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6296051.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2416837.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9127222.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1177221.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5322963.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6196004.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3274653.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6471133.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4502574.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2565778.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1729482.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8216978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7125363.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9891998.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2554926.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9725316.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7951467.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5098422.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3436529.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9436095.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6173052.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8914006.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9238881.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1709937.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3009054.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7487218.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1892803.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7368078.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8576542.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3521927.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3682647.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3932423.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4918702.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3750600.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9043201.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9133261.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2394664.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5896583.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7096267.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4759241.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9824329.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5402717.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8310367.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5775385.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6700926.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1571962.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7509462.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8403720.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8671728.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9970616.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4537790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2134549.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5714696.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5647196.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6287210.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5098072.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6604754.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6850916.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7379669.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6215681.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7037895.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3558107.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7214938.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9366819.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8937336.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2861672.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4075145.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8108899.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1986108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9079890.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6880024.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3006821.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9132759.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7116680.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3484277.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6648610.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1128119.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6555974.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9886924.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5173071.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2830807.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1971860.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4385597.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4983761.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7845896.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3649893.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2785861.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2135071.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3586128.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4482039.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3670707.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3723007.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6885226.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8742003.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9313333.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4519912.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8873520.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6398004.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3297102.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9519267.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9910797.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9048764.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8669461.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1010357.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9844752.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9590110.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5760304.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2948807.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7612851.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3781470.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4767190.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3300109.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1639133.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1389976.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3423402.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2828164.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5733766.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4571373.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9421183.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9066636.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2669427.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8275386.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8920670.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8584052.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8976010.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4741108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4487391.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1441536.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7074327.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8052268.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9187541.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2808182.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6861461.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5943128.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4537143.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8087372.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3386922.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7131009.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6641431.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3044351.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1792407.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6310132.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2096525.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8025355.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6187496.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3835657.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3848367.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7211813.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8174468.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1242643.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5737725.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6794649.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2718606.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9331242.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5661227.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3665505.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8425491.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3301348.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2750078.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1448347.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1796917.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9358361.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5924916.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6865971.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3823783.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3813335.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7173780.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4007503.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1387968.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4716483.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1666088.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2942509.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7752584.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6680568.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4183324.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9133518.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5647315.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4347718.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5397151.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9576290.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6911051.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2443251.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1561718.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7105805.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8141376.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1640010.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4121303.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4928137.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3962817.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7725143.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7793577.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1132144.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4626357.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2435984.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A8331933.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5943082.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9848264.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7582544.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9601317.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9960883.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5140654.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9731139.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7938378.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1007187.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5340099.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8720279.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2165680.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7736780.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6835683.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5581499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4453475.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3896827.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9579470.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8063889.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8622126.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2437956.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8162103.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6602815.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3972401.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1234929.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3829731.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3559983.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2422257.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3954499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2267312.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8546398.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5416168.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5963822.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4987237.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3458009.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7676706.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4440609.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3590910.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7215016.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4008249.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1716457.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1626679.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8468002.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1161199.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5630697.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6385289.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6819646.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8213916.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9669976.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8585706.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5375787.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6331680.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7596507.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4873342.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3119859.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6441213.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3921433.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3997007.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9396088.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8160094.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6762526.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8599725.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8958904.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6399750.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5238563.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7043541.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5224540.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5062914.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6123973.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3938612.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9647824.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4936596.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8853483.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9546763.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5091896.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4803040.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8657476.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4984948.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6626449.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9918348.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7614069.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3475777.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9305658.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9628979.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9285895.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6638457.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6153722.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8335245.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4544528.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2245799.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9049899.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5771000.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3000449.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3789555.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9103842.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3775722.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3792749.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1318227.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9824846.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6319256.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2822586.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5083901.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6597217.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2611600.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6589209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9873134.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9584016.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5814684.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2723413.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9901169.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6971646.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8778407.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7340768.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9756004.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8781188.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3013265.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1874845.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3283004.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9526031.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2302170.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7815334.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3545109.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1839869.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1777847.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3686468.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3590013.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4928971.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1671608.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6923966.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4555293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1494569.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7750805.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9148543.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7189136.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4578914.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2534848.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9747245.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9481526.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9858634.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3036982.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5401707.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1250691.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5579357.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8695753.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2745295.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5715341.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9868282.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4133781.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3960596.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2043829.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4883116.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5441549.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2008178.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4012644.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3235060.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2329670.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4255502.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5983725.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9329367.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4636212.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2423016.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5041777.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1715781.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7264712.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9809586.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9457904.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2626334.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4744058.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2063271.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2035411.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2321057.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7017808.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8925720.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2804359.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2021002.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4058210.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7498196.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6745442.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4193076.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2248216.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7535126.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2574811.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6132476.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7123736.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3032685.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3564443.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7257971.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3437343.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7508658.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9007077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4407896.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2066073.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6356050.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7631999.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3500702.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3405662.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1514819.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8820210.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1520445.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4710255.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3419641.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8467949.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1415193.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6438577.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5838006.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8705320.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3353269.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7871262.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8024616.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4233193.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8039927.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6759031.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8298518.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4427489.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7996491.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8652930.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8333885.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3879768.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7030628.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7384274.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2623566.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6957133.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6865320.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1146157.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1026567.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1683676.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7606613.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9057239.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2813166.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9494533.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5737027.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4386143.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4263277.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9415274.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1208702.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7315163.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8701699.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1098563.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5475201.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9667786.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7625489.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6199670.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2966304.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5263726.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7792937.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4423130.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8618220.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6981255.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5504889.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9816673.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1885344.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8921333.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7596710.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4825735.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5500063.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6301021.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2388796.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7979863.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6415659.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4240147.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6861733.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2788402.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7685539.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7799382.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8388380.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2709345.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7728073.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4620978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9546124.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9765089.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9287646.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9362572.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9139617.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6167590.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6691181.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9088684.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3703219.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4707590.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3112501.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5090439.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1817385.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2660104.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9108849.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9228053.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3934975.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2542923.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3028322.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3870549.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5405553.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7728589.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7257422.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5419570.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2615004.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8808296.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1936240.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1191973.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7842017.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1290321.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5778523.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6560084.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3652031.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5354388.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3260684.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1672376.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9110595.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6323916.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7027102.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7929791.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9695853.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4223486.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5943295.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7928883.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2889578.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6176694.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4747731.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2552535.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9562494.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9970682.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2910994.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1459311.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7301435.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9167152.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6041685.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1047131.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4176866.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9652077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2525408.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8906806.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2757400.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8819192.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7990400.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9657625.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4348750.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1247656.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3780426.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4547056.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6434411.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9856128.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7845382.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9667293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2323986.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3562082.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5080985.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1956904.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1284698.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9676482.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9054803.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3165083.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2549683.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5976071.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9079384.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5396804.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9741169.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4464454.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5423174.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2850912.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6743083.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6712126.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5906689.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3574156.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8965978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7708979.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7083858.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9589126.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2089097.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8206846.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6915655.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2197611.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9556431.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2359620.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5217172.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3397077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8623035.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3372021.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5034525.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2002627.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7259129.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5415046.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2381108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5010580.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6812358.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2879686.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8378091.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2764730.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5255751.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9265993.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9803164.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4158467.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2508726.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9857739.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9747547.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2726543.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6786199.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3224173.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3340500.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1655455.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6490018.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3817531.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1520500.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2692228.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4472979.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5781805.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1099667.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1310545.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6990852.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9332383.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7483365.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9138143.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2018553.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2816558.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7491071.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5064012.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6633630.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8368642.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6962912.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8028459.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7120726.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8091398.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8476437.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A5227434.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4023532.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9304032.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5237747.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5364047.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4278657.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1051266.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1991209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6031704.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3493176.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4383087.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8109066.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5804305.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2782263.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7396025.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7022479.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5716146.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6008890.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1196920.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9063859.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9580184.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8346710.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7907010.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6964595.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7073476.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3199077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8969721.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6618130.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5912019.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3826515.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9055592.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1584670.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1178639.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4828691.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7065058.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A6514235.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9903986.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8168125.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2362659.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4344909.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8789890.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8842713.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5645216.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7125174.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7656261.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4342977.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1544138.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9066358.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2486625.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2822007.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2927167.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5104588.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2156461.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2359159.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8852343.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6166417.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1940700.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5108952.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2158886.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2193982.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1859643.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1227387.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4856427.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7245673.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7518967.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1499770.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3040386.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9497523.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8275312.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1438878.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5890640.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7573879.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3841078.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9939194.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4373729.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8868602.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2183081.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9290615.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1702896.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2037210.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5529861.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3775309.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6698066.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6281583.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8395674.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3247324.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1955851.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5758746.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3129597.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7778401.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5131296.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7142049.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9616503.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8875899.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6671910.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6028876.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7740487.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2307759.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4884352.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4380701.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9361098.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2168860.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1401646.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9965253.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9702272.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8256022.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7789044.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3649807.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2266128.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4856077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5088635.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4171589.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8161304.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5082238.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6424368.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9433983.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6470535.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7511615.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6051543.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5387080.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5416955.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6324416.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6419103.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1643217.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2729120.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5112519.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5381857.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7776809.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4231287.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1162721.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2748433.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3335396.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9184316.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6828475.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1426923.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6351516.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7949755.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1982999.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4467014.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1255407.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2429175.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1193364.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1929766.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1122095.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A4237020.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9338018.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2419039.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2160945.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8614080.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4922812.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2571890.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5807196.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3421014.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4981727.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5655703.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3513207.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6198718.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9635776.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1938527.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4527092.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7295584.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6817766.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9754557.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1790912.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9538541.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6822428.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6950475.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4808362.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5312784.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6636824.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2581797.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7356628.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5104567.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2483132.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6116200.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8153330.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6597283.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6468943.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3968562.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4482412.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4995764.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5603533.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1130801.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8283587.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1374468.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3510978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3415818.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6166102.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2413064.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4146245.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2784358.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8981903.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5978653.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3426381.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8267790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1927778.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6164996.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8493524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4026675.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9025385.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5899524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6312174.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6134721.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3385676.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9336006.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3288326.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9178862.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8320483.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8821728.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5553378.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3467674.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1092617.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5035508.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9030884.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2620599.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5812394.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8375836.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8776527.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8720347.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7522460.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4909241.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1076953.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2055590.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5392778.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5275471.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9326905.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1157896.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6457353.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4408519.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4093894.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6997102.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2857941.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7561901.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2660387.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9360236.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9735947.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5572075.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3577845.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3856752.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9539350.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7098982.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4663360.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4210889.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4461590.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2448935.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4501909.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6854304.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4486001.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3641471.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A6315891.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8500995.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8644364.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9669848.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3552208.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5223641.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4104935.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7260028.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2268073.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6266854.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1955017.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6173300.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5946701.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8110752.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2655533.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9602956.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5987208.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4593862.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5059279.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1621082.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2073158.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4931697.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8949905.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9932449.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8665317.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7565295.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6395860.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7485659.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5636850.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2143458.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5459769.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4538449.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4611771.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2793649.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9560411.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5030474.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6022313.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5556204.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2343295.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3842195.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6601080.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8846992.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1862728.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9794161.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8615015.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3972641.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5885679.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1714780.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1944128.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3576079.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7057742.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1815615.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7869255.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2039465.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4573948.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7611882.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4538019.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7585491.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5637312.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4775752.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9566896.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1355948.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7929683.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2433256.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2276313.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5312803.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5561527.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1852234.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1298603.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7835038.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3327485.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8343379.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1630017.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5238723.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5941640.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6379744.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3007965.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7572803.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6628247.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6906868.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9964383.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8257408.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2780435.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6938039.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1815245.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9606738.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3445928.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8116901.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8336783.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8803874.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8657636.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3009582.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7395961.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7080235.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7776624.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1669078.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2334202.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4144556.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4139066.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7005531.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5301686.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1403010.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6061771.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7486075.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8879228.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4962922.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2412858.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2399979.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5143238.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9986943.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7492466.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7114042.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9324345.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4449238.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1111872.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1334108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3166247.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4457226.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9587883.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6042011.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2896635.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8377276.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2448718.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2178708.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3939613.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9326682.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6999262.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7678108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6307008.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7834783.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7184114.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7943026.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8829965.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5539709.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8730039.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5780605.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2017864.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5009719.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9756244.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7871235.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6407263.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2363789.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5783880.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4421859.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4903861.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2681146.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6342414.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9726516.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3872870.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4913498.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1701428.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3456607.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9129210.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9669235.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4768160.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3259101.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4646350.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8646924.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6558813.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6593917.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6046951.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1332875.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7263080.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5555582.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1952855.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5892016.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7420912.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6962380.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3508735.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5417169.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9590215.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5998283.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4718262.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7792599.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6583014.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5409177.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3453110.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7735753.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9910187.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5314938.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7899514.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7205743.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2822683.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7204851.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1978102.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9769442.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7885537.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5871878.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4644382.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2872834.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7314230.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6483399.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6874423.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5422732.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3568821.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8177004.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9381018.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1896929.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4229875.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8619173.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4458096.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4443770.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7943499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4749328.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9652889.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2155830.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1120293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8724095.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A6136654.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8872872.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3812764.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1336070.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2711667.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8313072.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7854897.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5579052.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6445505.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2392289.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3345305.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3405320.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9037029.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1861411.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7681192.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2586269.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4154940.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6756686.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2916817.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4779634.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5879818.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1418719.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7695581.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4660777.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2600744.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1717143.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4193164.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4423921.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9039934.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9280838.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2931267.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2490525.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2059622.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6797675.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6076958.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3975868.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1075914.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1879922.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6592740.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3397020.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1357133.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8316270.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6732197.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4148430.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2892363.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6176769.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4689352.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9892674.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9488052.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1758851.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1791968.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4233982.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1561108.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8071748.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6758732.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9416819.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1407546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7926599.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5957281.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5804581.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6060025.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6049348.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6942223.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8096723.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5307617.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6179166.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1891215.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5116331.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2848476.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1226312.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9122519.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5147294.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1411492.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9465434.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3436010.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7438837.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5641828.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3465188.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5694932.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8868985.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5245356.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1730230.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8838698.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1681759.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4944056.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5873516.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3215229.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4675575.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4163330.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9940263.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8726801.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5002010.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8521909.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5666608.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6199298.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7620799.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4413494.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8021855.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4928377.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8558129.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5702781.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1221087.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1507274.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7431745.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1995837.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9067267.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5869818.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9501417.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1698578.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3827979.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7635962.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8062534.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2388684.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7706463.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2720090.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1344436.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4194072.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1050070.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6254134.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8456486.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1510698.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9245308.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5462205.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5612230.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3347011.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3079815.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6158841.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1699040.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1233669.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6756055.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1606719.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5288555.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4150779.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1125212.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6983950.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3226660.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1225247.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1311883.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3172068.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3879103.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7485966.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3514080.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9090125.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7275338.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3960040.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7312864.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6598064.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8424613.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9804025.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5141593.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6993403.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4444666.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8438630.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5543790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7714327.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9853957.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4964663.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2973297.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7329667.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7781073.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4180031.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3321697.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3100707.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5625513.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9290642.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2582800.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8137499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7263346.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3343951.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6852268.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6804408.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7818480.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3463375.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6651558.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9534923.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1593048.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8994740.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3943370.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1253838.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1564920.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5412557.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3197194.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3852603.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7500403.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9123021.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5265099.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1968381.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2301320.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3360698.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A6514798.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9573401.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3881767.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8750507.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8706367.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6718205.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6660655.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8085676.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3436293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1235247.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2449735.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4137644.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3691381.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1255846.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9185045.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1831576.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9722693.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3658742.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8178871.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4609984.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4392291.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8501795.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3369840.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1974658.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5363385.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1626655.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8929538.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8299562.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7006521.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6067099.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2865922.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6669927.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2546608.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1870980.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6506086.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1470752.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5007091.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2368653.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4390306.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3079546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9821691.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3273786.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4461528.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7141262.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3449634.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4975971.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6886563.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1122884.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1436831.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8898401.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6503284.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6167251.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3660394.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7031202.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9033656.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6017724.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5738556.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1952785.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1077246.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8638911.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2087748.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9875023.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3870267.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9142924.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4630755.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5577220.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1456725.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2444042.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2634077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6693368.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1944651.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6958911.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3999873.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8493123.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7794764.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7167215.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7165228.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9687356.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2448962.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6109458.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6509666.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4608229.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8101114.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2001230.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4623179.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5317928.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7898539.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6573493.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9062209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8534064.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3320439.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3213938.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2004462.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8152126.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7038865.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A4707964.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6455339.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1692749.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9046306.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8573445.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1893044.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9736795.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5263008.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5700180.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8703470.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7938211.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8260002.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1178681.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5477512.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6741285.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8188633.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6897237.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9285505.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5764691.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1183333.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2369804.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3326914.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9210651.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7015618.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4945978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2673456.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4842825.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1362011.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7092121.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3672346.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5912808.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6147608.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6192712.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4199705.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3005688.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3321678.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7508526.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9738621.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3095224.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9681778.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8040629.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8075567.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7450939.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6032190.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8190653.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2489092.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5415787.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6775670.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7669060.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2170441.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8514128.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2088844.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2632459.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2761359.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2283596.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7132259.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3026412.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1560125.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6669531.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6440091.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5036723.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6170081.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4344118.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5273458.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5374505.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5646528.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9567854.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7903511.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7421483.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6489002.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2970907.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5487746.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8000037.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8630072.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4850818.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6340350.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6507228.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6054716.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7726313.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4201666.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1431248.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2497126.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8682956.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1791207.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8540325.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8300598.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6798646.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2375124.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4552595.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2481508.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3019701.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7354212.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8238386.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5368176.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6008081.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9178136.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2812059.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6026429.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7423144.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5604464.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9097160.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4446071.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2040550.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9962241.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8755986.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6985607.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7095021.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9259151.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9437344.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5774404.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8721794.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6635463.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6108176.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8668860.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6473837.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6205711.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3377327.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6666001.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5099209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8002765.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2974682.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4873817.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6982438.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5394194.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8329460.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4496369.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7535167.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3928444.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3469152.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1870353.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4468123.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8980579.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9072136.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6435754.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1810952.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6500328.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2652937.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7891077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6242330.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5218229.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9008269.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9124064.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2337068.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6295217.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3519098.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9868484.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4913524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7906586.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3502284.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4377814.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5050760.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4004196.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7140609.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7058858.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1093694.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7505181.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6613551.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4865869.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2140262.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7295746.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4628959.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4030563.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4066303.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4726326.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4183037.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9457046.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2908059.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8668163.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3972207.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8344150.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7360022.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5245205.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6415618.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7143475.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5551187.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9006627.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4976074.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7218188.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1832823.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7071666.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6703263.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5154441.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2028798.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A7643994.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5000484.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9012234.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1968401.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8488000.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9362499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3760326.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9765162.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5386453.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6374160.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6567645.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1891716.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8862921.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4477686.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2261993.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1868333.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7942621.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7080673.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9284928.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9074148.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2552061.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8344500.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8816733.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5624178.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5647456.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6799368.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6928886.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3940726.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8670800.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7800730.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5925517.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2322790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7471008.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9660452.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1221584.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8576082.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2863675.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9117704.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4020830.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8125324.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4754449.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5950417.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5307744.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3115285.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3088379.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4920751.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5119482.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5790306.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1934729.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6202892.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2451939.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7634666.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9557261.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8273004.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8910993.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9732955.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7101743.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4851823.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7712066.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5427875.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9202945.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3318295.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9446712.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8886370.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8591006.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2367733.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9978709.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8681950.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5355921.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2409644.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3835051.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4140446.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1083381.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1240078.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1697361.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2383877.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7610339.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1028884.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6503011.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7089844.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2941870.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7618709.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5920200.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1421198.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8418013.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4876253.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4156068.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7866509.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5372701.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2057780.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7964206.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8811449.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4579846.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1043830.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5066347.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5373813.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4409826.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1876792.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6309145.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8731281.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4526504.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5108339.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9117641.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4934712.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2169949.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8446613.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9546020.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3980982.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1078263.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1156053.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2403619.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3391048.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3393075.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2845252.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9911780.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7660191.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3217652.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4608403.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5065992.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1193519.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7047241.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1729904.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9135360.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4552645.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2720985.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9099938.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4948063.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7275007.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4334060.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3836387.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7713677.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2798156.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7456394.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4158076.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2508337.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5141706.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9737254.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9159041.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1079022.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5737820.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9354544.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1926714.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1534502.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7613515.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7716475.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9019497.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8973044.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9670147.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3359330.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9210978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5187030.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4599311.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2714189.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6902978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7413272.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2435681.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6572152.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7982186.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5993965.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2500357.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5479776.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7186580.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7402199.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9589537.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3489613.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1668690.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4983537.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1118203.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4701540.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8748658.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4041565.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6844579.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6917279.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9718844.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7922466.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3985779.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9173853.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3235723.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8906514.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4829242.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4446564.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2040045.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6085966.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9489655.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8967007.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A5820641.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4142928.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8003898.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9996113.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3210894.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7753593.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4972172.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3295739.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9308379.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1318134.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7661780.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3358872.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1413840.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8642137.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8711637.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5364006.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1789764.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5016696.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1395579.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8886409.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4253546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9287191.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3757669.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9112290.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4702045.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8076648.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9246498.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5461595.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1933795.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9875520.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4448653.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9004026.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6093762.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3327755.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9908372.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4275024.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8129868.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1718920.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2917969.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1623011.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8929484.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3188277.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6018428.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1870996.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6419904.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9573047.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4412913.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6296657.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1871684.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8427029.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8574729.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5441820.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2558600.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4108541.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7959201.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3427494.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9117138.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7939800.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4901325.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7501654.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9956088.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3531622.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7966542.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9502807.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4871345.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7898190.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7853094.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8644260.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6948141.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1700043.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7515247.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8895675.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2394062.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2890431.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6357196.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6073166.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8911052.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4927647.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5111661.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1993625.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2476060.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6816073.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2782672.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7152008.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2687712.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7057168.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7843997.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2954058.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9168966.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7697729.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6690047.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7129546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2637358.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9040381.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7740096.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5724975.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2450851.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9772561.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6510847.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7169708.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1618341.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9745612.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9709886.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1284909.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8407165.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9912285.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2290343.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7231820.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4966648.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4628666.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1671798.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7723042.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7626122.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4767145.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3380989.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2952476.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8298365.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9013649.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1244742.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4253815.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1641284.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9353452.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3056643.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9671886.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8988325.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9326552.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5431671.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4067284.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4891812.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5276709.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2776936.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2838918.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5455160.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3450950.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8536809.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3390120.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9124658.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6747652.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A9244386.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1688647.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8541934.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5477912.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8175756.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8318852.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1288479.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6059132.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8843456.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2048619.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9747290.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9308115.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2995947.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6752846.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4327070.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8486767.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3815721.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7904692.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5081843.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6508431.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4333463.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5884357.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A1982652.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1216927.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9202380.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5144338.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8597214.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7888485.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3830896.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6528984.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1271119.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8667916.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3680990.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3147625.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6083627.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4422019.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7689672.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4583989.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6751293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4847332.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2419078.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3184311.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5018237.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3566346.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3586112.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5814201.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3973695.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9156072.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4793217.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3137177.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9777276.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1568503.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4433258.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7355946.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9922326.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9259278.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8590181.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4633495.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2526009.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5728540.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3987178.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2126237.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7321754.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6623364.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2719187.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6057985.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2983939.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5352071.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5978612.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9629344.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9918667.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3833613.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8559542.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1206474.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9390023.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7802977.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3740143.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4890645.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6335616.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3037215.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5968242.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3418338.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9612444.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7832568.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3549405.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9185546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4502237.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2995044.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5896690.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6779215.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6404770.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8174452.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4145582.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5441965.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6345847.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6003771.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1461010.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5364143.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5597432.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5091843.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2541564.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6671547.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7944825.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7692897.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4470790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4138548.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7892088.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1289287.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3901953.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8488779.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4960323.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8206738.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9676355.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9503200.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3560292.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9946964.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4359696.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7141331.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2104346.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9185116.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6039660.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1728883.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6022186.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2308951.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5247111.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1748282.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3582151.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3788391.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5754661.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6291487.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7774526.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8158497.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5589586.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3139493.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4751132.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6676328.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5175035.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9333615.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7050212.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A3519492.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7580056.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3661985.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6743304.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6610404.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3301722.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3357142.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8806949.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6460431.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8043013.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1375238.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4253053.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5063283.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1540585.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1999697.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2167392.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3119926.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1934545.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2106681.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3674284.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1523785.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9814208.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8610256.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7468784.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6835482.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9103340.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6949838.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9507994.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5554278.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8185369.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1606867.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8784888.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1463353.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5045535.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5142468.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9660405.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5733971.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6317049.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7485618.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6118571.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7373209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1817669.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4197023.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2382227.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7674490.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5898909.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7473598.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8609077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9083877.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1092528.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7146270.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7664869.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1850248.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8049760.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2160729.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6734147.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3507878.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9739358.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4028807.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9388297.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5537306.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4708223.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9479143.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7436184.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5906670.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5657952.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6246324.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2046129.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7916181.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8445984.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2282515.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3009039.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9176610.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A7589780.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5834463.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7080274.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A1935359.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1838983.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9158742.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3785327.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6274255.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2127758.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9088738.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6874874.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8543231.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4444918.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8028789.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2150665.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6108822.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7907790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8580705.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7285341.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3155136.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7360075.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4007647.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8344107.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4288383.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8909209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7664490.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5580573.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4715041.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2064408.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9674915.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9640549.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5896917.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3339989.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9121231.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9986902.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4929032.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5545890.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9648179.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4069808.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3113306.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7611590.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A3429891.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1165621.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9834344.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6245158.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3559281.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2513469.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9495764.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4779360.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7638307.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6939239.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5020435.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1099734.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8140273.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9837991.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1487514.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8575303.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3925671.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7142399.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1559989.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7190546.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9374849.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6412923.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4344620.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8002698.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9461089.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4436324.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2675740.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1679039.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8957409.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8737617.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9283613.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1450599.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5196733.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1859069.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1921439.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4074369.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3683191.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4266960.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3023578.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1057598.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8778256.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8421796.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1347934.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A3324898.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7213639.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3386735.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3575244.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3931632.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1310046.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2903212.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5780214.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2609898.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6408587.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2566139.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5518445.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7885063.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9602385.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4855837.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3589526.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1309288.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4093617.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8089497.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1715095.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3092666.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6991756.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6295305.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2700037.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5916365.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1384915.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9519436.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3581116.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9397477.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8453446.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7728823.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3821946.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1353832.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7059658.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5504489.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6755842.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1568692.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8626671.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9307521.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3516785.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2818383.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A5742757.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6395067.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9607187.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9592286.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8951861.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5334566.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2329534.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4256969.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6347712.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7331996.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3099929.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4969293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4464911.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3313524.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5909839.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9563293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2048072.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2812624.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7459036.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2724138.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9297345.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3259005.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9888668.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8769502.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9931731.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1811752.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9705372.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9880258.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6247470.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5569910.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2194928.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3097034.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1057127.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9604251.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3648979.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5278039.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9935772.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4332049.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3366977.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8039177.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9662087.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3992511.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6206185.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7420545.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4198293.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1861903.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6257020.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5483178.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7284946.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2482109.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7013918.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1219410.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8872130.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5642746.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3858865.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6469978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6265151.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9556974.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8842586.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7268232.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2260269.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9523874.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6418092.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1827660.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3354806.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8230962.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7296078.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2802274.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2652576.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9700873.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4966865.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5818449.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4121102.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7401648.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6079615.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1921985.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4373945.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8560414.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7660596.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6515468.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9396636.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5795153.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2911690.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8067777.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8506338.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5797494.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6956221.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7319910.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7665794.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1570308.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9285682.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4423063.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7926472.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4363046.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6151908.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7465159.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3194080.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6104047.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7852328.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3556748.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A1198708.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9855591.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8730644.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3424715.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5261998.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9862318.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6035751.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9319246.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9261616.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4058590.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2140409.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9021295.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7038432.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2759721.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4449445.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9972979.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1409260.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A9618678.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8690496.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5891944.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4673399.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1986020.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6933458.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3081699.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8021394.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9381370.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7244977.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3261200.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4143544.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6616568.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7342738.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6208748.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7166150.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3442469.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2266094.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5750730.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6724281.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3283593.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8966991.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3960451.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9731857.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2370222.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7197515.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6602481.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2896418.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1250756.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8695694.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3566254.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1833859.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1978790.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3397718.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2084430.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1076103.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4037834.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8052710.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1798572.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4451075.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2434244.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1681431.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2871920.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6304059.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4005416.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9291442.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9462133.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6841956.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5931295.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8458123.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4236942.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1669255.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1479861.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3468082.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1797687.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6993911.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7768417.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3427139.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1325867.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7533772.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7772919.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9655177.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6720738.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6546323.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1159172.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7387272.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4448254.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5342499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9565594.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9562251.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7649028.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2052756.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5874441.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6336128.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1732535.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6045900.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4486502.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1569650.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6196655.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9061872.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7878239.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8895272.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9783870.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9218365.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6501702.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1770746.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4546981.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2510029.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7258057.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9350383.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2318510.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4015945.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9207993.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2767223.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1795710.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5033976.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7854356.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9814064.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1702479.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6355056.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5214031.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6193457.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9668259.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7919448.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9294210.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5438542.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6813363.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8025292.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6396077.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1212933.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7479316.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8525634.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9665484.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3252075.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2272891.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3768468.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8297881.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9391665.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1632342.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2339758.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6699724.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7517368.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4271876.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1572159.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5827166.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6024906.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6069880.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7679021.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3032943.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2036102.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5429353.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4275566.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7033291.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9734643.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9865961.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1135316.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7921421.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2539651.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1939320.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3361924.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6610003.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4704980.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1554591.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5070552.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1400554.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2517353.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7322085.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3285502.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3403173.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9006109.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2691384.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5926946.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8210341.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1442727.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6649596.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2239590.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5407651.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4625845.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7491122.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4994533.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2811634.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2368757.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3788796.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6171281.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3959679.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3641037.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A8093886.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4498459.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3133499.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3530988.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8393759.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3603244.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2176184.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9783935.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2205806.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2088556.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8750053.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1925753.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6083220.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6714322.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8284254.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9999177.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5881552.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8702670.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2978926.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8707188.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6041806.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8184201.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8166068.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9466465.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9160814.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2623209.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6887626.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6570704.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2616147.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1881468.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5625047.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8451247.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6438218.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9308512.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8174956.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7708650.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1529808.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6726253.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7971395.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1246397.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5230978.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3879457.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8145358.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1988878.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6053092.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5984062.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7995881.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2330129.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2595238.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8440006.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5731366.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2684186.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1796079.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1671370.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_1041335.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6235489.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A9936942.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2293884.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3586145.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8161607.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2037343.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9297083.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4895040.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6901196.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2810025.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7605750.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_5975427.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7354253.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_7144867.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9035669.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9454144.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_2804436.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_3595769.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_8012948.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_4492957.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_6105590.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_9008117.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/flac/LA_E_A7299292.flac  \n",
            "  inflating: LA/ASVspoof2019_LA_eval/LICENSE.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U nobuco"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHllF11aRWVv",
        "outputId": "670ee3e6-3df6-4a7b-a0e4-43fc6e3754f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nobuco\n",
            "  Downloading nobuco-0.17.0-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m858.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sty>=1.0.0 (from nobuco)\n",
            "  Downloading sty-1.0.6-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.11/dist-packages (from nobuco) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from nobuco) (13.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from nobuco) (2.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->nobuco) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->nobuco) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->nobuco) (0.1.2)\n",
            "Downloading nobuco-0.17.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sty-1.0.6-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: sty, nobuco\n",
            "Successfully installed nobuco-0.17.0 sty-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'keras<3.0.0' mediapipe-model-maker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eEHgFQby2UI6",
        "outputId": "68615a85-988f-4712-9181-640cc6b08f58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "8529f1b65608414b86aa2329b9fb8f89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting keras<3.0.0',\n",
              " '  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)',\n",
              " 'Collecting mediapipe-model-maker',\n",
              " '  Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl.metadata (1.7 kB)',\n",
              " 'Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (1.4.0)',\n",
              " 'Collecting mediapipe>=0.10.0 (from mediapipe-model-maker)',\n",
              " '  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)',\n",
              " 'Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (2.0.2)',\n",
              " 'Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (4.12.0.88)',\n",
              " 'Collecting tensorflow<2.16,>=2.10 (from mediapipe-model-maker)',\n",
              " '  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)',\n",
              " 'Collecting tensorflow-addons (from mediapipe-model-maker)',\n",
              " '  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)',\n",
              " 'Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (4.9.9)',\n",
              " 'Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (0.16.1)',\n",
              " 'Collecting tensorflow-model-optimization<0.8.0 (from mediapipe-model-maker)',\n",
              " '  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)',\n",
              " 'Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (2.18.1)',\n",
              " 'Collecting tf-models-official<2.16.0,>=2.13.2 (from mediapipe-model-maker)',\n",
              " '  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)',\n",
              " 'Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (25.3.0)',\n",
              " 'Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (25.2.10)',\n",
              " 'Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.5.2)',\n",
              " 'Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.5.1)',\n",
              " 'Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.10.0)',\n",
              " 'Collecting numpy (from mediapipe-model-maker)',\n",
              " '  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)',\n",
              " '\\x1b[?25l     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/61.0 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m10.2/61.0 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━\\x1b[0m \\x1b[32m41.0/61.0 kB\\x1b[0m \\x1b[31m529.8 kB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m61.0/61.0 kB\\x1b[0m \\x1b[31m699.6 kB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.12.0.88)',\n",
              " 'Collecting protobuf<5,>=4.25.3 (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)',\n",
              " 'Collecting sounddevice>=0.4.4 (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)',\n",
              " 'Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.2.0)',\n",
              " 'Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.6.3)',\n",
              " 'Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.6.0)',\n",
              " 'Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.2.0)',\n",
              " 'Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.14.0)',\n",
              " 'Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (18.1.1)',\n",
              " 'Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)',\n",
              " '  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)',\n",
              " 'Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.4.0)',\n",
              " 'Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (25.0)',\n",
              " 'Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (75.2.0)',\n",
              " 'Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.17.0)',\n",
              " 'Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.1.0)',\n",
              " 'Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.14.1)',\n",
              " 'Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)',\n",
              " '  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)',\n",
              " 'Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.37.1)',\n",
              " 'Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.74.0)',\n",
              " 'Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)',\n",
              " '  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)',\n",
              " 'Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)',\n",
              " '  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)',\n",
              " 'Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization<0.8.0->mediapipe-model-maker) (0.1.9)',\n",
              " 'Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.0.12)',\n",
              " 'Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (11.3.0)',\n",
              " 'Requirement already satisfied: gin-config in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.0)',\n",
              " 'Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.177.0)',\n",
              " 'Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.2.1)',\n",
              " 'Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.7.4.5)',\n",
              " 'Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.3)',\n",
              " 'Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.12.0.88)',\n",
              " 'Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.2.2)',\n",
              " 'Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.9.5)',\n",
              " 'Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (9.0.0)',\n",
              " 'Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.0.10)',\n",
              " 'Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.0.2)',\n",
              " 'Collecting sacrebleu (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)',\n",
              " '  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)',\n",
              " '\\x1b[?25l     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/51.8 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m51.8/51.8 kB\\x1b[0m \\x1b[31m2.0 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.16.0)',\n",
              " 'Collecting seqeval (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)',\n",
              " '  Downloading seqeval-1.2.2.tar.gz (43 kB)',\n",
              " '\\x1b[?25l     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/43.6 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m43.6/43.6 kB\\x1b[0m \\x1b[31m2.4 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25h  Preparing metadata (setup.py) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " 'Collecting tensorflow-text (from mediapipe-model-maker)',\n",
              " '  Downloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)',\n",
              " 'Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.1.0)',\n",
              " 'Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub->mediapipe-model-maker) (2.18.0)',\n",
              " 'INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.',\n",
              " 'Collecting opencv-python (from mediapipe-model-maker)',\n",
              " '  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)',\n",
              " 'Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->mediapipe-model-maker)',\n",
              " '  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)',\n",
              " 'Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.7.2)',\n",
              " 'Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (1.13.0)',\n",
              " 'Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)',\n",
              " 'Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (18.1.0)',\n",
              " 'Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.32.3)',\n",
              " 'Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.7)',\n",
              " 'Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.17.2)',\n",
              " 'Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)',\n",
              " 'Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (4.67.1)',\n",
              " 'Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.45.1)',\n",
              " 'Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (0.8.1)',\n",
              " 'Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (2025.3.0)',\n",
              " 'Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (6.5.2)',\n",
              " 'Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (3.23.0)',\n",
              " 'Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.22.0)',\n",
              " 'Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.38.0)',\n",
              " 'Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.2.0)',\n",
              " 'Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.25.1)',\n",
              " 'Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.2.0)',\n",
              " 'Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.2.0)',\n",
              " 'Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.7.14)',\n",
              " 'Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.4.2)',\n",
              " 'Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.10)',\n",
              " 'Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.9.0.post0)',\n",
              " 'Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (8.0.4)',\n",
              " 'Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.3)',\n",
              " 'Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.5.0)',\n",
              " 'Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.1)',\n",
              " 'Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.2)',\n",
              " 'Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.2)',\n",
              " 'Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (1.17.1)',\n",
              " 'Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.2.2)',\n",
              " 'Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.8.2)',\n",
              " 'Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.7.2)',\n",
              " 'Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.1.3)',\n",
              " 'INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.',\n",
              " 'Collecting tf-keras>=2.14.1 (from tensorflow-hub->mediapipe-model-maker)',\n",
              " '  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)',\n",
              " '  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)',\n",
              " '  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)',\n",
              " '  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)',\n",
              " 'INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.',\n",
              " 'Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jax-0.7.0-py3-none-any.whl.metadata (13 kB)',\n",
              " 'Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jaxlib-0.7.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)',\n",
              " 'Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)',\n",
              " 'Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jaxlib-0.6.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)',\n",
              " 'Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)',\n",
              " 'Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)',\n",
              " 'Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)',\n",
              " 'Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)',\n",
              " 'Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)',\n",
              " 'Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)',\n",
              " 'Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)',\n",
              " '  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)',\n",
              " 'Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)',\n",
              " 'INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.',\n",
              " 'Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)',\n",
              " 'Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)',\n",
              " 'Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)',\n",
              " 'Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)',\n",
              " 'Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)',\n",
              " '  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)',\n",
              " 'Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)',\n",
              " 'Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)',\n",
              " 'Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)',\n",
              " 'Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.3.2)',\n",
              " 'Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (0.12.1)',\n",
              " 'Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (4.59.0)',\n",
              " 'Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.4.8)',\n",
              " 'Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (3.2.3)',\n",
              " 'Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.6.1)',\n",
              " 'Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.4.2)',\n",
              " 'Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.9.1)',\n",
              " 'INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.',\n",
              " 'Collecting opencv-contrib-python (from mediapipe>=0.10.0->mediapipe-model-maker)',\n",
              " '  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)',\n",
              " 'INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.',\n",
              " 'Collecting opencv-python-headless (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)',\n",
              " '  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)',\n",
              " 'Collecting portalocker (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)',\n",
              " '  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)',\n",
              " 'Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.11.6)',\n",
              " 'Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.9.0)',\n",
              " 'Collecting colorama (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)',\n",
              " '  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)',\n",
              " 'Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.4.0)',\n",
              " 'Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.6.1)',\n",
              " 'Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->mediapipe-model-maker) (0.17.0)',\n",
              " 'Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets->mediapipe-model-maker) (1.70.0)',\n",
              " 'Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.22)',\n",
              " 'Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.26.1)',\n",
              " 'Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.5.2)',\n",
              " 'Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.0.0)',\n",
              " 'Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.5.1)',\n",
              " 'Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.6.0)',\n",
              " 'Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.0.2)',\n",
              " 'Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.3.1)',\n",
              " 'Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/1.7 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.1/1.7 MB\\x1b[0m \\x1b[31m3.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.2/1.7 MB\\x1b[0m \\x1b[31m2.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.3/1.7 MB\\x1b[0m \\x1b[31m3.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.6/1.7 MB\\x1b[0m \\x1b[31m4.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.9/1.7 MB\\x1b[0m \\x1b[31m5.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━\\x1b[0m \\x1b[32m1.5/1.7 MB\\x1b[0m \\x1b[31m7.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m1.7/1.7 MB\\x1b[0m \\x1b[31m7.1 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl (133 kB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/133.3 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m133.3/133.3 kB\\x1b[0m \\x1b[31m14.7 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/35.6 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m1.8/35.6 MB\\x1b[0m \\x1b[31m70.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m3.0/35.6 MB\\x1b[0m \\x1b[31m43.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m5.4/35.6 MB\\x1b[0m \\x1b[31m60.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m8.5/35.6 MB\\x1b[0m \\x1b[31m61.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m10.5/35.6 MB\\x1b[0m \\x1b[31m59.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m13.5/35.6 MB\\x1b[0m \\x1b[31m79.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m15.7/35.6 MB\\x1b[0m \\x1b[31m77.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m17.6/35.6 MB\\x1b[0m \\x1b[31m79.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m21.6/35.6 MB\\x1b[0m \\x1b[31m79.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━\\x1b[0m \\x1b[32m23.3/35.6 MB\\x1b[0m \\x1b[31m68.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━\\x1b[0m \\x1b[32m25.5/35.6 MB\\x1b[0m \\x1b[31m77.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━\\x1b[0m \\x1b[32m28.8/35.6 MB\\x1b[0m \\x1b[31m75.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━\\x1b[0m \\x1b[32m30.9/35.6 MB\\x1b[0m \\x1b[31m67.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m33.0/35.6 MB\\x1b[0m \\x1b[31m75.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m35.6/35.6 MB\\x1b[0m \\x1b[31m67.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m35.6/35.6 MB\\x1b[0m \\x1b[31m67.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m35.6/35.6 MB\\x1b[0m \\x1b[31m67.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m35.6/35.6 MB\\x1b[0m \\x1b[31m40.4 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/18.3 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m4.1/18.3 MB\\x1b[0m \\x1b[31m232.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m6.3/18.3 MB\\x1b[0m \\x1b[31m92.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m6.8/18.3 MB\\x1b[0m \\x1b[31m93.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m10.2/18.3 MB\\x1b[0m \\x1b[31m82.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━\\x1b[0m \\x1b[32m12.3/18.3 MB\\x1b[0m \\x1b[31m62.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━\\x1b[0m \\x1b[32m14.1/18.3 MB\\x1b[0m \\x1b[31m61.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━\\x1b[0m \\x1b[32m17.4/18.3 MB\\x1b[0m \\x1b[31m79.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━\\x1b[0m \\x1b[32m17.8/18.3 MB\\x1b[0m \\x1b[31m61.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m18.2/18.3 MB\\x1b[0m \\x1b[31m60.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m18.3/18.3 MB\\x1b[0m \\x1b[31m46.7 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/475.3 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m4.1/475.3 MB\\x1b[0m \\x1b[31m157.7 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m5.7/475.3 MB\\x1b[0m \\x1b[31m84.0 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m6.4/475.3 MB\\x1b[0m \\x1b[31m87.3 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m9.9/475.3 MB\\x1b[0m \\x1b[31m74.6 MB/s\\x1b[0m eta \\x1b[36m0:00:07\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m10.9/475.3 MB\\x1b[0m \\x1b[31m60.7 MB/s\\x1b[0m eta \\x1b[36m0:00:08\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m13.2/475.3 MB\\x1b[0m \\x1b[31m60.1 MB/s\\x1b[0m eta \\x1b[36m0:00:08\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m16.3/475.3 MB\\x1b[0m \\x1b[31m61.0 MB/s\\x1b[0m eta \\x1b[36m0:00:08\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m16.6/475.3 MB\\x1b[0m \\x1b[31m49.6 MB/s\\x1b[0m eta \\x1b[36m0:00:10\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m20.1/475.3 MB\\x1b[0m \\x1b[31m59.9 MB/s\\x1b[0m eta \\x1b[36m0:00:08\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m22.8/475.3 MB\\x1b[0m \\x1b[31m62.6 MB/s\\x1b[0m eta \\x1b[36m0:00:08\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m23.2/475.3 MB\\x1b[0m \\x1b[31m62.1 MB/s\\x1b[0m eta \\x1b[36m0:00:08\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m26.9/475.3 MB\\x1b[0m \\x1b[31m79.6 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m28.6/475.3 MB\\x1b[0m \\x1b[31m62.7 MB/s\\x1b[0m eta \\x1b[36m0:00:08\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m30.6/475.3 MB\\x1b[0m \\x1b[31m75.7 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m34.0/475.3 MB\\x1b[0m \\x1b[31m79.0 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m34.8/475.3 MB\\x1b[0m \\x1b[31m62.2 MB/s\\x1b[0m eta \\x1b[36m0:00:08\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m37.9/475.3 MB\\x1b[0m \\x1b[31m77.5 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m40.9/475.3 MB\\x1b[0m \\x1b[31m77.8 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m41.2/475.3 MB\\x1b[0m \\x1b[31m76.9 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m45.0/475.3 MB\\x1b[0m \\x1b[31m76.3 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m47.3/475.3 MB\\x1b[0m \\x1b[31m63.0 MB/s\\x1b[0m eta \\x1b[36m0:00:07\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m48.6/475.3 MB\\x1b[0m \\x1b[31m76.4 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m52.6/475.3 MB\\x1b[0m \\x1b[31m80.9 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m54.2/475.3 MB\\x1b[0m \\x1b[31m65.8 MB/s\\x1b[0m eta \\x1b[36m0:00:07\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m56.6/475.3 MB\\x1b[0m \\x1b[31m80.2 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m60.1/475.3 MB\\x1b[0m \\x1b[31m80.2 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m60.6/475.3 MB\\x1b[0m \\x1b[31m64.4 MB/s\\x1b[0m eta \\x1b[36m0:00:07\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m64.6/475.3 MB\\x1b[0m \\x1b[31m80.4 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m66.9/475.3 MB\\x1b[0m \\x1b[31m81.2 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m68.4/475.3 MB\\x1b[0m \\x1b[31m79.6 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m72.6/475.3 MB\\x1b[0m \\x1b[31m79.6 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m73.4/475.3 MB\\x1b[0m \\x1b[31m64.3 MB/s\\x1b[0m eta \\x1b[36m0:00:07\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m76.5/475.3 MB\\x1b[0m \\x1b[31m79.8 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m79.6/475.3 MB\\x1b[0m \\x1b[31m81.0 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m80.6/475.3 MB\\x1b[0m \\x1b[31m80.1 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m84.4/475.3 MB\\x1b[0m \\x1b[31m79.5 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m86.2/475.3 MB\\x1b[0m \\x1b[31m64.6 MB/s\\x1b[0m eta \\x1b[36m0:00:07\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m88.3/475.3 MB\\x1b[0m \\x1b[31m79.8 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m92.3/475.3 MB\\x1b[0m \\x1b[31m80.5 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m93.1/475.3 MB\\x1b[0m \\x1b[31m64.7 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m96.3/475.3 MB\\x1b[0m \\x1b[31m80.0 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m99.0/475.3 MB\\x1b[0m \\x1b[31m79.6 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m100.3/475.3 MB\\x1b[0m \\x1b[31m79.9 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m104.2/475.3 MB\\x1b[0m \\x1b[31m79.1 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m105.6/475.3 MB\\x1b[0m \\x1b[31m64.5 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m108.1/475.3 MB\\x1b[0m \\x1b[31m79.4 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m111.2/475.3 MB\\x1b[0m \\x1b[31m76.9 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m112.9/475.3 MB\\x1b[0m \\x1b[31m65.7 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m115.4/475.3 MB\\x1b[0m \\x1b[31m77.0 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m118.4/475.3 MB\\x1b[0m \\x1b[31m78.2 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m119.4/475.3 MB\\x1b[0m \\x1b[31m77.0 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m123.4/475.3 MB\\x1b[0m \\x1b[31m76.9 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m125.1/475.3 MB\\x1b[0m \\x1b[31m64.8 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m127.3/475.3 MB\\x1b[0m \\x1b[31m77.2 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m130.8/475.3 MB\\x1b[0m \\x1b[31m78.1 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m132.1/475.3 MB\\x1b[0m \\x1b[31m64.9 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m133.4/475.3 MB\\x1b[0m \\x1b[31m58.1 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m136.0/475.3 MB\\x1b[0m \\x1b[31m59.9 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m137.5/475.3 MB\\x1b[0m \\x1b[31m53.9 MB/s\\x1b[0m eta \\x1b[36m0:00:07\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m140.9/475.3 MB\\x1b[0m \\x1b[31m61.0 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m142.3/475.3 MB\\x1b[0m \\x1b[31m58.3 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m145.8/475.3 MB\\x1b[0m \\x1b[31m74.2 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m148.7/475.3 MB\\x1b[0m \\x1b[31m81.6 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m150.0/475.3 MB\\x1b[0m \\x1b[31m68.1 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m153.1/475.3 MB\\x1b[0m \\x1b[31m76.8 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m155.0/475.3 MB\\x1b[0m \\x1b[31m63.3 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m157.7/475.3 MB\\x1b[0m \\x1b[31m70.4 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m160.8/475.3 MB\\x1b[0m \\x1b[31m80.8 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m162.6/475.3 MB\\x1b[0m \\x1b[31m66.2 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m165.3/475.3 MB\\x1b[0m \\x1b[31m76.6 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m167.8/475.3 MB\\x1b[0m \\x1b[31m72.8 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m169.9/475.3 MB\\x1b[0m \\x1b[31m69.9 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m172.9/475.3 MB\\x1b[0m \\x1b[31m74.1 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m175.3/475.3 MB\\x1b[0m \\x1b[31m70.2 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m177.2/475.3 MB\\x1b[0m \\x1b[31m69.3 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m180.3/475.3 MB\\x1b[0m \\x1b[31m75.6 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m182.6/475.3 MB\\x1b[0m \\x1b[31m72.0 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m184.0/475.3 MB\\x1b[0m \\x1b[31m69.0 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m187.1/475.3 MB\\x1b[0m \\x1b[31m69.1 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m188.2/475.3 MB\\x1b[0m \\x1b[31m61.5 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m192.0/475.3 MB\\x1b[0m \\x1b[31m70.9 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m194.6/475.3 MB\\x1b[0m \\x1b[31m81.3 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m196.2/475.3 MB\\x1b[0m \\x1b[31m72.9 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m199.5/475.3 MB\\x1b[0m \\x1b[31m76.7 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m200.8/475.3 MB\\x1b[0m \\x1b[31m62.9 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m204.1/475.3 MB\\x1b[0m \\x1b[31m73.9 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m206.7/475.3 MB\\x1b[0m \\x1b[31m78.1 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m208.5/475.3 MB\\x1b[0m \\x1b[31m66.3 MB/s\\x1b[0m eta \\x1b[36m0:00:05\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m211.8/475.3 MB\\x1b[0m \\x1b[31m77.8 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m213.4/475.3 MB\\x1b[0m \\x1b[31m65.9 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m216.0/475.3 MB\\x1b[0m \\x1b[31m75.1 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m218.9/475.3 MB\\x1b[0m \\x1b[31m74.4 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m220.9/475.3 MB\\x1b[0m \\x1b[31m68.3 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m223.9/475.3 MB\\x1b[0m \\x1b[31m76.4 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m226.1/475.3 MB\\x1b[0m \\x1b[31m68.0 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m228.2/475.3 MB\\x1b[0m \\x1b[31m68.5 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m231.3/475.3 MB\\x1b[0m \\x1b[31m74.9 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m233.3/475.3 MB\\x1b[0m \\x1b[31m68.0 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m235.7/475.3 MB\\x1b[0m \\x1b[31m76.3 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m238.8/475.3 MB\\x1b[0m \\x1b[31m75.6 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m241.0/475.3 MB\\x1b[0m \\x1b[31m69.5 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m243.8/475.3 MB\\x1b[0m \\x1b[31m76.1 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m246.2/475.3 MB\\x1b[0m \\x1b[31m74.7 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m248.4/475.3 MB\\x1b[0m \\x1b[31m69.8 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m251.3/475.3 MB\\x1b[0m \\x1b[31m75.2 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m253.4/475.3 MB\\x1b[0m \\x1b[31m69.6 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m255.5/475.3 MB\\x1b[0m \\x1b[31m74.4 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m257.9/475.3 MB\\x1b[0m \\x1b[31m68.8 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m257.9/475.3 MB\\x1b[0m \\x1b[31m68.8 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m257.9/475.3 MB\\x1b[0m \\x1b[31m68.8 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m257.9/475.3 MB\\x1b[0m \\x1b[31m68.8 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m258.0/475.3 MB\\x1b[0m \\x1b[31m36.0 MB/s\\x1b[0m eta \\x1b[36m0:00:07\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m262.0/475.3 MB\\x1b[0m \\x1b[31m41.4 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m264.3/475.3 MB\\x1b[0m \\x1b[31m37.3 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m265.6/475.3 MB\\x1b[0m \\x1b[31m38.6 MB/s\\x1b[0m eta \\x1b[36m0:00:06\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m269.0/475.3 MB\\x1b[0m \\x1b[31m81.3 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m270.3/475.3 MB\\x1b[0m \\x1b[31m62.6 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m272.9/475.3 MB\\x1b[0m \\x1b[31m81.2 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m276.7/475.3 MB\\x1b[0m \\x1b[31m80.2 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m276.7/475.3 MB\\x1b[0m \\x1b[31m80.2 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m280.4/475.3 MB\\x1b[0m \\x1b[31m81.5 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m282.8/475.3 MB\\x1b[0m \\x1b[31m62.9 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m284.3/475.3 MB\\x1b[0m \\x1b[31m80.4 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m287.9/475.3 MB\\x1b[0m \\x1b[31m81.2 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m289.0/475.3 MB\\x1b[0m \\x1b[31m63.2 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m291.9/475.3 MB\\x1b[0m \\x1b[31m80.9 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m295.4/475.3 MB\\x1b[0m \\x1b[31m80.5 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m295.5/475.3 MB\\x1b[0m \\x1b[31m79.7 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m299.5/475.3 MB\\x1b[0m \\x1b[31m82.9 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m301.7/475.3 MB\\x1b[0m \\x1b[31m63.8 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m303.4/475.3 MB\\x1b[0m \\x1b[31m81.5 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m307.1/475.3 MB\\x1b[0m \\x1b[31m81.3 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m307.8/475.3 MB\\x1b[0m \\x1b[31m63.2 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━\\x1b[0m \\x1b[32m311.1/475.3 MB\\x1b[0m \\x1b[31m81.2 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━\\x1b[0m \\x1b[32m314.4/475.3 MB\\x1b[0m \\x1b[31m81.6 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━\\x1b[0m \\x1b[32m315.1/475.3 MB\\x1b[0m \\x1b[31m80.5 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━\\x1b[0m \\x1b[32m318.7/475.3 MB\\x1b[0m \\x1b[31m82.0 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━\\x1b[0m \\x1b[32m320.8/475.3 MB\\x1b[0m \\x1b[31m63.3 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━\\x1b[0m \\x1b[32m322.7/475.3 MB\\x1b[0m \\x1b[31m81.5 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━\\x1b[0m \\x1b[32m326.6/475.3 MB\\x1b[0m \\x1b[31m80.4 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━\\x1b[0m \\x1b[32m327.3/475.3 MB\\x1b[0m \\x1b[31m63.6 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━\\x1b[0m \\x1b[32m330.5/475.3 MB\\x1b[0m \\x1b[31m79.6 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━\\x1b[0m \\x1b[32m333.5/475.3 MB\\x1b[0m \\x1b[31m80.7 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━\\x1b[0m \\x1b[32m334.2/475.3 MB\\x1b[0m \\x1b[31m80.1 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━\\x1b[0m \\x1b[32m338.2/475.3 MB\\x1b[0m \\x1b[31m81.0 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━\\x1b[0m \\x1b[32m340.0/475.3 MB\\x1b[0m \\x1b[31m64.6 MB/s\\x1b[0m eta \\x1b[36m0:00:03\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━\\x1b[0m \\x1b[32m342.2/475.3 MB\\x1b[0m \\x1b[31m81.2 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m346.2/475.3 MB\\x1b[0m \\x1b[31m80.3 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m346.9/475.3 MB\\x1b[0m \\x1b[31m64.3 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m349.9/475.3 MB\\x1b[0m \\x1b[31m73.5 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m352.5/475.3 MB\\x1b[0m \\x1b[31m79.8 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m353.4/475.3 MB\\x1b[0m \\x1b[31m73.2 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m353.4/475.3 MB\\x1b[0m \\x1b[31m73.2 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m353.4/475.3 MB\\x1b[0m \\x1b[31m73.2 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m353.4/475.3 MB\\x1b[0m \\x1b[31m73.2 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m353.4/475.3 MB\\x1b[0m \\x1b[31m73.2 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m355.6/475.3 MB\\x1b[0m \\x1b[31m32.2 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━\\x1b[0m \\x1b[32m357.5/475.3 MB\\x1b[0m \\x1b[31m35.9 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━\\x1b[0m \\x1b[32m360.8/475.3 MB\\x1b[0m \\x1b[31m35.6 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━\\x1b[0m \\x1b[32m361.3/475.3 MB\\x1b[0m \\x1b[31m31.5 MB/s\\x1b[0m eta \\x1b[36m0:00:04\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━\\x1b[0m \\x1b[32m364.8/475.3 MB\\x1b[0m \\x1b[31m81.8 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━\\x1b[0m \\x1b[32m368.3/475.3 MB\\x1b[0m \\x1b[31m81.8 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━\\x1b[0m \\x1b[32m368.3/475.3 MB\\x1b[0m \\x1b[31m81.8 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m372.2/475.3 MB\\x1b[0m \\x1b[31m83.8 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m373.7/475.3 MB\\x1b[0m \\x1b[31m62.3 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m376.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m379.1/475.3 MB\\x1b[0m \\x1b[31m80.8 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m379.3/475.3 MB\\x1b[0m \\x1b[31m61.4 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━\\x1b[0m \\x1b[32m382.9/475.3 MB\\x1b[0m \\x1b[31m77.1 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━\\x1b[0m \\x1b[32m385.3/475.3 MB\\x1b[0m \\x1b[31m61.9 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━\\x1b[0m \\x1b[32m385.8/475.3 MB\\x1b[0m \\x1b[31m61.3 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━\\x1b[0m \\x1b[32m389.5/475.3 MB\\x1b[0m \\x1b[31m77.8 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━\\x1b[0m \\x1b[32m390.8/475.3 MB\\x1b[0m \\x1b[31m61.9 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━\\x1b[0m \\x1b[32m392.7/475.3 MB\\x1b[0m \\x1b[31m61.6 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━\\x1b[0m \\x1b[32m396.2/475.3 MB\\x1b[0m \\x1b[31m79.0 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━\\x1b[0m \\x1b[32m396.4/475.3 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━\\x1b[0m \\x1b[32m399.9/475.3 MB\\x1b[0m \\x1b[31m77.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━\\x1b[0m \\x1b[32m402.8/475.3 MB\\x1b[0m \\x1b[31m61.2 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━\\x1b[0m \\x1b[32m403.1/475.3 MB\\x1b[0m \\x1b[31m77.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━\\x1b[0m \\x1b[32m406.9/475.3 MB\\x1b[0m \\x1b[31m80.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━\\x1b[0m \\x1b[32m408.5/475.3 MB\\x1b[0m \\x1b[31m62.0 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━\\x1b[0m \\x1b[32m410.6/475.3 MB\\x1b[0m \\x1b[31m76.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━\\x1b[0m \\x1b[32m414.1/475.3 MB\\x1b[0m \\x1b[31m79.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━\\x1b[0m \\x1b[32m414.6/475.3 MB\\x1b[0m \\x1b[31m62.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━\\x1b[0m \\x1b[32m417.8/475.3 MB\\x1b[0m \\x1b[31m78.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━\\x1b[0m \\x1b[32m420.9/475.3 MB\\x1b[0m \\x1b[31m77.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━\\x1b[0m \\x1b[32m421.4/475.3 MB\\x1b[0m \\x1b[31m77.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━\\x1b[0m \\x1b[32m425.1/475.3 MB\\x1b[0m \\x1b[31m81.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━\\x1b[0m \\x1b[32m427.5/475.3 MB\\x1b[0m \\x1b[31m63.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━\\x1b[0m \\x1b[32m429.2/475.3 MB\\x1b[0m \\x1b[31m79.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━\\x1b[0m \\x1b[32m433.2/475.3 MB\\x1b[0m \\x1b[31m80.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━\\x1b[0m \\x1b[32m433.8/475.3 MB\\x1b[0m \\x1b[31m63.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━\\x1b[0m \\x1b[32m437.1/475.3 MB\\x1b[0m \\x1b[31m80.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m440.2/475.3 MB\\x1b[0m \\x1b[31m80.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m441.0/475.3 MB\\x1b[0m \\x1b[31m80.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m442.9/475.3 MB\\x1b[0m \\x1b[31m57.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m446.6/475.3 MB\\x1b[0m \\x1b[31m64.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m448.5/475.3 MB\\x1b[0m \\x1b[31m68.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m451.0/475.3 MB\\x1b[0m \\x1b[31m63.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━\\x1b[0m \\x1b[32m453.3/475.3 MB\\x1b[0m \\x1b[31m76.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━\\x1b[0m \\x1b[32m455.4/475.3 MB\\x1b[0m \\x1b[31m68.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━\\x1b[0m \\x1b[32m459.1/475.3 MB\\x1b[0m \\x1b[31m76.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━\\x1b[0m \\x1b[32m460.5/475.3 MB\\x1b[0m \\x1b[31m66.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m \\x1b[32m463.4/475.3 MB\\x1b[0m \\x1b[31m73.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m \\x1b[32m466.1/475.3 MB\\x1b[0m \\x1b[31m75.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m \\x1b[32m468.1/475.3 MB\\x1b[0m \\x1b[31m68.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m471.3/475.3 MB\\x1b[0m \\x1b[31m78.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m473.0/475.3 MB\\x1b[0m \\x1b[31m65.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m475.2/475.3 MB\\x1b[0m \\x1b[31m78.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m475.3/475.3 MB\\x1b[0m \\x1b[31m3.9 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/241.2 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m241.2/241.2 kB\\x1b[0m \\x1b[31m24.4 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/2.7 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m2.7/2.7 MB\\x1b[0m \\x1b[31m91.4 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/5.2 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m4.1/5.2 MB\\x1b[0m \\x1b[31m194.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m5.2/5.2 MB\\x1b[0m \\x1b[31m82.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m5.2/5.2 MB\\x1b[0m \\x1b[31m63.8 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/63.0 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m4.1/63.0 MB\\x1b[0m \\x1b[31m180.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m5.3/63.0 MB\\x1b[0m \\x1b[31m77.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m7.7/63.0 MB\\x1b[0m \\x1b[31m78.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m11.6/63.0 MB\\x1b[0m \\x1b[31m81.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m12.4/63.0 MB\\x1b[0m \\x1b[31m65.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m15.9/63.0 MB\\x1b[0m \\x1b[31m75.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m18.2/63.0 MB\\x1b[0m \\x1b[31m77.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m20.0/63.0 MB\\x1b[0m \\x1b[31m74.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m23.8/63.0 MB\\x1b[0m \\x1b[31m80.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m25.2/63.0 MB\\x1b[0m \\x1b[31m64.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m28.1/63.0 MB\\x1b[0m \\x1b[31m74.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m30.7/63.0 MB\\x1b[0m \\x1b[31m76.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m32.5/63.0 MB\\x1b[0m \\x1b[31m67.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m35.8/63.0 MB\\x1b[0m \\x1b[31m76.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m37.9/63.0 MB\\x1b[0m \\x1b[31m65.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m40.0/63.0 MB\\x1b[0m \\x1b[31m74.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━\\x1b[0m \\x1b[32m43.4/63.0 MB\\x1b[0m \\x1b[31m77.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━\\x1b[0m \\x1b[32m45.3/63.0 MB\\x1b[0m \\x1b[31m67.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━\\x1b[0m \\x1b[32m47.8/63.0 MB\\x1b[0m \\x1b[31m73.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━\\x1b[0m \\x1b[32m50.6/63.0 MB\\x1b[0m \\x1b[31m75.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━\\x1b[0m \\x1b[32m52.4/63.0 MB\\x1b[0m \\x1b[31m68.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━\\x1b[0m \\x1b[32m55.4/63.0 MB\\x1b[0m \\x1b[31m72.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━\\x1b[0m \\x1b[32m57.9/63.0 MB\\x1b[0m \\x1b[31m71.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━\\x1b[0m \\x1b[32m59.9/63.0 MB\\x1b[0m \\x1b[31m73.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m63.0/63.0 MB\\x1b[0m \\x1b[31m77.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m63.0/63.0 MB\\x1b[0m \\x1b[31m77.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m63.0/63.0 MB\\x1b[0m \\x1b[31m77.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m63.0/63.0 MB\\x1b[0m \\x1b[31m77.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m63.0/63.0 MB\\x1b[0m \\x1b[31m77.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m63.0/63.0 MB\\x1b[0m \\x1b[31m77.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m63.0/63.0 MB\\x1b[0m \\x1b[31m29.8 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/611.8 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m611.8/611.8 kB\\x1b[0m \\x1b[31m48.9 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/2.2 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m2.2/2.2 MB\\x1b[0m \\x1b[31m95.7 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/294.9 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m294.9/294.9 kB\\x1b[0m \\x1b[31m28.7 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)',\n",
              " 'Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/5.5 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m4.1/5.5 MB\\x1b[0m \\x1b[31m253.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m5.5/5.5 MB\\x1b[0m \\x1b[31m89.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m5.5/5.5 MB\\x1b[0m \\x1b[31m67.7 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/442.0 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m442.0/442.0 kB\\x1b[0m \\x1b[31m41.3 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/1.7 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m1.7/1.7 MB\\x1b[0m \\x1b[31m78.7 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)',\n",
              " 'Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/78.4 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m78.4/78.4 kB\\x1b[0m \\x1b[31m9.1 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading jax-0.4.34-py3-none-any.whl (2.1 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/2.1 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m2.1/2.1 MB\\x1b[0m \\x1b[31m67.2 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl (86.1 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/86.1 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m4.1/86.1 MB\\x1b[0m \\x1b[31m194.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m6.1/86.1 MB\\x1b[0m \\x1b[31m89.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m8.0/86.1 MB\\x1b[0m \\x1b[31m102.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m11.9/86.1 MB\\x1b[0m \\x1b[31m80.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m12.7/86.1 MB\\x1b[0m \\x1b[31m64.4 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m15.6/86.1 MB\\x1b[0m \\x1b[31m81.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m18.9/86.1 MB\\x1b[0m \\x1b[31m80.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m19.5/86.1 MB\\x1b[0m \\x1b[31m80.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m23.4/86.1 MB\\x1b[0m \\x1b[31m81.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m25.3/86.1 MB\\x1b[0m \\x1b[31m64.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m27.4/86.1 MB\\x1b[0m \\x1b[31m81.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m31.5/86.1 MB\\x1b[0m \\x1b[31m81.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m31.8/86.1 MB\\x1b[0m \\x1b[31m64.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m35.4/86.1 MB\\x1b[0m \\x1b[31m81.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m37.9/86.1 MB\\x1b[0m \\x1b[31m81.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m39.4/86.1 MB\\x1b[0m \\x1b[31m82.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m43.3/86.1 MB\\x1b[0m \\x1b[31m81.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m44.4/86.1 MB\\x1b[0m \\x1b[31m63.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m47.1/86.1 MB\\x1b[0m \\x1b[31m81.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m50.3/86.1 MB\\x1b[0m \\x1b[31m80.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m51.3/86.1 MB\\x1b[0m \\x1b[31m65.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m54.6/86.1 MB\\x1b[0m \\x1b[31m79.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━\\x1b[0m \\x1b[32m57.1/86.1 MB\\x1b[0m \\x1b[31m63.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━\\x1b[0m \\x1b[32m58.6/86.1 MB\\x1b[0m \\x1b[31m80.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m62.6/86.1 MB\\x1b[0m \\x1b[31m79.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m63.8/86.1 MB\\x1b[0m \\x1b[31m64.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m64.0/86.1 MB\\x1b[0m \\x1b[31m63.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m64.0/86.1 MB\\x1b[0m \\x1b[31m63.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m64.0/86.1 MB\\x1b[0m \\x1b[31m63.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m64.0/86.1 MB\\x1b[0m \\x1b[31m63.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m64.0/86.1 MB\\x1b[0m \\x1b[31m63.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m64.0/86.1 MB\\x1b[0m \\x1b[31m63.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m67.9/86.1 MB\\x1b[0m \\x1b[31m29.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m68.1/86.1 MB\\x1b[0m \\x1b[31m27.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━\\x1b[0m \\x1b[32m71.8/86.1 MB\\x1b[0m \\x1b[31m29.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━\\x1b[0m \\x1b[32m74.5/86.1 MB\\x1b[0m \\x1b[31m81.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━\\x1b[0m \\x1b[32m75.7/86.1 MB\\x1b[0m \\x1b[31m80.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━\\x1b[0m \\x1b[32m79.6/86.1 MB\\x1b[0m \\x1b[31m80.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m80.7/86.1 MB\\x1b[0m \\x1b[31m63.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m80.7/86.1 MB\\x1b[0m \\x1b[31m62.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m80.7/86.1 MB\\x1b[0m \\x1b[31m62.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m80.7/86.1 MB\\x1b[0m \\x1b[31m62.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m80.7/86.1 MB\\x1b[0m \\x1b[31m62.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m80.7/86.1 MB\\x1b[0m \\x1b[31m62.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━\\x1b[0m \\x1b[32m82.4/86.1 MB\\x1b[0m \\x1b[31m31.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m \\x1b[32m84.8/86.1 MB\\x1b[0m \\x1b[31m31.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m86.1/86.1 MB\\x1b[0m \\x1b[31m31.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m86.1/86.1 MB\\x1b[0m \\x1b[31m31.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m86.1/86.1 MB\\x1b[0m \\x1b[31m31.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m86.1/86.1 MB\\x1b[0m \\x1b[31m31.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m86.1/86.1 MB\\x1b[0m \\x1b[31m31.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m86.1/86.1 MB\\x1b[0m \\x1b[31m31.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m86.1/86.1 MB\\x1b[0m \\x1b[31m31.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m86.1/86.1 MB\\x1b[0m \\x1b[31m31.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m86.1/86.1 MB\\x1b[0m \\x1b[31m31.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m86.1/86.1 MB\\x1b[0m \\x1b[31m16.3 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/69.1 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m4.1/69.1 MB\\x1b[0m \\x1b[31m249.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m7.1/69.1 MB\\x1b[0m \\x1b[31m104.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m7.1/69.1 MB\\x1b[0m \\x1b[31m104.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m11.0/69.1 MB\\x1b[0m \\x1b[31m83.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m12.7/69.1 MB\\x1b[0m \\x1b[31m62.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m14.5/69.1 MB\\x1b[0m \\x1b[31m82.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m18.2/69.1 MB\\x1b[0m \\x1b[31m83.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m18.2/69.1 MB\\x1b[0m \\x1b[31m83.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m22.1/69.1 MB\\x1b[0m \\x1b[31m82.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m25.0/69.1 MB\\x1b[0m \\x1b[31m82.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m25.9/69.1 MB\\x1b[0m \\x1b[31m81.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m29.4/69.1 MB\\x1b[0m \\x1b[31m83.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m30.6/69.1 MB\\x1b[0m \\x1b[31m62.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m33.4/69.1 MB\\x1b[0m \\x1b[31m81.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m36.9/69.1 MB\\x1b[0m \\x1b[31m81.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m36.9/69.1 MB\\x1b[0m \\x1b[31m81.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m40.7/69.1 MB\\x1b[0m \\x1b[31m82.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m43.2/69.1 MB\\x1b[0m \\x1b[31m62.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m44.5/69.1 MB\\x1b[0m \\x1b[31m80.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━\\x1b[0m \\x1b[32m47.9/69.1 MB\\x1b[0m \\x1b[31m82.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━\\x1b[0m \\x1b[32m48.3/69.1 MB\\x1b[0m \\x1b[31m61.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━\\x1b[0m \\x1b[32m52.0/69.1 MB\\x1b[0m \\x1b[31m78.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m54.5/69.1 MB\\x1b[0m \\x1b[31m60.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m54.5/69.1 MB\\x1b[0m \\x1b[31m60.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━\\x1b[0m \\x1b[32m58.3/69.1 MB\\x1b[0m \\x1b[31m79.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━\\x1b[0m \\x1b[32m59.9/69.1 MB\\x1b[0m \\x1b[31m62.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━\\x1b[0m \\x1b[32m61.7/69.1 MB\\x1b[0m \\x1b[31m61.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m64.8/69.1 MB\\x1b[0m \\x1b[31m79.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m65.3/69.1 MB\\x1b[0m \\x1b[31m60.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m68.6/69.1 MB\\x1b[0m \\x1b[31m77.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m69.1/69.1 MB\\x1b[0m \\x1b[31m9.6 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/50.0 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m4.1/50.0 MB\\x1b[0m \\x1b[31m213.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m6.4/50.0 MB\\x1b[0m \\x1b[31m94.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m6.4/50.0 MB\\x1b[0m \\x1b[31m94.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m10.2/50.0 MB\\x1b[0m \\x1b[31m77.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m10.8/50.0 MB\\x1b[0m \\x1b[31m60.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m12.8/50.0 MB\\x1b[0m \\x1b[31m60.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m16.1/50.0 MB\\x1b[0m \\x1b[31m58.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m16.5/50.0 MB\\x1b[0m \\x1b[31m57.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m19.3/50.0 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m20.6/50.0 MB\\x1b[0m \\x1b[31m58.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m23.1/50.0 MB\\x1b[0m \\x1b[31m77.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m25.7/50.0 MB\\x1b[0m \\x1b[31m61.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m25.7/50.0 MB\\x1b[0m \\x1b[31m48.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m29.7/50.0 MB\\x1b[0m \\x1b[31m77.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m32.1/50.0 MB\\x1b[0m \\x1b[31m61.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m32.1/50.0 MB\\x1b[0m \\x1b[31m61.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━\\x1b[0m \\x1b[32m36.2/50.0 MB\\x1b[0m \\x1b[31m79.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m37.3/50.0 MB\\x1b[0m \\x1b[31m62.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m38.9/50.0 MB\\x1b[0m \\x1b[31m61.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━\\x1b[0m \\x1b[32m42.8/50.0 MB\\x1b[0m \\x1b[31m79.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━\\x1b[0m \\x1b[32m42.8/50.0 MB\\x1b[0m \\x1b[31m78.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━\\x1b[0m \\x1b[32m45.8/50.0 MB\\x1b[0m \\x1b[31m61.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━\\x1b[0m \\x1b[32m47.9/50.0 MB\\x1b[0m \\x1b[31m59.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m49.8/50.0 MB\\x1b[0m \\x1b[31m79.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m50.0/50.0 MB\\x1b[0m \\x1b[31m62.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m50.0/50.0 MB\\x1b[0m \\x1b[31m62.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m50.0/50.0 MB\\x1b[0m \\x1b[31m62.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m50.0/50.0 MB\\x1b[0m \\x1b[31m62.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m50.0/50.0 MB\\x1b[0m \\x1b[31m32.0 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/104.1 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m104.1/104.1 kB\\x1b[0m \\x1b[31m13.3 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)',\n",
              " 'Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)',\n",
              " 'Building wheels for collected packages: seqeval',\n",
              " '  Building wheel for seqeval (setup.py) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=a8eb0c5f3148c2aeb35aeceb913272b0ccfcea4ec1685897e4a8a49228709958',\n",
              " '  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead',\n",
              " 'Successfully built seqeval',\n",
              " 'Installing collected packages: wrapt, typeguard, tensorflow-estimator, protobuf, portalocker, numpy, keras, colorama, tensorflow-addons, sounddevice, sacrebleu, opencv-python-headless, opencv-python, opencv-contrib-python, ml-dtypes, tensorflow-model-optimization, jaxlib, tensorboard, seqeval, jax, tensorflow, mediapipe, tf-keras, tensorflow-text, tf-models-official, mediapipe-model-maker',\n",
              " '  Attempting uninstall: wrapt',\n",
              " '    Found existing installation: wrapt 1.17.2',\n",
              " '    Uninstalling wrapt-1.17.2:',\n",
              " '      Successfully uninstalled wrapt-1.17.2',\n",
              " '  Attempting uninstall: typeguard',\n",
              " '    Found existing installation: typeguard 4.4.4',\n",
              " '    Uninstalling typeguard-4.4.4:',\n",
              " '      Successfully uninstalled typeguard-4.4.4',\n",
              " '  Attempting uninstall: protobuf',\n",
              " '    Found existing installation: protobuf 5.29.5',\n",
              " '    Uninstalling protobuf-5.29.5:',\n",
              " '      Successfully uninstalled protobuf-5.29.5',\n",
              " '  Attempting uninstall: numpy',\n",
              " '    Found existing installation: numpy 2.0.2',\n",
              " '    Uninstalling numpy-2.0.2:',\n",
              " '      Successfully uninstalled numpy-2.0.2',\n",
              " '  Attempting uninstall: keras',\n",
              " '    Found existing installation: keras 3.8.0',\n",
              " '    Uninstalling keras-3.8.0:',\n",
              " '      Successfully uninstalled keras-3.8.0',\n",
              " '  Attempting uninstall: opencv-python-headless',\n",
              " '    Found existing installation: opencv-python-headless 4.12.0.88',\n",
              " '    Uninstalling opencv-python-headless-4.12.0.88:',\n",
              " '      Successfully uninstalled opencv-python-headless-4.12.0.88',\n",
              " '  Attempting uninstall: opencv-python',\n",
              " '    Found existing installation: opencv-python 4.12.0.88',\n",
              " '    Uninstalling opencv-python-4.12.0.88:',\n",
              " '      Successfully uninstalled opencv-python-4.12.0.88',\n",
              " '  Attempting uninstall: opencv-contrib-python',\n",
              " '    Found existing installation: opencv-contrib-python 4.12.0.88',\n",
              " '    Uninstalling opencv-contrib-python-4.12.0.88:',\n",
              " '      Successfully uninstalled opencv-contrib-python-4.12.0.88',\n",
              " '  Attempting uninstall: ml-dtypes',\n",
              " '    Found existing installation: ml-dtypes 0.4.1',\n",
              " '    Uninstalling ml-dtypes-0.4.1:',\n",
              " '      Successfully uninstalled ml-dtypes-0.4.1',\n",
              " '  Attempting uninstall: jaxlib',\n",
              " '    Found existing installation: jaxlib 0.5.1',\n",
              " '    Uninstalling jaxlib-0.5.1:',\n",
              " '      Successfully uninstalled jaxlib-0.5.1',\n",
              " '  Attempting uninstall: tensorboard',\n",
              " '    Found existing installation: tensorboard 2.18.0',\n",
              " '    Uninstalling tensorboard-2.18.0:',\n",
              " '      Successfully uninstalled tensorboard-2.18.0',\n",
              " '  Attempting uninstall: jax',\n",
              " '    Found existing installation: jax 0.5.2',\n",
              " '    Uninstalling jax-0.5.2:',\n",
              " '      Successfully uninstalled jax-0.5.2',\n",
              " '  Attempting uninstall: tensorflow',\n",
              " '    Found existing installation: tensorflow 2.18.0',\n",
              " '    Uninstalling tensorflow-2.18.0:',\n",
              " '      Successfully uninstalled tensorflow-2.18.0',\n",
              " '  Attempting uninstall: tf-keras',\n",
              " '    Found existing installation: tf_keras 2.18.0',\n",
              " '    Uninstalling tf_keras-2.18.0:',\n",
              " '      Successfully uninstalled tf_keras-2.18.0',\n",
              " '  Attempting uninstall: tensorflow-text',\n",
              " '    Found existing installation: tensorflow-text 2.18.1',\n",
              " '    Uninstalling tensorflow-text-2.18.1:',\n",
              " '      Successfully uninstalled tensorflow-text-2.18.1',\n",
              " \"\\x1b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\",\n",
              " 'ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.',\n",
              " 'dopamine-rl 4.1.2 requires tf-keras>=2.18.0, but you have tf-keras 2.15.1 which is incompatible.',\n",
              " 'flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.34 which is incompatible.',\n",
              " 'inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.',\n",
              " 'grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.',\n",
              " 'tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.1 which is incompatible.',\n",
              " 'tensorflow-decision-forests 1.11.0 requires tf-keras~=2.17, but you have tf-keras 2.15.1 which is incompatible.',\n",
              " 'thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.',\n",
              " 'orbax-checkpoint 0.11.19 requires jax>=0.5.0, but you have jax 0.4.34 which is incompatible.\\x1b[0m\\x1b[31m',\n",
              " '\\x1b[0mSuccessfully installed colorama-0.4.6 jax-0.4.34 jaxlib-0.4.34 keras-2.15.0 mediapipe-0.10.21 mediapipe-model-maker-0.2.1.4 ml-dtypes-0.3.2 numpy-1.26.4 opencv-contrib-python-4.11.0.86 opencv-python-4.11.0.86 opencv-python-headless-4.11.0.86 portalocker-3.2.0 protobuf-4.25.8 sacrebleu-2.5.1 seqeval-1.2.2 sounddevice-0.5.2 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-addons-0.23.0 tensorflow-estimator-2.15.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tf-keras-2.15.1 tf-models-official-2.15.0 typeguard-2.13.3 wrapt-1.14.1']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XaRXDCXcerL",
        "outputId": "b5c47d95-cd27-4719-800e-6c9adb500dec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul 29 06:29:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xD_GNoCc964",
        "outputId": "185ee3db-8631-4a68-e5c8-2b02d9258fdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "12.4\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/aasist/\n",
        "import sys\n",
        "import os\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "sys.path.append(os.path.join(current_dir, 'models'))\n",
        "\n",
        "import nobuco\n",
        "from nobuco import ChannelOrder, ChannelOrderingStrategy\n",
        "from nobuco.layers.weight import WeightLayer\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import json\n",
        "from AASIST import Model\n",
        "\n",
        "# set device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device: {}\".format(device))\n",
        "if device == \"cpu\":\n",
        "    raise ValueError(\"GPU not detected!\")\n",
        "\n",
        "# 1. Load model and weights\n",
        "with open(\"./config/AASIST.conf\", 'r') as f:\n",
        "  cfg = json.load(f)\n",
        "  d_args = cfg['model_config']\n",
        "\n",
        "ckpt = torch.load(\"/content/aasist/models/weights/AASIST.pth\", map_location=device)\n",
        "\n",
        "# # 2) if it has the old filters key, move it to conv_time.weight\n",
        "# if \"conv_time.filters\" in ckpt:\n",
        "#     # shape [out_ch, kernel] → [out_ch, 1, kernel]\n",
        "#     ckpt[\"conv_time.weight\"] = ckpt.pop(\"conv_time.filters\").unsqueeze(1)\n",
        "\n",
        "model = Model(d_args)\n",
        "model.load_state_dict(ckpt)\n",
        "pytorch_module = model.eval()\n",
        "\n",
        "# 2. Prepare dummy input (e.g. batch_size=1, seq_len=…, channels=…)\n",
        "dummy = torch.randn(24, 64600)  # shape must match training\n",
        "\n",
        "# 3. Export\n",
        "keras_model = nobuco.pytorch_to_keras(\n",
        "    pytorch_module,\n",
        "    args=[dummy], kwargs=None,\n",
        "    inputs_channel_order=ChannelOrder.TENSORFLOW,\n",
        "    outputs_channel_order=ChannelOrder.TENSORFLOW,\n",
        ")\n",
        "\n",
        "model_path = 'aasist'\n",
        "keras_model.save(model_path + '.h5')\n",
        "print('Model saved')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZTJ_5ZM9R5oX",
        "outputId": "a1149042-40df-4522-cdc6-dd692a400cd1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/aasist\n",
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Tracing (DONE): : 474ops [01:02,  7.56ops/s] \n",
            "[Nobuco] Converting:   2%|▏         | 9/372 [00:27<20:53,  3.45s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 23, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 23, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 23, 21490], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 23, 21490], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be157901dd0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 23, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 23, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157901dd0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 23, 21490], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 23, 21490], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be19412a150\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 23, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 23, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be19412a150</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 23, 21490], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 23, 21490], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:   3%|▎         | 11/372 [00:53<53:38,  8.92s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 21490], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 21490], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be157a182d0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157a182d0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 21490], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 21490], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be1578ebf90\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1578ebf90</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 21490], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 21490], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:   4%|▍         | 15/372 [02:40<2:07:36, 21.45s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Residual_block'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv_downsample\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be157929250\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 23, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Residual_block'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv_downsample<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157929250</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 23, 21490], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 7163], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Sequential'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv_downsample\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be33b958510\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 23, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Sequential'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv_downsample<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be33b958510</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 23, 21490], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 7163], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Nobuco] Converting:   4%|▍         | 16/372 [02:59<2:04:17, 20.95s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 7163], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 7163], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be194092a10\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be194092a10</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 7163], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 7163], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be157a3f050\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157a3f050</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 7163], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 7163], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:   5%|▍         | 18/372 [03:19<1:30:27, 15.33s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 7163], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 7163], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be15794c150\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be15794c150</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 7163], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 7163], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be15792aed0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 24, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be15792aed0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 7163], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 24, 7163], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:   6%|▌         | 21/372 [03:48<1:06:12, 11.32s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Residual_block'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be15792ab10\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Residual_block'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be15792ab10</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 7163], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 2387], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Sequential'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be194104990\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 7163\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Sequential'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be194104990</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 7163], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 2387], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Nobuco] Converting:   6%|▌         | 22/372 [03:56<1:00:50, 10.43s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 2387], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 2387], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be15794c390\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be15794c390</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 2387], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 2387], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be157964810\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157964810</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 2387], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 2387], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:   6%|▋         | 24/372 [04:06<44:28,  7.67s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 2387], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 2387], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be157a3e510\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157a3e510</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 2387], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 2387], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be1579830d0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1579830d0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 2387], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 2387], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:   8%|▊         | 28/372 [04:31<37:39,  6.57s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Residual_block'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv_downsample\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be157953050\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Residual_block'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv_downsample<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157953050</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 2387], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 795], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Sequential'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv_downsample\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be157978550\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 32, 23, 2387\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Sequential'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv_downsample<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157978550</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 32, 23, 2387], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 795], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Nobuco] Converting:   8%|▊         | 29/372 [04:36<34:23,  6.02s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 795], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 795], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be15794d4d0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be15794d4d0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 795], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 795], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be1579f9110\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1579f9110</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 795], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 795], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:   8%|▊         | 31/372 [04:40<23:01,  4.05s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 795], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 795], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be15798b110\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be15798b110</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 795], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 795], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be15799d950\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be15799d950</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 795], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 795], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:   9%|▉         | 34/372 [04:46<14:23,  2.56s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Residual_block'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be1579aaad0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Residual_block'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1579aaad0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 795], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 265], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Sequential'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be1579ad910\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 795\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Sequential'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1579ad910</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 795], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 265], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Nobuco] Converting:   9%|▉         | 35/372 [04:47<12:36,  2.24s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 265], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 265], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be157982d50\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157982d50</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 265], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 265], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be157973950\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157973950</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 265], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 265], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:  10%|▉         | 37/372 [04:48<07:47,  1.40s/ops]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 265], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 265], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be1579c9550\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1579c9550</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 265], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 265], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be1579bc850\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1579bc850</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 265], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 265], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:  11%|█         | 40/372 [04:50<05:12,  1.06ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Residual_block'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be1579c0fd0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Residual_block'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1579c0fd0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 265], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 88], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Sequential'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be15790b6d0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 265\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Sequential'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be15790b6d0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 265], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 88], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Nobuco] Converting:  11%|█         | 41/372 [04:51<04:26,  1.24ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 88], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 88], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be1579cb910\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1579cb910</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 88], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 88], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be157973d10\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157973d10</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 88], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 88], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:  12%|█▏        | 43/372 [04:51<02:43,  2.01ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 88], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 88], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be1579bf8d0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1579bf8d0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 88], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 88], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be157900250\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 24, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157900250</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 88], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 24, 88], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:  12%|█▏        | 46/372 [04:52<01:35,  3.41ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Residual_block'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14ddcc450\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 29\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Residual_block'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "  <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14ddcc450</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 88], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 29], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Sequential'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be157981750\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 88\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 29\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Sequential'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "    <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157981750</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 88], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 29], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Sequential'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv_downsample\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv_downsample\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14ddb7c90\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 23, 21490\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64, 23, 29\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Sequential'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv_downsample<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv_downsample<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14ddb7c90</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 23, 21490], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64, 23, 29], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:  17%|█▋        | 62/372 [04:52<00:14, 21.37ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 23, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 23, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 23, 64], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 23, 64], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be1579cb6d0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 23, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 23, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1579cb6d0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 23, 64], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 23, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be157a3dc50\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 23, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 23, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be157a3dc50</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 23, 64], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 23, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'GraphAttentionLayer'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be15798b190\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 23, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 23, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'GraphAttentionLayer'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be15798b190</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 23, 64], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 23, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Nobuco] Converting:  20%|█▉        | 73/372 [04:53<00:07, 39.25ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'GraphPool'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14de142d0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 23, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 11, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[1m{\u001b[0m\u001b[1m{\u001b[0mfunction_node __wrapped__TopKV2_device_/job:localhost/repli\u001b[1;92mca:0\u001b[0m/task:\u001b[1;36m0\u001b[0m/devi\u001b[1;92mce:C\u001b[0mPU:\u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m input must have at least k columns. Had \u001b[1;36m1\u001b[0m, needed \u001b[1;36m11\u001b[0m \u001b[1m[\u001b[0mOp:TopKV2\u001b[1m]\u001b[0m name: \n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'GraphPool'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14de142d0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 23, 64], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 11, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"font-weight: bold\">{{</span>function_node __wrapped__TopKV2_device_/job:localhost/repli<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ca:0</span>/task:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/devi<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ce:C</span>PU:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}}</span> input must have at least k columns. Had <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, needed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"font-weight: bold\">[</span>Op:TopKV2<span style=\"font-weight: bold\">]</span> name: \n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:  24%|██▎       | 88/372 [04:53<00:07, 37.91ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 29, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 29, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 29, 64], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 29, 64], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be15794ee50\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 29, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 29, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be15794ee50</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 29, 64], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 29, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14dde0b90\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 29, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 29, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14dde0b90</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 29, 64], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 29, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'GraphAttentionLayer'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be15799f310\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 29, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 29, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'GraphAttentionLayer'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be15799f310</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 29, 64], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 29, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Nobuco] Converting:  28%|██▊       | 103/372 [04:53<00:04, 64.01ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'GraphPool'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14de22dd0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 29, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 20, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[1m{\u001b[0m\u001b[1m{\u001b[0mfunction_node __wrapped__TopKV2_device_/job:localhost/repli\u001b[1;92mca:0\u001b[0m/task:\u001b[1;36m0\u001b[0m/devi\u001b[1;92mce:C\u001b[0mPU:\u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m input must have at least k columns. Had \u001b[1;36m1\u001b[0m, needed \u001b[1;36m20\u001b[0m \u001b[1m[\u001b[0mOp:TopKV2\u001b[1m]\u001b[0m name: \n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'GraphPool'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14de22dd0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 29, 64], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 20, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"font-weight: bold\">{{</span>function_node __wrapped__TopKV2_device_/job:localhost/repli<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ca:0</span>/task:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/devi<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ce:C</span>PU:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}}</span> input must have at least k columns. Had <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, needed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"font-weight: bold\">[</span>Op:TopKV2<span style=\"font-weight: bold\">]</span> name: \n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:  40%|████      | 150/372 [04:54<00:02, 98.37ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be14ddb7e50\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14ddb7e50</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14de73f90\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14de73f90</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'HtrgGraphAttentionLayer'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mHtrgGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_type1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_type2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0matt_projM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_with_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_without_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14de96b50\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 20, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 11, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[32m'master'\u001b[0m: \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1, 1, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 20, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 11, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'HtrgGraphAttentionLayer'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HtrgGraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_type1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_type2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>att_projM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_with_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_without_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14de96b50</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 20, 64], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 11, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'master'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[1, 1, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 20, 32], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 11, 32], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'GraphPool'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be1941290d0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 11, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 5, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[1m{\u001b[0m\u001b[1m{\u001b[0mfunction_node __wrapped__TopKV2_device_/job:localhost/repli\u001b[1;92mca:0\u001b[0m/task:\u001b[1;36m0\u001b[0m/devi\u001b[1;92mce:C\u001b[0mPU:\u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m input must have at least k columns. Had \u001b[1;36m1\u001b[0m, needed \u001b[1;36m5\u001b[0m \u001b[1m[\u001b[0mOp:TopKV2\u001b[1m]\u001b[0m name: \n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'GraphPool'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1941290d0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 11, 32], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 5, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"font-weight: bold\">{{</span>function_node __wrapped__TopKV2_device_/job:localhost/repli<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ca:0</span>/task:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/devi<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ce:C</span>PU:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}}</span> input must have at least k columns. Had <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, needed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> <span style=\"font-weight: bold\">[</span>Op:TopKV2<span style=\"font-weight: bold\">]</span> name: \n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Nobuco] Converting:  44%|████▍     | 163/372 [04:54<00:01, 105.96ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'GraphPool'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14ddebf50\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 20, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 10, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[1m{\u001b[0m\u001b[1m{\u001b[0mfunction_node __wrapped__TopKV2_device_/job:localhost/repli\u001b[1;92mca:0\u001b[0m/task:\u001b[1;36m0\u001b[0m/devi\u001b[1;92mce:C\u001b[0mPU:\u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m input must have at least k columns. Had \u001b[1;36m1\u001b[0m, needed \u001b[1;36m10\u001b[0m \u001b[1m[\u001b[0mOp:TopKV2\u001b[1m]\u001b[0m name: \n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'GraphPool'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14ddebf50</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 20, 32], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 10, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"font-weight: bold\">{{</span>function_node __wrapped__TopKV2_device_/job:localhost/repli<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ca:0</span>/task:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/devi<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ce:C</span>PU:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}}</span> input must have at least k columns. Had <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, needed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> <span style=\"font-weight: bold\">[</span>Op:TopKV2<span style=\"font-weight: bold\">]</span> name: \n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:  55%|█████▍    | 203/372 [04:54<00:01, 151.35ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be14ab92710\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14ab92710</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14de22550\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14de22550</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'HtrgGraphAttentionLayer'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mHtrgGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_type1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_type2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0matt_projM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_with_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_without_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14ab8fd10\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 10, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 5, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[32m'master'\u001b[0m: \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 10, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 5, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'HtrgGraphAttentionLayer'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HtrgGraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_type1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_type2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>att_projM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_with_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_without_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14ab8fd10</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 10, 32], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 5, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'master'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 10, 32], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 5, 32], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:  69%|██████▉   | 258/372 [04:54<00:00, 120.19ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be14de849d0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14de849d0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14abb8610\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 31, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14abb8610</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 31, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'HtrgGraphAttentionLayer'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mHtrgGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_type1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_type2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0matt_projM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_with_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_without_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14de84710\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 20, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 11, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[32m'master'\u001b[0m: \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1, 1, 64\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 20, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 11, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'HtrgGraphAttentionLayer'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HtrgGraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_type1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_type2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>att_projM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_with_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_without_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14de84710</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 20, 64], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 11, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'master'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[1, 1, 64], dtype=torch.float32)'</span><span style=\"font-weight: bold\">}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 20, 32], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 11, 32], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Nobuco] Converting:  73%|███████▎  | 273/372 [04:55<00:00, 123.90ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'GraphPool'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be1579863d0\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 11, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 5, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[1m{\u001b[0m\u001b[1m{\u001b[0mfunction_node __wrapped__TopKV2_device_/job:localhost/repli\u001b[1;92mca:0\u001b[0m/task:\u001b[1;36m0\u001b[0m/devi\u001b[1;92mce:C\u001b[0mPU:\u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m input must have at least k columns. Had \u001b[1;36m1\u001b[0m, needed \u001b[1;36m5\u001b[0m \u001b[1m[\u001b[0mOp:TopKV2\u001b[1m]\u001b[0m name: \n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'GraphPool'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be1579863d0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 11, 32], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 5, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"font-weight: bold\">{{</span>function_node __wrapped__TopKV2_device_/job:localhost/repli<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ca:0</span>/task:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/devi<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ce:C</span>PU:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}}</span> input must have at least k columns. Had <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, needed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> <span style=\"font-weight: bold\">[</span>Op:TopKV2<span style=\"font-weight: bold\">]</span> name: \n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'GraphPool'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14abd3c90\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 20, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 10, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[1m{\u001b[0m\u001b[1m{\u001b[0mfunction_node __wrapped__TopKV2_device_/job:localhost/repli\u001b[1;92mca:0\u001b[0m/task:\u001b[1;36m0\u001b[0m/devi\u001b[1;92mce:C\u001b[0mPU:\u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m input must have at least k columns. Had \u001b[1;36m1\u001b[0m, needed \u001b[1;36m10\u001b[0m \u001b[1m[\u001b[0mOp:TopKV2\u001b[1m]\u001b[0m name: \n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'GraphPool'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14abd3c90</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 20, 32], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 10, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"font-weight: bold\">{{</span>function_node __wrapped__TopKV2_device_/job:localhost/repli<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ca:0</span>/task:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/devi<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">ce:C</span>PU:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}}</span> input must have at least k columns. Had <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, needed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> <span style=\"font-weight: bold\">[</span>Op:TopKV2<span style=\"font-weight: bold\">]</span> name: \n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting:  83%|████████▎ | 308/372 [04:55<00:00, 143.57ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu_'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mbuilt-in\u001b[0m\u001b[39m method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: \u001b[0m\u001b[1;35mUnimplementedOpStub\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mname\u001b[0m\u001b[39m=<built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput args: \u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39mInput kwargs: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39mOutput tensors: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39mException: Unimplemented op: <built-in method selu_ of type object at \u001b[0m\u001b[1;36m0x7be2e0a1ff00\u001b[0m\u001b[1m>\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu_'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">built-in</span><span style=\"color: #000000; text-decoration-color: #000000\"> method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UnimplementedOpStub</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input args: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Input kwargs: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Output tensors: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Exception: Unimplemented op: &lt;built-in method selu_ of type object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be2e0a1ff00</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'selu'\u001b[0m:\n",
              "PyTorch op: \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m selu at \u001b[0m\u001b[1;36m0x7be25e53d580\u001b[0m\u001b[39m>\u001b[0m\n",
              "\u001b[39mKeras op: <nobuco.layers.container.TransientContainer object at \u001b[0m\u001b[1;36m0x7be14abd2710\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'selu'</span>:\n",
              "PyTorch op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> selu at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be25e53d580</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">Keras op: &lt;nobuco.layers.container.TransientContainer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14abd2710</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'SELU'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14de91090\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 15, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'SELU'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14de91090</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 15, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Nobuco] Converting:  89%|████████▉ | 331/372 [04:55<00:00, 159.64ops/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'HtrgGraphAttentionLayer'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mHtrgGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_type1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_type2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0matt_projM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_with_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mproj_without_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14ac4eb10\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 10, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 5, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[32m'master'\u001b[0m: \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 10, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 5, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 1, 32\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'HtrgGraphAttentionLayer'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HtrgGraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_type1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_type2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>att_projM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_with_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>proj_without_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14ac4eb10</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 10, 32], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 5, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'master'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 10, 32], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 5, 32], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 1, 32], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "❌ Validation exception on node \u001b[32m'Model'\u001b[0m:\n",
              "PyTorch op: \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mconv_time\u001b[1m)\u001b[0m: \u001b[1;35mCONV\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mfirst_bn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.5\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mdrop_way\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mencoder\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv_downsample\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv_downsample\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResidual_block\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mbn1\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mselu\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mbn2\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mmp\u001b[1m)\u001b[0m: \u001b[1;35mMaxPool2d\u001b[0m\u001b[1m(\u001b[0m\u001b[33mkernel_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mdilation\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mceil_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mGAT_layer_S\u001b[1m)\u001b[0m: \u001b[1;35mGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mGAT_layer_T\u001b[1m)\u001b[0m: \u001b[1;35mGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mHtrgGAT_layer_ST11\u001b[1m)\u001b[0m: \u001b[1;35mHtrgGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_type1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_type2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0matt_projM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_with_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_without_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mHtrgGAT_layer_ST12\u001b[1m)\u001b[0m: \u001b[1;35mHtrgGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_type1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_type2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0matt_projM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_with_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_without_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mHtrgGAT_layer_ST21\u001b[1m)\u001b[0m: \u001b[1;35mHtrgGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_type1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_type2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0matt_projM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_with_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_without_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mHtrgGAT_layer_ST22\u001b[1m)\u001b[0m: \u001b[1;35mHtrgGraphAttentionLayer\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_type1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_type2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0matt_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0matt_projM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_with_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_without_att\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_with_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj_without_attM\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mbn\u001b[1m)\u001b[0m: \u001b[1;35mBatchNorm1d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33mmomentum\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33maffine\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mtrack_running_stats\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0minput_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mSELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33minplace\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mpool_S\u001b[1m)\u001b[0m: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mpool_T\u001b[1m)\u001b[0m: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m64\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mpool_hS1\u001b[1m)\u001b[0m: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mpool_hT1\u001b[1m)\u001b[0m: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mpool_hS2\u001b[1m)\u001b[0m: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mpool_hT2\u001b[1m)\u001b[0m: \u001b[1;35mGraphPool\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0msigmoid\u001b[1m)\u001b[0m: \u001b[1;35mSigmoid\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mout_layer\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m160\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n",
              "Keras op: \u001b[1m<\u001b[0m\u001b[1;95mnobuco.layers.container.TransientContainer\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7be14ac4ea10\u001b[0m\u001b[1m>\u001b[0m\n",
              "Input args: \u001b[1m(\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 64600\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Input kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "Output tensors: \u001b[1m[\u001b[0m\u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 160\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'Tensor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mshape\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m24, 2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32mdtype\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtorch\u001b[0m\u001b[32m.float32\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "Exception: \u001b[32m'UnimplementedOpStub'\u001b[0m object has no attribute \u001b[32m'reset_states'\u001b[0m\n",
              "Traceback:\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">❌ Validation exception on node <span style=\"color: #008000; text-decoration-color: #008000\">'Model'</span>:\n",
              "PyTorch op: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>conv_time<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CONV</span><span style=\"font-weight: bold\">()</span>\n",
              "  <span style=\"font-weight: bold\">(</span>first_bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>drop_way<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>encoder<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv_downsample<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv_downsample<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Residual_block</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>bn1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>selu<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>bn2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>conv2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
              "        <span style=\"font-weight: bold\">(</span>mp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaxPool2d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">kernel_size</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">stride</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dilation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">ceil_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>GAT_layer_S<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>GAT_layer_T<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>HtrgGAT_layer_ST11<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HtrgGraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_type1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_type2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>att_projM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_with_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_without_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>HtrgGAT_layer_ST12<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HtrgGraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_type1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_type2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>att_projM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_with_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_without_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>HtrgGAT_layer_ST21<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HtrgGraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_type1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_type2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>att_projM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_with_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_without_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>HtrgGAT_layer_ST22<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HtrgGraphAttentionLayer</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_type1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_type2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>att_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>att_projM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_with_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_without_att<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_with_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj_without_attM<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>bn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchNorm1d</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">momentum</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">track_running_stats</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>input_drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>pool_S<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>pool_T<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>pool_hS1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>pool_hT1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>pool_hS2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>pool_hT2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GraphPool</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>sigmoid<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sigmoid</span><span style=\"font-weight: bold\">()</span>\n",
              "    <span style=\"font-weight: bold\">(</span>proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>out_layer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "Keras op: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">nobuco.layers.container.TransientContainer</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7be14ac4ea10</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "Input args: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 64600], dtype=torch.float32)'</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Input kwargs: <span style=\"font-weight: bold\">{}</span>\n",
              "Output tensors: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 160], dtype=torch.float32)'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tensor(shape=[24, 2], dtype=torch.float32)'</span><span style=\"font-weight: bold\">]</span>\n",
              "Exception: <span style=\"color: #008000; text-decoration-color: #008000\">'UnimplementedOpStub'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'reset_states'</span>\n",
              "Traceback:\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Nobuco] Converting (DONE):  94%|█████████▍| 349/372 [04:55<00:19,  1.18ops/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Legend:\n",
            "    \u001b[32mGreen\u001b[0m — conversion successful\n",
            "    \u001b[33mYellow\u001b[0m — conversion imprecise\n",
            "    \u001b[31mRed\u001b[0m — conversion failed\n",
            "    \u001b[31m\u001b[7mRed\u001b[0m — no converter found\n",
            "    \u001b[0m\u001b[1mBold\u001b[0m — conversion applied directly\n",
            "    * — subgraph reused\n",
            "    \u001b[7mTensor\u001b[0m — this output is not dependent on any of subgraph's input tensors\n",
            "    \u001b[4mTensor\u001b[0m — this input is a parameter / constant\n",
            "    \u001b[90mTensor\u001b[0m — this tensor is useless\n",
            "\n",
            "\u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/nobuco/trace/trace.py\", line 471\u001b[0m \n",
            "\u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 469 \u001b[0m \n",
            "\u001b[31mModel[AASIST]\u001b[0m(float32_0<24,64600>\u001b[0m) -> (float32_531<24,160>\u001b[0m, float32_534<24,2>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_0<24,64600>\u001b[0m, 1) -> float32_1<24,1,64600>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32mCONV[AASIST]\u001b[0m(float32_1<24,1,64600>\u001b[0m, mask=False) -> float32_5<24,70,64472>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mclone[torch.Tensor]\u001b[0m(\u001b[4mfloat32_2<70,129>\u001b[0m) -> float32_3<70,129>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mto[torch.Tensor]\u001b[0m(float32_3<70,129>\u001b[0m, cpu) -> float32_3<70,129>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_3<70,129>\u001b[0m, 70, 1, 129) -> float32_4<70,1,129>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mconv1d[torch.nn.functional]\u001b[0m(float32_1<24,1,64600>\u001b[0m, float32_4<70,1,129>\u001b[0m, stride=1, padding=0, dilation=1, bias=None, groups=1) -> float32_5<24,70,64472>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_5<24,70,64472>\u001b[0m, dim=1) -> float32_6<24,1,70,64472>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mabs[torch]\u001b[0m(float32_6<24,1,70,64472>\u001b[0m) -> float32_7<24,1,70,64472>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_7<24,1,70,64472>\u001b[0m, (3, 3)) -> float32_8<24,1,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmax_pool2d[torch]\u001b[0m(float32_7<24,1,70,64472>\u001b[0m, (3, 3), [], 0, 1, False) -> float32_8<24,1,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_8<24,1,23,21490>\u001b[0m) -> float32_13<24,1,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_8<24,1,23,21490>\u001b[0m, float32_9<1>\u001b[0m, float32_10<1>\u001b[0m, float32_11<1>\u001b[0m, float32_12<1>\u001b[0m, False, 0.1, 1e-05) -> float32_13<24,1,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_8<24,1,23,21490>\u001b[0m, float32_11<1>\u001b[0m, float32_12<1>\u001b[0m, float32_9<1>\u001b[0m, float32_10<1>\u001b[0m, False, 0.1, 1e-05, True) -> float32_13<24,1,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 535\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_13<24,1,23,21490>\u001b[0m) -> float32_13<24,1,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_13<24,1,23,21490>\u001b[0m, True) -> float32_13<24,1,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_13<24,1,23,21490>\u001b[0m) -> float32_13<24,1,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 539\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_13<24,1,23,21490>\u001b[0m) -> float32_116<24,64,23,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_13<24,1,23,21490>\u001b[0m) -> float32_28<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_13<24,1,23,21490>\u001b[0m) -> float32_28<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_13<24,1,23,21490>\u001b[0m) -> float32_16<24,32,24,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_13<24,1,23,21490>\u001b[0m, float32_14<32,1,2,3>\u001b[0m, float32_15<32>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_16<24,32,24,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_16<24,32,24,21490>\u001b[0m) -> float32_21<24,32,24,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_16<24,32,24,21490>\u001b[0m, float32_17<32>\u001b[0m, float32_18<32>\u001b[0m, float32_19<32>\u001b[0m, float32_20<32>\u001b[0m, False, 0.1, 1e-05) -> float32_21<24,32,24,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_16<24,32,24,21490>\u001b[0m, float32_19<32>\u001b[0m, float32_20<32>\u001b[0m, float32_17<32>\u001b[0m, float32_18<32>\u001b[0m, False, 0.1, 1e-05, True) -> float32_21<24,32,24,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_21<24,32,24,21490>\u001b[0m) -> float32_21<24,32,24,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_21<24,32,24,21490>\u001b[0m, True) -> float32_21<24,32,24,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_21<24,32,24,21490>\u001b[0m) -> float32_21<24,32,24,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_21<24,32,24,21490>\u001b[0m) -> float32_24<24,32,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_21<24,32,24,21490>\u001b[0m, float32_22<32,32,2,3>\u001b[0m, float32_23<32>\u001b[0m, (1, 1), (0, 1), (1, 1), 1) -> float32_24<24,32,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_13<24,1,23,21490>\u001b[0m) -> float32_27<24,32,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_13<24,1,23,21490>\u001b[0m, float32_25<32,1,1,3>\u001b[0m, float32_26<32>\u001b[0m, (1, 1), (0, 1), (1, 1), 1) -> float32_27<24,32,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_24<24,32,23,21490>\u001b[0m, float32_27<24,32,23,21490>\u001b[0m) -> float32_24<24,32,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_24<24,32,23,21490>\u001b[0m, float32_27<24,32,23,21490>\u001b[0m) -> float32_24<24,32,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_24<24,32,23,21490>\u001b[0m) -> float32_28<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_24<24,32,23,21490>\u001b[0m, (1, 3), (1, 3), 0, 1, ceil_mode=False, return_indices=False) -> float32_28<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmax_pool2d[torch]\u001b[0m(float32_24<24,32,23,21490>\u001b[0m, (1, 3), (1, 3), 0, 1, False) -> float32_28<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_28<24,32,23,7163>\u001b[0m) -> float32_45<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_28<24,32,23,7163>\u001b[0m) -> float32_45<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_28<24,32,23,7163>\u001b[0m) -> \u001b[90mfloat32_33<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_28<24,32,23,7163>\u001b[0m, float32_29<32>\u001b[0m, float32_30<32>\u001b[0m, float32_31<32>\u001b[0m, float32_32<32>\u001b[0m, False, 0.1, 1e-05) -> float32_33<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_28<24,32,23,7163>\u001b[0m, float32_31<32>\u001b[0m, float32_32<32>\u001b[0m, float32_29<32>\u001b[0m, float32_30<32>\u001b[0m, False, 0.1, 1e-05, True) -> float32_33<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 450\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_33<24,32,23,7163>\u001b[0m) -> \u001b[90mfloat32_33<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_33<24,32,23,7163>\u001b[0m, True) -> float32_33<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_33<24,32,23,7163>\u001b[0m) -> float32_33<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_28<24,32,23,7163>\u001b[0m) -> float32_36<24,32,24,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_28<24,32,23,7163>\u001b[0m, float32_34<32,32,2,3>\u001b[0m, float32_35<32>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_36<24,32,24,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_36<24,32,24,7163>\u001b[0m) -> float32_41<24,32,24,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_36<24,32,24,7163>\u001b[0m, float32_37<32>\u001b[0m, float32_38<32>\u001b[0m, float32_39<32>\u001b[0m, float32_40<32>\u001b[0m, False, 0.1, 1e-05) -> float32_41<24,32,24,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_36<24,32,24,7163>\u001b[0m, float32_39<32>\u001b[0m, float32_40<32>\u001b[0m, float32_37<32>\u001b[0m, float32_38<32>\u001b[0m, False, 0.1, 1e-05, True) -> float32_41<24,32,24,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_41<24,32,24,7163>\u001b[0m) -> float32_41<24,32,24,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_41<24,32,24,7163>\u001b[0m, True) -> float32_41<24,32,24,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_41<24,32,24,7163>\u001b[0m) -> float32_41<24,32,24,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_41<24,32,24,7163>\u001b[0m) -> float32_44<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_41<24,32,24,7163>\u001b[0m, float32_42<32,32,2,3>\u001b[0m, float32_43<32>\u001b[0m, (1, 1), (0, 1), (1, 1), 1) -> float32_44<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_44<24,32,23,7163>\u001b[0m, float32_28<24,32,23,7163>\u001b[0m) -> float32_44<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_44<24,32,23,7163>\u001b[0m, float32_28<24,32,23,7163>\u001b[0m) -> float32_44<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_44<24,32,23,7163>\u001b[0m) -> float32_45<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_44<24,32,23,7163>\u001b[0m, (1, 3), (1, 3), 0, 1, ceil_mode=False, return_indices=False) -> float32_45<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmax_pool2d[torch]\u001b[0m(float32_44<24,32,23,7163>\u001b[0m, (1, 3), (1, 3), 0, 1, False) -> float32_45<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_45<24,32,23,2387>\u001b[0m) -> float32_65<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_45<24,32,23,2387>\u001b[0m) -> float32_65<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_45<24,32,23,2387>\u001b[0m) -> \u001b[90mfloat32_50<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_45<24,32,23,2387>\u001b[0m, float32_46<32>\u001b[0m, float32_47<32>\u001b[0m, float32_48<32>\u001b[0m, float32_49<32>\u001b[0m, False, 0.1, 1e-05) -> float32_50<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_45<24,32,23,2387>\u001b[0m, float32_48<32>\u001b[0m, float32_49<32>\u001b[0m, float32_46<32>\u001b[0m, float32_47<32>\u001b[0m, False, 0.1, 1e-05, True) -> float32_50<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 450\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_50<24,32,23,2387>\u001b[0m) -> \u001b[90mfloat32_50<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_50<24,32,23,2387>\u001b[0m, True) -> float32_50<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_50<24,32,23,2387>\u001b[0m) -> float32_50<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_45<24,32,23,2387>\u001b[0m) -> float32_53<24,64,24,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_45<24,32,23,2387>\u001b[0m, float32_51<64,32,2,3>\u001b[0m, float32_52<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_53<24,64,24,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_53<24,64,24,2387>\u001b[0m) -> float32_58<24,64,24,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_53<24,64,24,2387>\u001b[0m, float32_54<64>\u001b[0m, float32_55<64>\u001b[0m, float32_56<64>\u001b[0m, float32_57<64>\u001b[0m, False, 0.1, 1e-05) -> float32_58<24,64,24,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_53<24,64,24,2387>\u001b[0m, float32_56<64>\u001b[0m, float32_57<64>\u001b[0m, float32_54<64>\u001b[0m, float32_55<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_58<24,64,24,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_58<24,64,24,2387>\u001b[0m) -> float32_58<24,64,24,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_58<24,64,24,2387>\u001b[0m, True) -> float32_58<24,64,24,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_58<24,64,24,2387>\u001b[0m) -> float32_58<24,64,24,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_58<24,64,24,2387>\u001b[0m) -> float32_61<24,64,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_58<24,64,24,2387>\u001b[0m, float32_59<64,64,2,3>\u001b[0m, float32_60<64>\u001b[0m, (1, 1), (0, 1), (1, 1), 1) -> float32_61<24,64,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_45<24,32,23,2387>\u001b[0m) -> float32_64<24,64,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_45<24,32,23,2387>\u001b[0m, float32_62<64,32,1,3>\u001b[0m, float32_63<64>\u001b[0m, (1, 1), (0, 1), (1, 1), 1) -> float32_64<24,64,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_61<24,64,23,2387>\u001b[0m, float32_64<24,64,23,2387>\u001b[0m) -> float32_61<24,64,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_61<24,64,23,2387>\u001b[0m, float32_64<24,64,23,2387>\u001b[0m) -> float32_61<24,64,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_61<24,64,23,2387>\u001b[0m) -> float32_65<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_61<24,64,23,2387>\u001b[0m, (1, 3), (1, 3), 0, 1, ceil_mode=False, return_indices=False) -> float32_65<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmax_pool2d[torch]\u001b[0m(float32_61<24,64,23,2387>\u001b[0m, (1, 3), (1, 3), 0, 1, False) -> float32_65<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_65<24,64,23,795>\u001b[0m) -> float32_82<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_65<24,64,23,795>\u001b[0m) -> float32_82<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_65<24,64,23,795>\u001b[0m) -> \u001b[90mfloat32_70<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_65<24,64,23,795>\u001b[0m, float32_66<64>\u001b[0m, float32_67<64>\u001b[0m, float32_68<64>\u001b[0m, float32_69<64>\u001b[0m, False, 0.1, 1e-05) -> float32_70<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_65<24,64,23,795>\u001b[0m, float32_68<64>\u001b[0m, float32_69<64>\u001b[0m, float32_66<64>\u001b[0m, float32_67<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_70<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 450\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_70<24,64,23,795>\u001b[0m) -> \u001b[90mfloat32_70<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_70<24,64,23,795>\u001b[0m, True) -> float32_70<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_70<24,64,23,795>\u001b[0m) -> float32_70<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_65<24,64,23,795>\u001b[0m) -> float32_73<24,64,24,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_65<24,64,23,795>\u001b[0m, float32_71<64,64,2,3>\u001b[0m, float32_72<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_73<24,64,24,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_73<24,64,24,795>\u001b[0m) -> float32_78<24,64,24,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_73<24,64,24,795>\u001b[0m, float32_74<64>\u001b[0m, float32_75<64>\u001b[0m, float32_76<64>\u001b[0m, float32_77<64>\u001b[0m, False, 0.1, 1e-05) -> float32_78<24,64,24,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_73<24,64,24,795>\u001b[0m, float32_76<64>\u001b[0m, float32_77<64>\u001b[0m, float32_74<64>\u001b[0m, float32_75<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_78<24,64,24,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_78<24,64,24,795>\u001b[0m) -> float32_78<24,64,24,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_78<24,64,24,795>\u001b[0m, True) -> float32_78<24,64,24,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_78<24,64,24,795>\u001b[0m) -> float32_78<24,64,24,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_78<24,64,24,795>\u001b[0m) -> float32_81<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_78<24,64,24,795>\u001b[0m, float32_79<64,64,2,3>\u001b[0m, float32_80<64>\u001b[0m, (1, 1), (0, 1), (1, 1), 1) -> float32_81<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_81<24,64,23,795>\u001b[0m, float32_65<24,64,23,795>\u001b[0m) -> float32_81<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_81<24,64,23,795>\u001b[0m, float32_65<24,64,23,795>\u001b[0m) -> float32_81<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_81<24,64,23,795>\u001b[0m) -> float32_82<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_81<24,64,23,795>\u001b[0m, (1, 3), (1, 3), 0, 1, ceil_mode=False, return_indices=False) -> float32_82<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmax_pool2d[torch]\u001b[0m(float32_81<24,64,23,795>\u001b[0m, (1, 3), (1, 3), 0, 1, False) -> float32_82<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_82<24,64,23,265>\u001b[0m) -> float32_99<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_82<24,64,23,265>\u001b[0m) -> float32_99<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_82<24,64,23,265>\u001b[0m) -> \u001b[90mfloat32_87<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_82<24,64,23,265>\u001b[0m, float32_83<64>\u001b[0m, float32_84<64>\u001b[0m, float32_85<64>\u001b[0m, float32_86<64>\u001b[0m, False, 0.1, 1e-05) -> float32_87<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_82<24,64,23,265>\u001b[0m, float32_85<64>\u001b[0m, float32_86<64>\u001b[0m, float32_83<64>\u001b[0m, float32_84<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_87<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 450\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_87<24,64,23,265>\u001b[0m) -> \u001b[90mfloat32_87<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_87<24,64,23,265>\u001b[0m, True) -> float32_87<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_87<24,64,23,265>\u001b[0m) -> float32_87<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_82<24,64,23,265>\u001b[0m) -> float32_90<24,64,24,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_82<24,64,23,265>\u001b[0m, float32_88<64,64,2,3>\u001b[0m, float32_89<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_90<24,64,24,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_90<24,64,24,265>\u001b[0m) -> float32_95<24,64,24,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_90<24,64,24,265>\u001b[0m, float32_91<64>\u001b[0m, float32_92<64>\u001b[0m, float32_93<64>\u001b[0m, float32_94<64>\u001b[0m, False, 0.1, 1e-05) -> float32_95<24,64,24,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_90<24,64,24,265>\u001b[0m, float32_93<64>\u001b[0m, float32_94<64>\u001b[0m, float32_91<64>\u001b[0m, float32_92<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_95<24,64,24,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_95<24,64,24,265>\u001b[0m) -> float32_95<24,64,24,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_95<24,64,24,265>\u001b[0m, True) -> float32_95<24,64,24,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_95<24,64,24,265>\u001b[0m) -> float32_95<24,64,24,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_95<24,64,24,265>\u001b[0m) -> float32_98<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_95<24,64,24,265>\u001b[0m, float32_96<64,64,2,3>\u001b[0m, float32_97<64>\u001b[0m, (1, 1), (0, 1), (1, 1), 1) -> float32_98<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_98<24,64,23,265>\u001b[0m, float32_82<24,64,23,265>\u001b[0m) -> float32_98<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_98<24,64,23,265>\u001b[0m, float32_82<24,64,23,265>\u001b[0m) -> float32_98<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_98<24,64,23,265>\u001b[0m) -> float32_99<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_98<24,64,23,265>\u001b[0m, (1, 3), (1, 3), 0, 1, ceil_mode=False, return_indices=False) -> float32_99<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmax_pool2d[torch]\u001b[0m(float32_98<24,64,23,265>\u001b[0m, (1, 3), (1, 3), 0, 1, False) -> float32_99<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_99<24,64,23,88>\u001b[0m) -> float32_116<24,64,23,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_99<24,64,23,88>\u001b[0m) -> float32_116<24,64,23,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_99<24,64,23,88>\u001b[0m) -> \u001b[90mfloat32_104<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_99<24,64,23,88>\u001b[0m, float32_100<64>\u001b[0m, float32_101<64>\u001b[0m, float32_102<64>\u001b[0m, float32_103<64>\u001b[0m, False, 0.1, 1e-05) -> float32_104<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_99<24,64,23,88>\u001b[0m, float32_102<64>\u001b[0m, float32_103<64>\u001b[0m, float32_100<64>\u001b[0m, float32_101<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_104<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 450\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_104<24,64,23,88>\u001b[0m) -> \u001b[90mfloat32_104<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_104<24,64,23,88>\u001b[0m, True) -> float32_104<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_104<24,64,23,88>\u001b[0m) -> float32_104<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_99<24,64,23,88>\u001b[0m) -> float32_107<24,64,24,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_99<24,64,23,88>\u001b[0m, float32_105<64,64,2,3>\u001b[0m, float32_106<64>\u001b[0m, (1, 1), (1, 1), (1, 1), 1) -> float32_107<24,64,24,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_107<24,64,24,88>\u001b[0m) -> float32_112<24,64,24,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_107<24,64,24,88>\u001b[0m, float32_108<64>\u001b[0m, float32_109<64>\u001b[0m, float32_110<64>\u001b[0m, float32_111<64>\u001b[0m, False, 0.1, 1e-05) -> float32_112<24,64,24,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_107<24,64,24,88>\u001b[0m, float32_110<64>\u001b[0m, float32_111<64>\u001b[0m, float32_108<64>\u001b[0m, float32_109<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_112<24,64,24,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_112<24,64,24,88>\u001b[0m) -> float32_112<24,64,24,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_112<24,64,24,88>\u001b[0m, True) -> float32_112<24,64,24,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_112<24,64,24,88>\u001b[0m) -> float32_112<24,64,24,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_112<24,64,24,88>\u001b[0m) -> float32_115<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_112<24,64,24,88>\u001b[0m, float32_113<64,64,2,3>\u001b[0m, float32_114<64>\u001b[0m, (1, 1), (0, 1), (1, 1), 1) -> float32_115<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_115<24,64,23,88>\u001b[0m, float32_99<24,64,23,88>\u001b[0m) -> float32_115<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_115<24,64,23,88>\u001b[0m, float32_99<24,64,23,88>\u001b[0m) -> float32_115<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_115<24,64,23,88>\u001b[0m) -> float32_116<24,64,23,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_115<24,64,23,88>\u001b[0m, (1, 3), (1, 3), 0, 1, ceil_mode=False, return_indices=False) -> float32_116<24,64,23,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmax_pool2d[torch]\u001b[0m(float32_115<24,64,23,88>\u001b[0m, (1, 3), (1, 3), 0, 1, False) -> float32_116<24,64,23,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mabs[torch]\u001b[0m(float32_116<24,64,23,29>\u001b[0m) -> float32_117<24,64,23,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmax[torch]\u001b[0m(float32_117<24,64,23,29>\u001b[0m, dim=3) -> (float32_118<24,64,23>\u001b[0m, \u001b[90mint64_119<24,64,23>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_118<24,64,23>\u001b[0m, 1, 2) -> float32_120<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_120<24,23,64>\u001b[0m, \u001b[4mfloat32_121<1,23,64>\u001b[0m) -> float32_122<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_120<24,23,64>\u001b[0m, float32_121<1,23,64>\u001b[0m) -> float32_122<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 545\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 17 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mGraphAttentionLayer[AASIST]\u001b[0m(float32_122<24,23,64>\u001b[0m) -> float32_150<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_122<24,23,64>\u001b[0m) -> float32_122<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_122<24,23,64>\u001b[0m, 0.2, False, False) -> float32_122<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_122<24,23,64>\u001b[0m, 2) -> float32_123<24,23,1,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(float32_123<24,23,1,64>\u001b[0m, -1, -1, 23, -1) -> float32_124<24,23,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_124<24,23,23,64>\u001b[0m, 1, 2) -> float32_125<24,23,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_124<24,23,23,64>\u001b[0m, float32_125<24,23,23,64>\u001b[0m) -> float32_126<24,23,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_124<24,23,23,64>\u001b[0m, float32_125<24,23,23,64>\u001b[0m) -> float32_126<24,23,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_126<24,23,23,64>\u001b[0m) -> float32_129<24,23,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_126<24,23,23,64>\u001b[0m, float32_127<64,64>\u001b[0m, float32_128<64>\u001b[0m) -> float32_129<24,23,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtanh[torch]\u001b[0m(float32_129<24,23,23,64>\u001b[0m) -> float32_130<24,23,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_130<24,23,23,64>\u001b[0m, \u001b[4mfloat32_131<64,1>\u001b[0m) -> float32_132<24,23,23,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_132<24,23,23,1>\u001b[0m, 2.0) -> float32_133<24,23,23,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdiv[TensorBase]\u001b[0m(float32_132<24,23,23,1>\u001b[0m, 2.0) -> float32_133<24,23,23,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_133<24,23,23,1>\u001b[0m, dim=-2) -> float32_134<24,23,23,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_133<24,23,23,1>\u001b[0m, -2) -> float32_134<24,23,23,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msqueeze[torch.Tensor]\u001b[0m(float32_134<24,23,23,1>\u001b[0m, -1) -> float32_135<24,23,23>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_135<24,23,23>\u001b[0m, float32_122<24,23,64>\u001b[0m) -> float32_136<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_136<24,23,64>\u001b[0m) -> float32_139<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_136<24,23,64>\u001b[0m, float32_137<64,64>\u001b[0m, float32_138<64>\u001b[0m) -> float32_139<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_122<24,23,64>\u001b[0m) -> float32_142<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_122<24,23,64>\u001b[0m, float32_140<64,64>\u001b[0m, float32_141<64>\u001b[0m) -> float32_142<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_139<24,23,64>\u001b[0m, float32_142<24,23,64>\u001b[0m) -> float32_143<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_139<24,23,64>\u001b[0m, float32_142<24,23,64>\u001b[0m) -> float32_143<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_143<24,23,64>\u001b[0m, -1, 64) -> float32_144<552,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_144<552,64>\u001b[0m) -> float32_149<552,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_144<552,64>\u001b[0m, float32_145<64>\u001b[0m, float32_146<64>\u001b[0m, float32_147<64>\u001b[0m, float32_148<64>\u001b[0m, False, 0.1, 1e-05) -> float32_149<552,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_144<552,64>\u001b[0m, float32_147<64>\u001b[0m, float32_148<64>\u001b[0m, float32_145<64>\u001b[0m, float32_146<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_149<552,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_149<552,64>\u001b[0m, Size(24, 23, 64)) -> float32_150<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 58\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_150<24,23,64>\u001b[0m) -> float32_150<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_150<24,23,64>\u001b[0m, True) -> float32_150<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_150<24,23,64>\u001b[0m) -> float32_150<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 546\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 285 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mGraphPool[AASIST]\u001b[0m(float32_150<24,23,64>\u001b[0m) -> float32_159<24,11,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_150<24,23,64>\u001b[0m) -> float32_150<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_150<24,23,64>\u001b[0m, 0.3, False, False) -> float32_150<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_150<24,23,64>\u001b[0m) -> float32_153<24,23,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_150<24,23,64>\u001b[0m, float32_151<1,64>\u001b[0m, float32_152<1>\u001b[0m) -> float32_153<24,23,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32mSigmoid[torch.nn.modules.activation]\u001b[0m(float32_153<24,23,1>\u001b[0m) -> float32_154<24,23,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1msigmoid[torch]\u001b[0m(float32_153<24,23,1>\u001b[0m) -> float32_154<24,23,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtopk[torch]\u001b[0m(float32_154<24,23,1>\u001b[0m, 11, dim=1) -> (\u001b[90mfloat32_155<24,11,1>\u001b[0m, int64_156<24,11,1>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(int64_156<24,11,1>\u001b[0m, -1, -1, 64) -> int64_157<24,11,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_150<24,23,64>\u001b[0m, float32_154<24,23,1>\u001b[0m) -> float32_158<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_150<24,23,64>\u001b[0m, float32_154<24,23,1>\u001b[0m) -> float32_158<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_158<24,23,64>\u001b[0m, 1, int64_157<24,11,64>\u001b[0m) -> float32_159<24,11,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mabs[torch]\u001b[0m(float32_116<24,64,23,29>\u001b[0m) -> float32_160<24,64,23,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmax[torch]\u001b[0m(float32_160<24,64,23,29>\u001b[0m, dim=2) -> (float32_161<24,64,29>\u001b[0m, \u001b[90mint64_162<24,64,29>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_161<24,64,29>\u001b[0m, 1, 2) -> float32_163<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 552\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 17 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mGraphAttentionLayer[AASIST]\u001b[0m(float32_163<24,29,64>\u001b[0m) -> float32_191<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_163<24,29,64>\u001b[0m) -> float32_163<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_163<24,29,64>\u001b[0m, 0.2, False, False) -> float32_163<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_163<24,29,64>\u001b[0m, 2) -> float32_164<24,29,1,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(float32_164<24,29,1,64>\u001b[0m, -1, -1, 29, -1) -> float32_165<24,29,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_165<24,29,29,64>\u001b[0m, 1, 2) -> float32_166<24,29,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_165<24,29,29,64>\u001b[0m, float32_166<24,29,29,64>\u001b[0m) -> float32_167<24,29,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_165<24,29,29,64>\u001b[0m, float32_166<24,29,29,64>\u001b[0m) -> float32_167<24,29,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[33m\u001b[1m\u001b[7m (!) Max diff 0.00037 (0.000%) \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 82\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 50 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[33m\u001b[1m C \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/nobuco/node_converters/linear.py\", line 20 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[33m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_167<24,29,29,64>\u001b[0m) -> float32_170<24,29,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[33m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_167<24,29,29,64>\u001b[0m, float32_168<64,64>\u001b[0m, float32_169<64>\u001b[0m) -> float32_170<24,29,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtanh[torch]\u001b[0m(float32_170<24,29,29,64>\u001b[0m) -> float32_171<24,29,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_171<24,29,29,64>\u001b[0m, \u001b[4mfloat32_172<64,1>\u001b[0m) -> float32_173<24,29,29,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_173<24,29,29,1>\u001b[0m, 2.0) -> float32_174<24,29,29,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdiv[TensorBase]\u001b[0m(float32_173<24,29,29,1>\u001b[0m, 2.0) -> float32_174<24,29,29,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_174<24,29,29,1>\u001b[0m, dim=-2) -> float32_175<24,29,29,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_174<24,29,29,1>\u001b[0m, -2) -> float32_175<24,29,29,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msqueeze[torch.Tensor]\u001b[0m(float32_175<24,29,29,1>\u001b[0m, -1) -> float32_176<24,29,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_176<24,29,29>\u001b[0m, float32_163<24,29,64>\u001b[0m) -> float32_177<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_177<24,29,64>\u001b[0m) -> float32_180<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_177<24,29,64>\u001b[0m, float32_178<64,64>\u001b[0m, float32_179<64>\u001b[0m) -> float32_180<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_163<24,29,64>\u001b[0m) -> float32_183<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_163<24,29,64>\u001b[0m, float32_181<64,64>\u001b[0m, float32_182<64>\u001b[0m) -> float32_183<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_180<24,29,64>\u001b[0m, float32_183<24,29,64>\u001b[0m) -> float32_184<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_180<24,29,64>\u001b[0m, float32_183<24,29,64>\u001b[0m) -> float32_184<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_184<24,29,64>\u001b[0m, -1, 64) -> float32_185<696,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_185<696,64>\u001b[0m) -> float32_190<696,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_185<696,64>\u001b[0m, float32_186<64>\u001b[0m, float32_187<64>\u001b[0m, float32_188<64>\u001b[0m, float32_189<64>\u001b[0m, False, 0.1, 1e-05) -> float32_190<696,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_185<696,64>\u001b[0m, float32_188<64>\u001b[0m, float32_189<64>\u001b[0m, float32_186<64>\u001b[0m, float32_187<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_190<696,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_190<696,64>\u001b[0m, Size(24, 29, 64)) -> float32_191<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 58\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_191<24,29,64>\u001b[0m) -> float32_191<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_191<24,29,64>\u001b[0m, True) -> float32_191<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_191<24,29,64>\u001b[0m) -> float32_191<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 553\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 285 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mGraphPool[AASIST]\u001b[0m(float32_191<24,29,64>\u001b[0m) -> float32_200<24,20,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_191<24,29,64>\u001b[0m) -> float32_191<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_191<24,29,64>\u001b[0m, 0.3, False, False) -> float32_191<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_191<24,29,64>\u001b[0m) -> float32_194<24,29,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_191<24,29,64>\u001b[0m, float32_192<1,64>\u001b[0m, float32_193<1>\u001b[0m) -> float32_194<24,29,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32mSigmoid[torch.nn.modules.activation]\u001b[0m(float32_194<24,29,1>\u001b[0m) -> float32_195<24,29,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1msigmoid[torch]\u001b[0m(float32_194<24,29,1>\u001b[0m) -> float32_195<24,29,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtopk[torch]\u001b[0m(float32_195<24,29,1>\u001b[0m, 20, dim=1) -> (\u001b[90mfloat32_196<24,20,1>\u001b[0m, int64_197<24,20,1>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(int64_197<24,20,1>\u001b[0m, -1, -1, 64) -> int64_198<24,20,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_191<24,29,64>\u001b[0m, float32_195<24,29,1>\u001b[0m) -> float32_199<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_191<24,29,64>\u001b[0m, float32_195<24,29,1>\u001b[0m) -> float32_199<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_199<24,29,64>\u001b[0m, 1, int64_198<24,20,64>\u001b[0m) -> float32_200<24,20,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(\u001b[4mfloat32_201<1,1,64>\u001b[0m, 24, -1, -1) -> float32_202<24,1,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(\u001b[4mfloat32_203<1,1,64>\u001b[0m, 24, -1, -1) -> float32_204<24,1,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 560\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 113 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mHtrgGraphAttentionLayer[AASIST]\u001b[0m(float32_200<24,20,64>\u001b[0m, float32_159<24,11,64>\u001b[0m, master=\u001b[4mfloat32_201<1,1,64>\u001b[0m) -> (float32_271<24,20,32>\u001b[0m, float32_272<24,11,32>\u001b[0m, float32_254<24,1,32>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_200<24,20,64>\u001b[0m) -> float32_207<24,20,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_200<24,20,64>\u001b[0m, float32_205<64,64>\u001b[0m, float32_206<64>\u001b[0m) -> float32_207<24,20,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_159<24,11,64>\u001b[0m) -> float32_210<24,11,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_159<24,11,64>\u001b[0m, float32_208<64,64>\u001b[0m, float32_209<64>\u001b[0m) -> float32_210<24,11,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_207<24,20,64>\u001b[0m, float32_210<24,11,64>\u001b[0m], dim=1) -> float32_211<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_211<24,31,64>\u001b[0m) -> float32_211<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_211<24,31,64>\u001b[0m, 0.2, False, False) -> float32_211<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_211<24,31,64>\u001b[0m, 2) -> float32_212<24,31,1,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(float32_212<24,31,1,64>\u001b[0m, -1, -1, 31, -1) -> float32_213<24,31,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_213<24,31,31,64>\u001b[0m, 1, 2) -> float32_214<24,31,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_213<24,31,31,64>\u001b[0m, float32_214<24,31,31,64>\u001b[0m) -> float32_215<24,31,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_213<24,31,31,64>\u001b[0m, float32_214<24,31,31,64>\u001b[0m) -> float32_215<24,31,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_215<24,31,31,64>\u001b[0m) -> float32_218<24,31,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_215<24,31,31,64>\u001b[0m, float32_216<32,64>\u001b[0m, float32_217<32>\u001b[0m) -> float32_218<24,31,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtanh[torch]\u001b[0m(float32_218<24,31,31,32>\u001b[0m) -> float32_219<24,31,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_219<24,31,31,32>\u001b[0m, (:, :, :, 0)) -> float32_220<24,31,31>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mzeros_like[torch]\u001b[0m(float32_220<24,31,31>\u001b[0m) -> float32_221<24,31,31>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_221<24,31,31>\u001b[0m, -1) -> float32_222<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_219<24,31,31,32>\u001b[0m, (:, :20, :20, :)) -> float32_223<24,20,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_223<24,20,20,32>\u001b[0m, \u001b[4mfloat32_224<32,1>\u001b[0m) -> float32_225<24,20,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_222<24,31,31,1>\u001b[0m, (:, :20, :20, :), float32_225<24,20,20,1>\u001b[0m) -> float32_222<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_219<24,31,31,32>\u001b[0m, (:, 20:, 20:, :)) -> float32_226<24,11,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_226<24,11,11,32>\u001b[0m, \u001b[4mfloat32_227<32,1>\u001b[0m) -> float32_228<24,11,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_222<24,31,31,1>\u001b[0m, (:, 20:, 20:, :), float32_228<24,11,11,1>\u001b[0m) -> float32_222<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_219<24,31,31,32>\u001b[0m, (:, :20, 20:, :)) -> float32_229<24,20,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_229<24,20,11,32>\u001b[0m, \u001b[4mfloat32_230<32,1>\u001b[0m) -> float32_231<24,20,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_222<24,31,31,1>\u001b[0m, (:, :20, 20:, :), float32_231<24,20,11,1>\u001b[0m) -> float32_222<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_219<24,31,31,32>\u001b[0m, (:, 20:, :20, :)) -> float32_232<24,11,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_232<24,11,20,32>\u001b[0m, \u001b[4mfloat32_230<32,1>\u001b[0m) -> float32_233<24,11,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_222<24,31,31,1>\u001b[0m, (:, 20:, :20, :), float32_233<24,11,20,1>\u001b[0m) -> float32_222<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_222<24,31,31,1>\u001b[0m, 100.0) -> float32_234<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdiv[TensorBase]\u001b[0m(float32_222<24,31,31,1>\u001b[0m, 100.0) -> float32_234<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_234<24,31,31,1>\u001b[0m, dim=-2) -> float32_235<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_234<24,31,31,1>\u001b[0m, -2) -> float32_235<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_211<24,31,64>\u001b[0m, float32_201<1,1,64>\u001b[0m) -> float32_236<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_211<24,31,64>\u001b[0m, float32_201<1,1,64>\u001b[0m) -> float32_236<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_236<24,31,64>\u001b[0m) -> float32_239<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_236<24,31,64>\u001b[0m, float32_237<32,64>\u001b[0m, float32_238<32>\u001b[0m) -> float32_239<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtanh[torch]\u001b[0m(float32_239<24,31,32>\u001b[0m) -> float32_240<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_240<24,31,32>\u001b[0m, \u001b[4mfloat32_241<32,1>\u001b[0m) -> float32_242<24,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_242<24,31,1>\u001b[0m, 100.0) -> float32_243<24,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdiv[TensorBase]\u001b[0m(float32_242<24,31,1>\u001b[0m, 100.0) -> float32_243<24,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_243<24,31,1>\u001b[0m, dim=-2) -> float32_244<24,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_243<24,31,1>\u001b[0m, -2) -> float32_244<24,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msqueeze[torch.Tensor]\u001b[0m(float32_244<24,31,1>\u001b[0m, -1) -> float32_245<24,31>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_245<24,31>\u001b[0m, 1) -> float32_246<24,1,31>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_246<24,1,31>\u001b[0m, float32_211<24,31,64>\u001b[0m) -> float32_247<24,1,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_247<24,1,64>\u001b[0m) -> float32_250<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_247<24,1,64>\u001b[0m, float32_248<32,64>\u001b[0m, float32_249<32>\u001b[0m) -> float32_250<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_201<1,1,64>\u001b[0m) -> float32_253<1,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_201<1,1,64>\u001b[0m, float32_251<32,64>\u001b[0m, float32_252<32>\u001b[0m) -> float32_253<1,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_250<24,1,32>\u001b[0m, float32_253<1,1,32>\u001b[0m) -> float32_254<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_250<24,1,32>\u001b[0m, float32_253<1,1,32>\u001b[0m) -> float32_254<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msqueeze[torch.Tensor]\u001b[0m(float32_235<24,31,31,1>\u001b[0m, -1) -> float32_255<24,31,31>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_255<24,31,31>\u001b[0m, float32_211<24,31,64>\u001b[0m) -> float32_256<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_256<24,31,64>\u001b[0m) -> float32_259<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_256<24,31,64>\u001b[0m, float32_257<32,64>\u001b[0m, float32_258<32>\u001b[0m) -> float32_259<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_211<24,31,64>\u001b[0m) -> float32_262<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_211<24,31,64>\u001b[0m, float32_260<32,64>\u001b[0m, float32_261<32>\u001b[0m) -> float32_262<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_259<24,31,32>\u001b[0m, float32_262<24,31,32>\u001b[0m) -> float32_263<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_259<24,31,32>\u001b[0m, float32_262<24,31,32>\u001b[0m) -> float32_263<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_263<24,31,32>\u001b[0m, -1, 32) -> float32_264<744,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_264<744,32>\u001b[0m) -> float32_269<744,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_264<744,32>\u001b[0m, float32_265<32>\u001b[0m, float32_266<32>\u001b[0m, float32_267<32>\u001b[0m, float32_268<32>\u001b[0m, False, 0.1, 1e-05) -> float32_269<744,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_264<744,32>\u001b[0m, float32_267<32>\u001b[0m, float32_268<32>\u001b[0m, float32_265<32>\u001b[0m, float32_266<32>\u001b[0m, False, 0.1, 1e-05, True) -> float32_269<744,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_269<744,32>\u001b[0m, Size(24, 31, 32)) -> float32_270<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 180\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_270<24,31,32>\u001b[0m) -> float32_270<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_270<24,31,32>\u001b[0m, True) -> float32_270<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_270<24,31,32>\u001b[0m) -> float32_270<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32m\u001b[1mnarrow[torch.Tensor]\u001b[0m(float32_270<24,31,32>\u001b[0m, 1, 0, 20) -> float32_271<24,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m └·\u001b[0m \u001b[32m\u001b[1mnarrow[torch.Tensor]\u001b[0m(float32_270<24,31,32>\u001b[0m, 1, 20, 11) -> float32_272<24,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 563\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 285 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mGraphPool[AASIST]\u001b[0m(float32_272<24,11,32>\u001b[0m) -> float32_281<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_272<24,11,32>\u001b[0m) -> float32_272<24,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_272<24,11,32>\u001b[0m, 0.3, False, False) -> float32_272<24,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_272<24,11,32>\u001b[0m) -> float32_275<24,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_272<24,11,32>\u001b[0m, float32_273<1,32>\u001b[0m, float32_274<1>\u001b[0m) -> float32_275<24,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32mSigmoid[torch.nn.modules.activation]\u001b[0m(float32_275<24,11,1>\u001b[0m) -> float32_276<24,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1msigmoid[torch]\u001b[0m(float32_275<24,11,1>\u001b[0m) -> float32_276<24,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtopk[torch]\u001b[0m(float32_276<24,11,1>\u001b[0m, 5, dim=1) -> (\u001b[90mfloat32_277<24,5,1>\u001b[0m, int64_278<24,5,1>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(int64_278<24,5,1>\u001b[0m, -1, -1, 32) -> int64_279<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_272<24,11,32>\u001b[0m, float32_276<24,11,1>\u001b[0m) -> float32_280<24,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_272<24,11,32>\u001b[0m, float32_276<24,11,1>\u001b[0m) -> float32_280<24,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_280<24,11,32>\u001b[0m, 1, int64_279<24,5,32>\u001b[0m) -> float32_281<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 564\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 285 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mGraphPool[AASIST]\u001b[0m(float32_271<24,20,32>\u001b[0m) -> float32_290<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_271<24,20,32>\u001b[0m) -> float32_271<24,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_271<24,20,32>\u001b[0m, 0.3, False, False) -> float32_271<24,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_271<24,20,32>\u001b[0m) -> float32_284<24,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_271<24,20,32>\u001b[0m, float32_282<1,32>\u001b[0m, float32_283<1>\u001b[0m) -> float32_284<24,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32mSigmoid[torch.nn.modules.activation]\u001b[0m(float32_284<24,20,1>\u001b[0m) -> float32_285<24,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1msigmoid[torch]\u001b[0m(float32_284<24,20,1>\u001b[0m) -> float32_285<24,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtopk[torch]\u001b[0m(float32_285<24,20,1>\u001b[0m, 10, dim=1) -> (\u001b[90mfloat32_286<24,10,1>\u001b[0m, int64_287<24,10,1>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(int64_287<24,10,1>\u001b[0m, -1, -1, 32) -> int64_288<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_271<24,20,32>\u001b[0m, float32_285<24,20,1>\u001b[0m) -> float32_289<24,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_271<24,20,32>\u001b[0m, float32_285<24,20,1>\u001b[0m) -> float32_289<24,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_289<24,20,32>\u001b[0m, 1, int64_288<24,10,32>\u001b[0m) -> float32_290<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 566\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 113 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mHtrgGraphAttentionLayer[AASIST]\u001b[0m(float32_290<24,10,32>\u001b[0m, float32_281<24,5,32>\u001b[0m, master=float32_254<24,1,32>\u001b[0m) -> (float32_357<24,10,32>\u001b[0m, float32_358<24,5,32>\u001b[0m, float32_340<24,1,32>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_290<24,10,32>\u001b[0m) -> float32_293<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_290<24,10,32>\u001b[0m, float32_291<32,32>\u001b[0m, float32_292<32>\u001b[0m) -> float32_293<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_281<24,5,32>\u001b[0m) -> float32_296<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_281<24,5,32>\u001b[0m, float32_294<32,32>\u001b[0m, float32_295<32>\u001b[0m) -> float32_296<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_293<24,10,32>\u001b[0m, float32_296<24,5,32>\u001b[0m], dim=1) -> float32_297<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_297<24,15,32>\u001b[0m) -> float32_297<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_297<24,15,32>\u001b[0m, 0.2, False, False) -> float32_297<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_297<24,15,32>\u001b[0m, 2) -> float32_298<24,15,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(float32_298<24,15,1,32>\u001b[0m, -1, -1, 15, -1) -> float32_299<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_299<24,15,15,32>\u001b[0m, 1, 2) -> float32_300<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_299<24,15,15,32>\u001b[0m, float32_300<24,15,15,32>\u001b[0m) -> float32_301<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_299<24,15,15,32>\u001b[0m, float32_300<24,15,15,32>\u001b[0m) -> float32_301<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_301<24,15,15,32>\u001b[0m) -> float32_304<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_301<24,15,15,32>\u001b[0m, float32_302<32,32>\u001b[0m, float32_303<32>\u001b[0m) -> float32_304<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtanh[torch]\u001b[0m(float32_304<24,15,15,32>\u001b[0m) -> float32_305<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_305<24,15,15,32>\u001b[0m, (:, :, :, 0)) -> float32_306<24,15,15>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mzeros_like[torch]\u001b[0m(float32_306<24,15,15>\u001b[0m) -> float32_307<24,15,15>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_307<24,15,15>\u001b[0m, -1) -> float32_308<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_305<24,15,15,32>\u001b[0m, (:, :10, :10, :)) -> float32_309<24,10,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_309<24,10,10,32>\u001b[0m, \u001b[4mfloat32_310<32,1>\u001b[0m) -> float32_311<24,10,10,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_308<24,15,15,1>\u001b[0m, (:, :10, :10, :), float32_311<24,10,10,1>\u001b[0m) -> float32_308<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_305<24,15,15,32>\u001b[0m, (:, 10:, 10:, :)) -> float32_312<24,5,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_312<24,5,5,32>\u001b[0m, \u001b[4mfloat32_313<32,1>\u001b[0m) -> float32_314<24,5,5,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_308<24,15,15,1>\u001b[0m, (:, 10:, 10:, :), float32_314<24,5,5,1>\u001b[0m) -> float32_308<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_305<24,15,15,32>\u001b[0m, (:, :10, 10:, :)) -> float32_315<24,10,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_315<24,10,5,32>\u001b[0m, \u001b[4mfloat32_316<32,1>\u001b[0m) -> float32_317<24,10,5,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_308<24,15,15,1>\u001b[0m, (:, :10, 10:, :), float32_317<24,10,5,1>\u001b[0m) -> float32_308<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_305<24,15,15,32>\u001b[0m, (:, 10:, :10, :)) -> float32_318<24,5,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_318<24,5,10,32>\u001b[0m, \u001b[4mfloat32_316<32,1>\u001b[0m) -> float32_319<24,5,10,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_308<24,15,15,1>\u001b[0m, (:, 10:, :10, :), float32_319<24,5,10,1>\u001b[0m) -> float32_308<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_308<24,15,15,1>\u001b[0m, 100.0) -> float32_320<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdiv[TensorBase]\u001b[0m(float32_308<24,15,15,1>\u001b[0m, 100.0) -> float32_320<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_320<24,15,15,1>\u001b[0m, dim=-2) -> float32_321<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_320<24,15,15,1>\u001b[0m, -2) -> float32_321<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_297<24,15,32>\u001b[0m, float32_254<24,1,32>\u001b[0m) -> float32_322<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_297<24,15,32>\u001b[0m, float32_254<24,1,32>\u001b[0m) -> float32_322<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_322<24,15,32>\u001b[0m) -> float32_325<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_322<24,15,32>\u001b[0m, float32_323<32,32>\u001b[0m, float32_324<32>\u001b[0m) -> float32_325<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtanh[torch]\u001b[0m(float32_325<24,15,32>\u001b[0m) -> float32_326<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_326<24,15,32>\u001b[0m, \u001b[4mfloat32_327<32,1>\u001b[0m) -> float32_328<24,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_328<24,15,1>\u001b[0m, 100.0) -> float32_329<24,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdiv[TensorBase]\u001b[0m(float32_328<24,15,1>\u001b[0m, 100.0) -> float32_329<24,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_329<24,15,1>\u001b[0m, dim=-2) -> float32_330<24,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_329<24,15,1>\u001b[0m, -2) -> float32_330<24,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msqueeze[torch.Tensor]\u001b[0m(float32_330<24,15,1>\u001b[0m, -1) -> float32_331<24,15>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_331<24,15>\u001b[0m, 1) -> float32_332<24,1,15>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_332<24,1,15>\u001b[0m, float32_297<24,15,32>\u001b[0m) -> float32_333<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_333<24,1,32>\u001b[0m) -> float32_336<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_333<24,1,32>\u001b[0m, float32_334<32,32>\u001b[0m, float32_335<32>\u001b[0m) -> float32_336<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_254<24,1,32>\u001b[0m) -> float32_339<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_254<24,1,32>\u001b[0m, float32_337<32,32>\u001b[0m, float32_338<32>\u001b[0m) -> float32_339<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_336<24,1,32>\u001b[0m, float32_339<24,1,32>\u001b[0m) -> float32_340<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_336<24,1,32>\u001b[0m, float32_339<24,1,32>\u001b[0m) -> float32_340<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msqueeze[torch.Tensor]\u001b[0m(float32_321<24,15,15,1>\u001b[0m, -1) -> float32_341<24,15,15>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_341<24,15,15>\u001b[0m, float32_297<24,15,32>\u001b[0m) -> float32_342<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_342<24,15,32>\u001b[0m) -> float32_345<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_342<24,15,32>\u001b[0m, float32_343<32,32>\u001b[0m, float32_344<32>\u001b[0m) -> float32_345<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_297<24,15,32>\u001b[0m) -> float32_348<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_297<24,15,32>\u001b[0m, float32_346<32,32>\u001b[0m, float32_347<32>\u001b[0m) -> float32_348<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_345<24,15,32>\u001b[0m, float32_348<24,15,32>\u001b[0m) -> float32_349<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_345<24,15,32>\u001b[0m, float32_348<24,15,32>\u001b[0m) -> float32_349<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_349<24,15,32>\u001b[0m, -1, 32) -> float32_350<360,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_350<360,32>\u001b[0m) -> float32_355<360,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_350<360,32>\u001b[0m, float32_351<32>\u001b[0m, float32_352<32>\u001b[0m, float32_353<32>\u001b[0m, float32_354<32>\u001b[0m, False, 0.1, 1e-05) -> float32_355<360,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_350<360,32>\u001b[0m, float32_353<32>\u001b[0m, float32_354<32>\u001b[0m, float32_351<32>\u001b[0m, float32_352<32>\u001b[0m, False, 0.1, 1e-05, True) -> float32_355<360,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_355<360,32>\u001b[0m, Size(24, 15, 32)) -> float32_356<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 180\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_356<24,15,32>\u001b[0m) -> float32_356<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_356<24,15,32>\u001b[0m, True) -> float32_356<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_356<24,15,32>\u001b[0m) -> float32_356<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32m\u001b[1mnarrow[torch.Tensor]\u001b[0m(float32_356<24,15,32>\u001b[0m, 1, 0, 10) -> float32_357<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m └·\u001b[0m \u001b[32m\u001b[1mnarrow[torch.Tensor]\u001b[0m(float32_356<24,15,32>\u001b[0m, 1, 10, 5) -> float32_358<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_290<24,10,32>\u001b[0m, float32_357<24,10,32>\u001b[0m) -> float32_359<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_290<24,10,32>\u001b[0m, float32_357<24,10,32>\u001b[0m) -> float32_359<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_281<24,5,32>\u001b[0m, float32_358<24,5,32>\u001b[0m) -> float32_360<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_281<24,5,32>\u001b[0m, float32_358<24,5,32>\u001b[0m) -> float32_360<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_254<24,1,32>\u001b[0m, float32_340<24,1,32>\u001b[0m) -> float32_361<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_254<24,1,32>\u001b[0m, float32_340<24,1,32>\u001b[0m) -> float32_361<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 573\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 113 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mHtrgGraphAttentionLayer[AASIST]\u001b[0m(float32_200<24,20,64>\u001b[0m, float32_159<24,11,64>\u001b[0m, master=\u001b[4mfloat32_203<1,1,64>\u001b[0m) -> (float32_428<24,20,32>\u001b[0m, float32_429<24,11,32>\u001b[0m, float32_411<24,1,32>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_200<24,20,64>\u001b[0m) -> float32_364<24,20,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_200<24,20,64>\u001b[0m, float32_362<64,64>\u001b[0m, float32_363<64>\u001b[0m) -> float32_364<24,20,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_159<24,11,64>\u001b[0m) -> float32_367<24,11,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_159<24,11,64>\u001b[0m, float32_365<64,64>\u001b[0m, float32_366<64>\u001b[0m) -> float32_367<24,11,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_364<24,20,64>\u001b[0m, float32_367<24,11,64>\u001b[0m], dim=1) -> float32_368<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_368<24,31,64>\u001b[0m) -> float32_368<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_368<24,31,64>\u001b[0m, 0.2, False, False) -> float32_368<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_368<24,31,64>\u001b[0m, 2) -> float32_369<24,31,1,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(float32_369<24,31,1,64>\u001b[0m, -1, -1, 31, -1) -> float32_370<24,31,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_370<24,31,31,64>\u001b[0m, 1, 2) -> float32_371<24,31,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_370<24,31,31,64>\u001b[0m, float32_371<24,31,31,64>\u001b[0m) -> float32_372<24,31,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_370<24,31,31,64>\u001b[0m, float32_371<24,31,31,64>\u001b[0m) -> float32_372<24,31,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_372<24,31,31,64>\u001b[0m) -> float32_375<24,31,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_372<24,31,31,64>\u001b[0m, float32_373<32,64>\u001b[0m, float32_374<32>\u001b[0m) -> float32_375<24,31,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtanh[torch]\u001b[0m(float32_375<24,31,31,32>\u001b[0m) -> float32_376<24,31,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_376<24,31,31,32>\u001b[0m, (:, :, :, 0)) -> float32_377<24,31,31>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mzeros_like[torch]\u001b[0m(float32_377<24,31,31>\u001b[0m) -> float32_378<24,31,31>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_378<24,31,31>\u001b[0m, -1) -> float32_379<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_376<24,31,31,32>\u001b[0m, (:, :20, :20, :)) -> float32_380<24,20,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_380<24,20,20,32>\u001b[0m, \u001b[4mfloat32_381<32,1>\u001b[0m) -> float32_382<24,20,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_379<24,31,31,1>\u001b[0m, (:, :20, :20, :), float32_382<24,20,20,1>\u001b[0m) -> float32_379<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_376<24,31,31,32>\u001b[0m, (:, 20:, 20:, :)) -> float32_383<24,11,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_383<24,11,11,32>\u001b[0m, \u001b[4mfloat32_384<32,1>\u001b[0m) -> float32_385<24,11,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_379<24,31,31,1>\u001b[0m, (:, 20:, 20:, :), float32_385<24,11,11,1>\u001b[0m) -> float32_379<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_376<24,31,31,32>\u001b[0m, (:, :20, 20:, :)) -> float32_386<24,20,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_386<24,20,11,32>\u001b[0m, \u001b[4mfloat32_387<32,1>\u001b[0m) -> float32_388<24,20,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_379<24,31,31,1>\u001b[0m, (:, :20, 20:, :), float32_388<24,20,11,1>\u001b[0m) -> float32_379<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_376<24,31,31,32>\u001b[0m, (:, 20:, :20, :)) -> float32_389<24,11,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_389<24,11,20,32>\u001b[0m, \u001b[4mfloat32_387<32,1>\u001b[0m) -> float32_390<24,11,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_379<24,31,31,1>\u001b[0m, (:, 20:, :20, :), float32_390<24,11,20,1>\u001b[0m) -> float32_379<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_379<24,31,31,1>\u001b[0m, 100.0) -> float32_391<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdiv[TensorBase]\u001b[0m(float32_379<24,31,31,1>\u001b[0m, 100.0) -> float32_391<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_391<24,31,31,1>\u001b[0m, dim=-2) -> float32_392<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_391<24,31,31,1>\u001b[0m, -2) -> float32_392<24,31,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_368<24,31,64>\u001b[0m, float32_203<1,1,64>\u001b[0m) -> float32_393<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_368<24,31,64>\u001b[0m, float32_203<1,1,64>\u001b[0m) -> float32_393<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_393<24,31,64>\u001b[0m) -> float32_396<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_393<24,31,64>\u001b[0m, float32_394<32,64>\u001b[0m, float32_395<32>\u001b[0m) -> float32_396<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtanh[torch]\u001b[0m(float32_396<24,31,32>\u001b[0m) -> float32_397<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_397<24,31,32>\u001b[0m, \u001b[4mfloat32_398<32,1>\u001b[0m) -> float32_399<24,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_399<24,31,1>\u001b[0m, 100.0) -> float32_400<24,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdiv[TensorBase]\u001b[0m(float32_399<24,31,1>\u001b[0m, 100.0) -> float32_400<24,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_400<24,31,1>\u001b[0m, dim=-2) -> float32_401<24,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_400<24,31,1>\u001b[0m, -2) -> float32_401<24,31,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msqueeze[torch.Tensor]\u001b[0m(float32_401<24,31,1>\u001b[0m, -1) -> float32_402<24,31>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_402<24,31>\u001b[0m, 1) -> float32_403<24,1,31>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_403<24,1,31>\u001b[0m, float32_368<24,31,64>\u001b[0m) -> float32_404<24,1,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_404<24,1,64>\u001b[0m) -> float32_407<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_404<24,1,64>\u001b[0m, float32_405<32,64>\u001b[0m, float32_406<32>\u001b[0m) -> float32_407<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_203<1,1,64>\u001b[0m) -> float32_410<1,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_203<1,1,64>\u001b[0m, float32_408<32,64>\u001b[0m, float32_409<32>\u001b[0m) -> float32_410<1,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_407<24,1,32>\u001b[0m, float32_410<1,1,32>\u001b[0m) -> float32_411<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_407<24,1,32>\u001b[0m, float32_410<1,1,32>\u001b[0m) -> float32_411<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msqueeze[torch.Tensor]\u001b[0m(float32_392<24,31,31,1>\u001b[0m, -1) -> float32_412<24,31,31>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_412<24,31,31>\u001b[0m, float32_368<24,31,64>\u001b[0m) -> float32_413<24,31,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_413<24,31,64>\u001b[0m) -> float32_416<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_413<24,31,64>\u001b[0m, float32_414<32,64>\u001b[0m, float32_415<32>\u001b[0m) -> float32_416<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_368<24,31,64>\u001b[0m) -> float32_419<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_368<24,31,64>\u001b[0m, float32_417<32,64>\u001b[0m, float32_418<32>\u001b[0m) -> float32_419<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_416<24,31,32>\u001b[0m, float32_419<24,31,32>\u001b[0m) -> float32_420<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_416<24,31,32>\u001b[0m, float32_419<24,31,32>\u001b[0m) -> float32_420<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_420<24,31,32>\u001b[0m, -1, 32) -> float32_421<744,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_421<744,32>\u001b[0m) -> float32_426<744,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_421<744,32>\u001b[0m, float32_422<32>\u001b[0m, float32_423<32>\u001b[0m, float32_424<32>\u001b[0m, float32_425<32>\u001b[0m, False, 0.1, 1e-05) -> float32_426<744,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_421<744,32>\u001b[0m, float32_424<32>\u001b[0m, float32_425<32>\u001b[0m, float32_422<32>\u001b[0m, float32_423<32>\u001b[0m, False, 0.1, 1e-05, True) -> float32_426<744,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_426<744,32>\u001b[0m, Size(24, 31, 32)) -> float32_427<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 180\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_427<24,31,32>\u001b[0m) -> float32_427<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_427<24,31,32>\u001b[0m, True) -> float32_427<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_427<24,31,32>\u001b[0m) -> float32_427<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32m\u001b[1mnarrow[torch.Tensor]\u001b[0m(float32_427<24,31,32>\u001b[0m, 1, 0, 20) -> float32_428<24,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m └·\u001b[0m \u001b[32m\u001b[1mnarrow[torch.Tensor]\u001b[0m(float32_427<24,31,32>\u001b[0m, 1, 20, 11) -> float32_429<24,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 575\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 285 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mGraphPool[AASIST]\u001b[0m(float32_429<24,11,32>\u001b[0m) -> float32_438<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_429<24,11,32>\u001b[0m) -> float32_429<24,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_429<24,11,32>\u001b[0m, 0.3, False, False) -> float32_429<24,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_429<24,11,32>\u001b[0m) -> float32_432<24,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_429<24,11,32>\u001b[0m, float32_430<1,32>\u001b[0m, float32_431<1>\u001b[0m) -> float32_432<24,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32mSigmoid[torch.nn.modules.activation]\u001b[0m(float32_432<24,11,1>\u001b[0m) -> float32_433<24,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1msigmoid[torch]\u001b[0m(float32_432<24,11,1>\u001b[0m) -> float32_433<24,11,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtopk[torch]\u001b[0m(float32_433<24,11,1>\u001b[0m, 5, dim=1) -> (\u001b[90mfloat32_434<24,5,1>\u001b[0m, int64_435<24,5,1>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(int64_435<24,5,1>\u001b[0m, -1, -1, 32) -> int64_436<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_429<24,11,32>\u001b[0m, float32_433<24,11,1>\u001b[0m) -> float32_437<24,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_429<24,11,32>\u001b[0m, float32_433<24,11,1>\u001b[0m) -> float32_437<24,11,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_437<24,11,32>\u001b[0m, 1, int64_436<24,5,32>\u001b[0m) -> float32_438<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 576\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 285 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mGraphPool[AASIST]\u001b[0m(float32_428<24,20,32>\u001b[0m) -> float32_447<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_428<24,20,32>\u001b[0m) -> float32_428<24,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_428<24,20,32>\u001b[0m, 0.3, False, False) -> float32_428<24,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_428<24,20,32>\u001b[0m) -> float32_441<24,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_428<24,20,32>\u001b[0m, float32_439<1,32>\u001b[0m, float32_440<1>\u001b[0m) -> float32_441<24,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32mSigmoid[torch.nn.modules.activation]\u001b[0m(float32_441<24,20,1>\u001b[0m) -> float32_442<24,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1msigmoid[torch]\u001b[0m(float32_441<24,20,1>\u001b[0m) -> float32_442<24,20,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtopk[torch]\u001b[0m(float32_442<24,20,1>\u001b[0m, 10, dim=1) -> (\u001b[90mfloat32_443<24,10,1>\u001b[0m, int64_444<24,10,1>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(int64_444<24,10,1>\u001b[0m, -1, -1, 32) -> int64_445<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_428<24,20,32>\u001b[0m, float32_442<24,20,1>\u001b[0m) -> float32_446<24,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_428<24,20,32>\u001b[0m, float32_442<24,20,1>\u001b[0m) -> float32_446<24,20,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m └·\u001b[0m \u001b[32m\u001b[1mgather[torch]\u001b[0m(float32_446<24,20,32>\u001b[0m, 1, int64_445<24,10,32>\u001b[0m) -> float32_447<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 578\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 113 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mHtrgGraphAttentionLayer[AASIST]\u001b[0m(float32_447<24,10,32>\u001b[0m, float32_438<24,5,32>\u001b[0m, master=float32_411<24,1,32>\u001b[0m) -> (float32_514<24,10,32>\u001b[0m, float32_515<24,5,32>\u001b[0m, float32_497<24,1,32>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_447<24,10,32>\u001b[0m) -> float32_450<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_447<24,10,32>\u001b[0m, float32_448<32,32>\u001b[0m, float32_449<32>\u001b[0m) -> float32_450<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_438<24,5,32>\u001b[0m) -> float32_453<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_438<24,5,32>\u001b[0m, float32_451<32,32>\u001b[0m, float32_452<32>\u001b[0m) -> float32_453<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_450<24,10,32>\u001b[0m, float32_453<24,5,32>\u001b[0m], dim=1) -> float32_454<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_454<24,15,32>\u001b[0m) -> float32_454<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_454<24,15,32>\u001b[0m, 0.2, False, False) -> float32_454<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_454<24,15,32>\u001b[0m, 2) -> float32_455<24,15,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mexpand[torch.Tensor]\u001b[0m(float32_455<24,15,1,32>\u001b[0m, -1, -1, 15, -1) -> float32_456<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_456<24,15,15,32>\u001b[0m, 1, 2) -> float32_457<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_456<24,15,15,32>\u001b[0m, float32_457<24,15,15,32>\u001b[0m) -> float32_458<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_456<24,15,15,32>\u001b[0m, float32_457<24,15,15,32>\u001b[0m) -> float32_458<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_458<24,15,15,32>\u001b[0m) -> float32_461<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_458<24,15,15,32>\u001b[0m, float32_459<32,32>\u001b[0m, float32_460<32>\u001b[0m) -> float32_461<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtanh[torch]\u001b[0m(float32_461<24,15,15,32>\u001b[0m) -> float32_462<24,15,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_462<24,15,15,32>\u001b[0m, (:, :, :, 0)) -> float32_463<24,15,15>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mzeros_like[torch]\u001b[0m(float32_463<24,15,15>\u001b[0m) -> float32_464<24,15,15>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_464<24,15,15>\u001b[0m, -1) -> float32_465<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_462<24,15,15,32>\u001b[0m, (:, :10, :10, :)) -> float32_466<24,10,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_466<24,10,10,32>\u001b[0m, \u001b[4mfloat32_467<32,1>\u001b[0m) -> float32_468<24,10,10,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_465<24,15,15,1>\u001b[0m, (:, :10, :10, :), float32_468<24,10,10,1>\u001b[0m) -> float32_465<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_462<24,15,15,32>\u001b[0m, (:, 10:, 10:, :)) -> float32_469<24,5,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_469<24,5,5,32>\u001b[0m, \u001b[4mfloat32_470<32,1>\u001b[0m) -> float32_471<24,5,5,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_465<24,15,15,1>\u001b[0m, (:, 10:, 10:, :), float32_471<24,5,5,1>\u001b[0m) -> float32_465<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_462<24,15,15,32>\u001b[0m, (:, :10, 10:, :)) -> float32_472<24,10,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_472<24,10,5,32>\u001b[0m, \u001b[4mfloat32_473<32,1>\u001b[0m) -> float32_474<24,10,5,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_465<24,15,15,1>\u001b[0m, (:, :10, 10:, :), float32_474<24,10,5,1>\u001b[0m) -> float32_465<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_462<24,15,15,32>\u001b[0m, (:, 10:, :10, :)) -> float32_475<24,5,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_475<24,5,10,32>\u001b[0m, \u001b[4mfloat32_473<32,1>\u001b[0m) -> float32_476<24,5,10,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__setitem__[torch.Tensor]\u001b[0m(float32_465<24,15,15,1>\u001b[0m, (:, 10:, :10, :), float32_476<24,5,10,1>\u001b[0m) -> float32_465<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_465<24,15,15,1>\u001b[0m, 100.0) -> float32_477<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdiv[TensorBase]\u001b[0m(float32_465<24,15,15,1>\u001b[0m, 100.0) -> float32_477<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_477<24,15,15,1>\u001b[0m, dim=-2) -> float32_478<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_477<24,15,15,1>\u001b[0m, -2) -> float32_478<24,15,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_454<24,15,32>\u001b[0m, float32_411<24,1,32>\u001b[0m) -> float32_479<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_454<24,15,32>\u001b[0m, float32_411<24,1,32>\u001b[0m) -> float32_479<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_479<24,15,32>\u001b[0m) -> float32_482<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_479<24,15,32>\u001b[0m, float32_480<32,32>\u001b[0m, float32_481<32>\u001b[0m) -> float32_482<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mtanh[torch]\u001b[0m(float32_482<24,15,32>\u001b[0m) -> float32_483<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_483<24,15,32>\u001b[0m, \u001b[4mfloat32_484<32,1>\u001b[0m) -> float32_485<24,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__truediv__[torch.Tensor]\u001b[0m(float32_485<24,15,1>\u001b[0m, 100.0) -> float32_486<24,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdiv[TensorBase]\u001b[0m(float32_485<24,15,1>\u001b[0m, 100.0) -> float32_486<24,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_486<24,15,1>\u001b[0m, dim=-2) -> float32_487<24,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_486<24,15,1>\u001b[0m, -2) -> float32_487<24,15,1>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msqueeze[torch.Tensor]\u001b[0m(float32_487<24,15,1>\u001b[0m, -1) -> float32_488<24,15>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1munsqueeze[torch.Tensor]\u001b[0m(float32_488<24,15>\u001b[0m, 1) -> float32_489<24,1,15>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_489<24,1,15>\u001b[0m, float32_454<24,15,32>\u001b[0m) -> float32_490<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_490<24,1,32>\u001b[0m) -> float32_493<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_490<24,1,32>\u001b[0m, float32_491<32,32>\u001b[0m, float32_492<32>\u001b[0m) -> float32_493<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_411<24,1,32>\u001b[0m) -> float32_496<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_411<24,1,32>\u001b[0m, float32_494<32,32>\u001b[0m, float32_495<32>\u001b[0m) -> float32_496<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_493<24,1,32>\u001b[0m, float32_496<24,1,32>\u001b[0m) -> float32_497<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_493<24,1,32>\u001b[0m, float32_496<24,1,32>\u001b[0m) -> float32_497<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1msqueeze[torch.Tensor]\u001b[0m(float32_478<24,15,15,1>\u001b[0m, -1) -> float32_498<24,15,15>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmatmul[torch]\u001b[0m(float32_498<24,15,15>\u001b[0m, float32_454<24,15,32>\u001b[0m) -> float32_499<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_499<24,15,32>\u001b[0m) -> float32_502<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_499<24,15,32>\u001b[0m, float32_500<32,32>\u001b[0m, float32_501<32>\u001b[0m) -> float32_502<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_454<24,15,32>\u001b[0m) -> float32_505<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_454<24,15,32>\u001b[0m, float32_503<32,32>\u001b[0m, float32_504<32>\u001b[0m) -> float32_505<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_502<24,15,32>\u001b[0m, float32_505<24,15,32>\u001b[0m) -> float32_506<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_502<24,15,32>\u001b[0m, float32_505<24,15,32>\u001b[0m) -> float32_506<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_506<24,15,32>\u001b[0m, -1, 32) -> float32_507<360,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm1d[torch.nn.modules.batchnorm]\u001b[0m(float32_507<360,32>\u001b[0m) -> float32_512<360,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_507<360,32>\u001b[0m, float32_508<32>\u001b[0m, float32_509<32>\u001b[0m, float32_510<32>\u001b[0m, float32_511<32>\u001b[0m, False, 0.1, 1e-05) -> float32_512<360,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_507<360,32>\u001b[0m, float32_510<32>\u001b[0m, float32_511<32>\u001b[0m, float32_508<32>\u001b[0m, float32_509<32>\u001b[0m, False, 0.1, 1e-05, True) -> float32_512<360,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_512<360,32>\u001b[0m, Size(24, 15, 32)) -> float32_513<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 180\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_513<24,15,32>\u001b[0m) -> float32_513<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_513<24,15,32>\u001b[0m, True) -> float32_513<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_513<24,15,32>\u001b[0m) -> float32_513<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[32m\u001b[1mnarrow[torch.Tensor]\u001b[0m(float32_513<24,15,32>\u001b[0m, 1, 0, 10) -> float32_514<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m └·\u001b[0m \u001b[32m\u001b[1mnarrow[torch.Tensor]\u001b[0m(float32_513<24,15,32>\u001b[0m, 1, 10, 5) -> float32_515<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_447<24,10,32>\u001b[0m, float32_514<24,10,32>\u001b[0m) -> float32_516<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_447<24,10,32>\u001b[0m, float32_514<24,10,32>\u001b[0m) -> float32_516<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_438<24,5,32>\u001b[0m, float32_515<24,5,32>\u001b[0m) -> float32_517<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_438<24,5,32>\u001b[0m, float32_515<24,5,32>\u001b[0m) -> float32_517<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_411<24,1,32>\u001b[0m, float32_497<24,1,32>\u001b[0m) -> float32_518<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[TensorBase]\u001b[0m(float32_411<24,1,32>\u001b[0m, float32_497<24,1,32>\u001b[0m) -> float32_518<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_359<24,10,32>\u001b[0m) -> float32_359<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_359<24,10,32>\u001b[0m, 0.2, False, True) -> float32_359<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m*Dropout[torch.nn.modules.dropout]\u001b[0m(float32_516<24,10,32>\u001b[0m) -> float32_516<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m*Dropout[torch.nn.modules.dropout]\u001b[0m(float32_360<24,5,32>\u001b[0m) -> float32_360<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m*Dropout[torch.nn.modules.dropout]\u001b[0m(float32_517<24,5,32>\u001b[0m) -> float32_517<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m*Dropout[torch.nn.modules.dropout]\u001b[0m(float32_361<24,1,32>\u001b[0m) -> float32_361<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m*Dropout[torch.nn.modules.dropout]\u001b[0m(float32_518<24,1,32>\u001b[0m) -> float32_518<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmax[torch]\u001b[0m(float32_359<24,10,32>\u001b[0m, float32_516<24,10,32>\u001b[0m) -> float32_519<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmax[torch]\u001b[0m(float32_360<24,5,32>\u001b[0m, float32_517<24,5,32>\u001b[0m) -> float32_520<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmax[torch]\u001b[0m(float32_361<24,1,32>\u001b[0m, float32_518<24,1,32>\u001b[0m) -> float32_521<24,1,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mabs[torch]\u001b[0m(float32_519<24,10,32>\u001b[0m) -> float32_522<24,10,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmax[torch]\u001b[0m(float32_522<24,10,32>\u001b[0m, dim=1) -> (float32_523<24,32>\u001b[0m, \u001b[90mint64_524<24,32>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmean[torch]\u001b[0m(float32_519<24,10,32>\u001b[0m, dim=1) -> float32_525<24,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mabs[torch]\u001b[0m(float32_520<24,5,32>\u001b[0m) -> float32_526<24,5,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmax[torch]\u001b[0m(float32_526<24,5,32>\u001b[0m, dim=1) -> (float32_527<24,32>\u001b[0m, \u001b[90mint64_528<24,32>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mmean[torch]\u001b[0m(float32_520<24,5,32>\u001b[0m, dim=1) -> float32_529<24,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1msqueeze[torch.Tensor]\u001b[0m(float32_521<24,1,32>\u001b[0m, 1) -> float32_530<24,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_523<24,32>\u001b[0m, float32_525<24,32>\u001b[0m, float32_527<24,32>\u001b[0m, float32_529<24,32>\u001b[0m, float32_530<24,32>\u001b[0m], dim=1) -> float32_531<24,160>\u001b[0m\n",
            "\u001b[31m ├·\u001b[0m \u001b[32m\u001b[1mDropout[torch.nn.modules.dropout]\u001b[0m(float32_531<24,160>\u001b[0m) -> float32_531<24,160>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mdropout[torch.nn.functional]\u001b[0m(float32_531<24,160>\u001b[0m, 0.5, False, True) -> float32_531<24,160>\u001b[0m\n",
            "\u001b[31m ├·\u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_531<24,160>\u001b[0m) -> float32_534<24,2>\u001b[0m\n",
            "\u001b[31m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_531<24,160>\u001b[0m, float32_532<2,160>\u001b[0m, float32_533<2>\u001b[0m) -> float32_534<24,2>\u001b[0m\n",
            "\n",
            "Unimplemented nodes:\n",
            "\u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/nobuco/trace/trace.py\", line 471\u001b[0m \n",
            "\u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 469 \u001b[0m \n",
            "\u001b[31mModel[AASIST]\u001b[0m(float32_0<24,64600>\u001b[0m) -> (float32_47<24,160>\u001b[0m, float32_48<24,2>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 535\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_1<24,1,23,21490>\u001b[0m) -> float32_1<24,1,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_1<24,1,23,21490>\u001b[0m, True) -> float32_1<24,1,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_1<24,1,23,21490>\u001b[0m) -> float32_1<24,1,23,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 539\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_1<24,1,23,21490>\u001b[0m) -> float32_18<24,64,23,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_1<24,1,23,21490>\u001b[0m) -> float32_3<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_1<24,1,23,21490>\u001b[0m) -> float32_3<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_2<24,32,24,21490>\u001b[0m) -> float32_2<24,32,24,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_2<24,32,24,21490>\u001b[0m, True) -> float32_2<24,32,24,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_2<24,32,24,21490>\u001b[0m) -> float32_2<24,32,24,21490>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_3<24,32,23,7163>\u001b[0m) -> float32_6<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_3<24,32,23,7163>\u001b[0m) -> float32_6<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 450\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_4<24,32,23,7163>\u001b[0m) -> \u001b[90mfloat32_4<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_4<24,32,23,7163>\u001b[0m, True) -> float32_4<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_4<24,32,23,7163>\u001b[0m) -> float32_4<24,32,23,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_5<24,32,24,7163>\u001b[0m) -> float32_5<24,32,24,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_5<24,32,24,7163>\u001b[0m, True) -> float32_5<24,32,24,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_5<24,32,24,7163>\u001b[0m) -> float32_5<24,32,24,7163>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_6<24,32,23,2387>\u001b[0m) -> float32_9<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_6<24,32,23,2387>\u001b[0m) -> float32_9<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 450\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_7<24,32,23,2387>\u001b[0m) -> \u001b[90mfloat32_7<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_7<24,32,23,2387>\u001b[0m, True) -> float32_7<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_7<24,32,23,2387>\u001b[0m) -> float32_7<24,32,23,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_8<24,64,24,2387>\u001b[0m) -> float32_8<24,64,24,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_8<24,64,24,2387>\u001b[0m, True) -> float32_8<24,64,24,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_8<24,64,24,2387>\u001b[0m) -> float32_8<24,64,24,2387>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_9<24,64,23,795>\u001b[0m) -> float32_12<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_9<24,64,23,795>\u001b[0m) -> float32_12<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 450\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_10<24,64,23,795>\u001b[0m) -> \u001b[90mfloat32_10<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_10<24,64,23,795>\u001b[0m, True) -> float32_10<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_10<24,64,23,795>\u001b[0m) -> float32_10<24,64,23,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_11<24,64,24,795>\u001b[0m) -> float32_11<24,64,24,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_11<24,64,24,795>\u001b[0m, True) -> float32_11<24,64,24,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_11<24,64,24,795>\u001b[0m) -> float32_11<24,64,24,795>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_12<24,64,23,265>\u001b[0m) -> float32_15<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_12<24,64,23,265>\u001b[0m) -> float32_15<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 450\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_13<24,64,23,265>\u001b[0m) -> \u001b[90mfloat32_13<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_13<24,64,23,265>\u001b[0m, True) -> float32_13<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_13<24,64,23,265>\u001b[0m) -> float32_13<24,64,23,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_14<24,64,24,265>\u001b[0m) -> float32_14<24,64,24,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_14<24,64,24,265>\u001b[0m, True) -> float32_14<24,64,24,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_14<24,64,24,265>\u001b[0m) -> float32_14<24,64,24,265>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 64 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mSequential[torch.nn.modules.container]\u001b[0m(float32_15<24,64,23,88>\u001b[0m) -> float32_18<24,64,23,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 413 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mResidual_block[AASIST]\u001b[0m(float32_15<24,64,23,88>\u001b[0m) -> float32_18<24,64,23,29>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 450\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_16<24,64,23,88>\u001b[0m) -> \u001b[90mfloat32_16<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_16<24,64,23,88>\u001b[0m, True) -> float32_16<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_16<24,64,23,88>\u001b[0m) -> float32_16<24,64,23,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 457\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_17<24,64,24,88>\u001b[0m) -> float32_17<24,64,24,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_17<24,64,24,88>\u001b[0m, True) -> float32_17<24,64,24,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_17<24,64,24,88>\u001b[0m) -> float32_17<24,64,24,88>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 545\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 17 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mGraphAttentionLayer[AASIST]\u001b[0m(float32_19<24,23,64>\u001b[0m) -> float32_20<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 58\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_20<24,23,64>\u001b[0m) -> float32_20<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_20<24,23,64>\u001b[0m, True) -> float32_20<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_20<24,23,64>\u001b[0m) -> float32_20<24,23,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 552\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 17 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mGraphAttentionLayer[AASIST]\u001b[0m(float32_21<24,29,64>\u001b[0m) -> float32_22<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 58\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_22<24,29,64>\u001b[0m) -> float32_22<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_22<24,29,64>\u001b[0m, True) -> float32_22<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_22<24,29,64>\u001b[0m) -> float32_22<24,29,64>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 560\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 113 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mHtrgGraphAttentionLayer[AASIST]\u001b[0m(float32_23<24,20,64>\u001b[0m, float32_24<24,11,64>\u001b[0m, master=\u001b[4mfloat32_25<1,1,64>\u001b[0m) -> (float32_27<24,20,32>\u001b[0m, float32_28<24,11,32>\u001b[0m, float32_29<24,1,32>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 180\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_26<24,31,32>\u001b[0m) -> float32_26<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_26<24,31,32>\u001b[0m, True) -> float32_26<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_26<24,31,32>\u001b[0m) -> float32_26<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 566\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 113 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mHtrgGraphAttentionLayer[AASIST]\u001b[0m(float32_30<24,10,32>\u001b[0m, float32_31<24,5,32>\u001b[0m, master=float32_29<24,1,32>\u001b[0m) -> (float32_33<24,10,32>\u001b[0m, float32_34<24,5,32>\u001b[0m, float32_35<24,1,32>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 180\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_32<24,15,32>\u001b[0m) -> float32_32<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_32<24,15,32>\u001b[0m, True) -> float32_32<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_32<24,15,32>\u001b[0m) -> float32_32<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 573\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 113 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mHtrgGraphAttentionLayer[AASIST]\u001b[0m(float32_23<24,20,64>\u001b[0m, float32_24<24,11,64>\u001b[0m, master=\u001b[4mfloat32_36<1,1,64>\u001b[0m) -> (float32_38<24,20,32>\u001b[0m, float32_39<24,11,32>\u001b[0m, float32_40<24,1,32>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 180\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_37<24,31,32>\u001b[0m) -> float32_37<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_37<24,31,32>\u001b[0m, True) -> float32_37<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_37<24,31,32>\u001b[0m) -> float32_37<24,31,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 578\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 113 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31mHtrgGraphAttentionLayer[AASIST]\u001b[0m(float32_41<24,10,32>\u001b[0m, float32_42<24,5,32>\u001b[0m, master=float32_40<24,1,32>\u001b[0m) -> (float32_44<24,10,32>\u001b[0m, float32_45<24,5,32>\u001b[0m, float32_46<24,1,32>\u001b[0m)\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/content/aasist/models/AASIST.py\", line 180\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 613 \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31mSELU[torch.nn.modules.activation]\u001b[0m(float32_43<24,15,32>\u001b[0m) -> float32_43<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 656\u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m ├·\u001b[0m \u001b[31mselu[torch.nn.functional]\u001b[0m(float32_43<24,15,32>\u001b[0m, True) -> float32_43<24,15,32>\u001b[0m\n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
            "\u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[31m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/usr/local/lib/python3.11/dist-packages/torch/overrides.py\", line 1742\u001b[0m \n",
            "\u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └ \u001b[0m \u001b[31m └·\u001b[0m \u001b[31m\u001b[7mselu_[torch]\u001b[0m(float32_43<24,15,32>\u001b[0m) -> float32_43<24,15,32>\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Unimplemented nodes",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-653319680.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# 3. Export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m keras_model = nobuco.pytorch_to_keras(\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mpytorch_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nobuco/convert.py\u001b[0m in \u001b[0;36mpytorch_to_keras\u001b[0;34m(model, args, kwargs, input_shapes, inputs_channel_order, outputs_channel_order, input_names, output_names, trace_shape, enable_torch_tracing, constants_to_variables, full_validation, validation_tolerance, return_outputs_pt, save_trace_html, debug_traces)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unimplemented nodes:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munimplemented_hierarchy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mvis_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unimplemented nodes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mkeras_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_converted_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Unimplemented nodes"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!ls /usr/local/cuda/lib64\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZivWriAdZr2",
        "outputId": "58ead904-a6f0-4b36-b756-3a027123cf8d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul 29 06:23:25 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0             41W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "cmake\t\t\t      libnppicc.so.12\n",
            "libaccinj64.so\t\t      libnppicc.so.12.3.0.159\n",
            "libaccinj64.so.12.5\t      libnppicc_static.a\n",
            "libaccinj64.so.12.5.82\t      libnppidei.so\n",
            "libcheckpoint.so\t      libnppidei.so.12\n",
            "libcublasLt.so\t\t      libnppidei.so.12.3.0.159\n",
            "libcublasLt.so.12\t      libnppidei_static.a\n",
            "libcublasLt.so.12.5.3.2       libnppif.so\n",
            "libcublasLt_static.a\t      libnppif.so.12\n",
            "libcublas.so\t\t      libnppif.so.12.3.0.159\n",
            "libcublas.so.12\t\t      libnppif_static.a\n",
            "libcublas.so.12.5.3.2\t      libnppig.so\n",
            "libcublas_static.a\t      libnppig.so.12\n",
            "libcudadevrt.a\t\t      libnppig.so.12.3.0.159\n",
            "libcudart.so\t\t      libnppig_static.a\n",
            "libcudart.so.12\t\t      libnppim.so\n",
            "libcudart.so.12.5.82\t      libnppim.so.12\n",
            "libcudart_static.a\t      libnppim.so.12.3.0.159\n",
            "libcufft.so\t\t      libnppim_static.a\n",
            "libcufft.so.11\t\t      libnppist.so\n",
            "libcufft.so.11.2.3.61\t      libnppist.so.12\n",
            "libcufft_static.a\t      libnppist.so.12.3.0.159\n",
            "libcufft_static_nocallback.a  libnppist_static.a\n",
            "libcufftw.so\t\t      libnppisu.so\n",
            "libcufftw.so.11\t\t      libnppisu.so.12\n",
            "libcufftw.so.11.2.3.61\t      libnppisu.so.12.3.0.159\n",
            "libcufftw_static.a\t      libnppisu_static.a\n",
            "libcufile_rdma.so\t      libnppitc.so\n",
            "libcufile_rdma.so.1\t      libnppitc.so.12\n",
            "libcufile_rdma.so.1.10.1      libnppitc.so.12.3.0.159\n",
            "libcufile_rdma_static.a       libnppitc_static.a\n",
            "libcufile.so\t\t      libnpps.so\n",
            "libcufile.so.0\t\t      libnpps.so.12\n",
            "libcufile.so.1.10.1\t      libnpps.so.12.3.0.159\n",
            "libcufile_static.a\t      libnpps_static.a\n",
            "libcufilt.a\t\t      libnvblas.so\n",
            "libcuinj64.so\t\t      libnvblas.so.12\n",
            "libcuinj64.so.12.5\t      libnvblas.so.12.5.3.2\n",
            "libcuinj64.so.12.5.82\t      libnvfatbin.so\n",
            "libculibos.a\t\t      libnvfatbin.so.12\n",
            "libcupti.so\t\t      libnvfatbin.so.12.5.82\n",
            "libcupti.so.12\t\t      libnvfatbin_static.a\n",
            "libcupti.so.2024.2.1\t      libnvJitLink.so\n",
            "libcupti_static.a\t      libnvJitLink.so.12\n",
            "libcurand.so\t\t      libnvJitLink.so.12.5.82\n",
            "libcurand.so.10\t\t      libnvJitLink_static.a\n",
            "libcurand.so.10.3.6.82\t      libnvjpeg.so\n",
            "libcurand_static.a\t      libnvjpeg.so.12\n",
            "libcusolver_lapack_static.a   libnvjpeg.so.12.3.2.81\n",
            "libcusolver_metis_static.a    libnvjpeg_static.a\n",
            "libcusolverMg.so\t      libnvperf_host.so\n",
            "libcusolverMg.so.11\t      libnvperf_host_static.a\n",
            "libcusolverMg.so.11.6.3.83    libnvperf_target.so\n",
            "libcusolver.so\t\t      libnvptxcompiler_static.a\n",
            "libcusolver.so.11\t      libnvrtc-builtins.so\n",
            "libcusolver.so.11.6.3.83      libnvrtc-builtins.so.12.5\n",
            "libcusolver_static.a\t      libnvrtc-builtins.so.12.5.82\n",
            "libcusparse.so\t\t      libnvrtc-builtins_static.a\n",
            "libcusparse.so.12\t      libnvrtc.so\n",
            "libcusparse.so.12.5.1.3       libnvrtc.so.12\n",
            "libcusparse_static.a\t      libnvrtc.so.12.5.82\n",
            "libmetis_static.a\t      libnvrtc_static.a\n",
            "libnppc.so\t\t      libnvToolsExt.so\n",
            "libnppc.so.12\t\t      libnvToolsExt.so.1\n",
            "libnppc.so.12.3.0.159\t      libnvToolsExt.so.1.0.0\n",
            "libnppc_static.a\t      libOpenCL.so\n",
            "libnppial.so\t\t      libOpenCL.so.1\n",
            "libnppial.so.12\t\t      libOpenCL.so.1.0\n",
            "libnppial.so.12.3.0.159       libOpenCL.so.1.0.0\n",
            "libnppial_static.a\t      libpcsamplingutil.so\n",
            "libnppicc.so\t\t      stubs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update && apt install -y nvidia-driver-550 nvidia-cuda-toolkit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vDC2OWRdovN",
        "outputId": "d469409d-2c3d-4ff5-ea68-a744bd149cad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,152 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,269 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,255 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,160 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,508 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,574 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,772 kB]\n",
            "Fetched 27.1 MB in 4s (6,244 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "43 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  dkms fakeroot fonts-dejavu-core fonts-dejavu-extra keyboard-configuration\n",
            "  libaccinj64-11.5 libatk-wrapper-java libatk-wrapper-java-jni libbabeltrace1\n",
            "  libcub-dev libcublas11 libcublaslt11 libcudart11.0 libcufft10 libcufftw10\n",
            "  libcuinj64-11.5 libcupti-dev libcupti-doc libcupti11.5 libcurand10\n",
            "  libcusolver11 libcusolvermg11 libcusparse11 libdebuginfod-common\n",
            "  libdebuginfod1 libegl-dev libfakeroot libgail-common libgail18 libgl-dev\n",
            "  libgl1-mesa-dev libgles-dev libgles1 libglvnd-core-dev libglvnd-dev\n",
            "  libglx-dev libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libipt2 libjansson4\n",
            "  liblocale-gettext-perl libnppc11 libnppial11 libnppicc11 libnppidei11\n",
            "  libnppif11 libnppig11 libnppim11 libnppist11 libnppisu11 libnppitc11\n",
            "  libnpps11 libnvblas11 libnvidia-cfg1-550 libnvidia-common-550\n",
            "  libnvidia-compute-550 libnvidia-decode-550 libnvidia-encode-550\n",
            "  libnvidia-extra-550 libnvidia-fbc1-550 libnvidia-gl-550 libnvidia-ml-dev\n",
            "  libnvjpeg11 libnvrtc-builtins11.5 libnvrtc11.2 libnvtoolsext1 libnvvm4\n",
            "  libopengl-dev librsvg2-common libsource-highlight-common\n",
            "  libsource-highlight4v5 libthrust-dev libudev1 libvdpau-dev libxcvt0 libxtst6\n",
            "  libxxf86dga1 node-html5shiv nvidia-compute-utils-550 nvidia-cuda-dev\n",
            "  nvidia-cuda-gdb nvidia-cuda-toolkit-doc nvidia-dkms-550\n",
            "  nvidia-firmware-550-550.163.01 nvidia-kernel-common-550\n",
            "  nvidia-kernel-source-550 nvidia-prime nvidia-profiler nvidia-settings\n",
            "  nvidia-utils-550 nvidia-visual-profiler openjdk-8-jre openjdk-8-jre-headless\n",
            "  python3-xkit screen-resolution-extra systemd-hwe-hwdb udev x11-utils xcvt\n",
            "  xserver-xorg-core xserver-xorg-video-nvidia-550\n",
            "Suggested packages:\n",
            "  menu gvfs libvdpau-doc nodejs libnss-mdns fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "  mesa-utils xfonts-100dpi | xfonts-75dpi xfonts-scalable\n",
            "Recommended packages:\n",
            "  libnvcuvid1 nsight-compute nsight-systems libnvidia-compute-550:i386\n",
            "  libnvidia-decode-550:i386 libnvidia-encode-550:i386 libnvidia-fbc1-550:i386\n",
            "  libnvidia-gl-550:i386\n",
            "The following NEW packages will be installed:\n",
            "  dkms fakeroot fonts-dejavu-core fonts-dejavu-extra keyboard-configuration\n",
            "  libaccinj64-11.5 libatk-wrapper-java libatk-wrapper-java-jni libbabeltrace1\n",
            "  libcub-dev libcublas11 libcublaslt11 libcudart11.0 libcufft10 libcufftw10\n",
            "  libcuinj64-11.5 libcupti-dev libcupti-doc libcupti11.5 libcurand10\n",
            "  libcusolver11 libcusolvermg11 libcusparse11 libdebuginfod-common\n",
            "  libdebuginfod1 libegl-dev libfakeroot libgail-common libgail18 libgl-dev\n",
            "  libgl1-mesa-dev libgles-dev libgles1 libglvnd-core-dev libglvnd-dev\n",
            "  libglx-dev libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libipt2 libjansson4\n",
            "  liblocale-gettext-perl libnppc11 libnppial11 libnppicc11 libnppidei11\n",
            "  libnppif11 libnppig11 libnppim11 libnppist11 libnppisu11 libnppitc11\n",
            "  libnpps11 libnvblas11 libnvidia-cfg1-550 libnvidia-common-550\n",
            "  libnvidia-compute-550 libnvidia-decode-550 libnvidia-encode-550\n",
            "  libnvidia-extra-550 libnvidia-fbc1-550 libnvidia-gl-550 libnvidia-ml-dev\n",
            "  libnvjpeg11 libnvrtc-builtins11.5 libnvrtc11.2 libnvtoolsext1 libnvvm4\n",
            "  libopengl-dev librsvg2-common libsource-highlight-common\n",
            "  libsource-highlight4v5 libthrust-dev libvdpau-dev libxcvt0 libxtst6\n",
            "  libxxf86dga1 node-html5shiv nvidia-compute-utils-550 nvidia-cuda-dev\n",
            "  nvidia-cuda-gdb nvidia-cuda-toolkit nvidia-cuda-toolkit-doc nvidia-dkms-550\n",
            "  nvidia-driver-550 nvidia-firmware-550-550.163.01 nvidia-kernel-common-550\n",
            "  nvidia-kernel-source-550 nvidia-prime nvidia-profiler nvidia-settings\n",
            "  nvidia-utils-550 nvidia-visual-profiler openjdk-8-jre openjdk-8-jre-headless\n",
            "  python3-xkit screen-resolution-extra systemd-hwe-hwdb udev x11-utils xcvt\n",
            "  xserver-xorg-core xserver-xorg-video-nvidia-550\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 103 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 1,776 MB of archives.\n",
            "After this operation, 4,796 MB of additional disk space will be used.\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 openjdk-8-jre-headless amd64 8u462-ga~us1-0ubuntu2~22.04.2 [30.8 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblocale-gettext-perl amd64 1.07-4build3 [17.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 keyboard-configuration all 1.205ubuntu3 [206 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdebuginfod-common all 0.186-1ubuntu0.1 [7,996 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.16 [76.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.16 [1,557 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  dkms 1:3.2.1-1ubuntu2 [53.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjansson4 amd64 2.13.1-1.1build3 [32.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfakeroot amd64 1.28-1ubuntu1 [31.5 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 fakeroot amd64 1.28-1ubuntu1 [60.4 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcupti11.5 amd64 11.5.114~11.5.1-1ubuntu1 [7,696 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libaccinj64-11.5 amd64 11.5.114~11.5.1-1ubuntu1 [845 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 openjdk-8-jre amd64 8u462-ga~us1-0ubuntu2~22.04.2 [75.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcub-dev all 1.15.0-3 [217 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcublaslt11 amd64 11.7.4.6~11.5.1-1ubuntu1 [148 MB]\n",
            "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-compute-550 550.163.01-0ubuntu1 [49.5 MB]\n",
            "Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-cfg1-550 550.163.01-0ubuntu1 [144 kB]\n",
            "Get:25 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-common-550 550.163.01-0ubuntu1 [15.6 kB]\n",
            "Get:26 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-decode-550 550.163.01-0ubuntu1 [1,787 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcublas11 amd64 11.7.4.6~11.5.1-1ubuntu1 [78.2 MB]\n",
            "Get:28 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-encode-550 550.163.01-0ubuntu1 [98.9 kB]\n",
            "Get:29 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-extra-550 550.163.01-0ubuntu1 [69.7 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcudart11.0 amd64 11.5.117~11.5.1-1ubuntu1 [178 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcufft10 amd64 11.1.1+~10.6.0.107~11.5.1-1ubuntu1 [70.4 MB]\n",
            "Get:32 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-fbc1-550 550.163.01-0ubuntu1 [53.5 kB]\n",
            "Get:33 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-gl-550 550.163.01-0ubuntu1 [136 MB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcufftw10 amd64 11.1.1+~10.6.0.107~11.5.1-1ubuntu1 [211 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcuinj64-11.5 amd64 11.5.114~11.5.1-1ubuntu1 [1,004 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcurand10 amd64 11.1.1+~10.2.7.107~11.5.1-1ubuntu1 [41.8 MB]\n",
            "Get:37 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-compute-utils-550 550.163.01-0ubuntu1 [116 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcusolver11 amd64 11.3.2.107~11.5.1-1ubuntu1 [31.3 MB]\n",
            "Get:39 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-source-550 550.163.01-0ubuntu1 [41.3 MB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcusolvermg11 amd64 11.3.2.107~11.5.1-1ubuntu1 [17.8 MB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcusparse11 amd64 11.7.0.107~11.5.1-1ubuntu1 [96.2 MB]\n",
            "Get:42 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-firmware-550-550.163.01 550.163.01-0ubuntu1 [37.0 MB]\n",
            "Get:43 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-common-550 550.163.01-0ubuntu1 [107 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdebuginfod1 amd64 0.186-1ubuntu0.1 [12.8 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:52 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-dkms-550 550.163.01-0ubuntu1 [34.7 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/main amd64 libipt2 amd64 2.0.5-1 [46.4 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppc11 amd64 11.5.1.107~11.5.1-1ubuntu1 [430 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppial11 amd64 11.5.1.107~11.5.1-1ubuntu1 [5,234 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppicc11 amd64 11.5.1.107~11.5.1-1ubuntu1 [2,373 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppidei11 amd64 11.5.1.107~11.5.1-1ubuntu1 [2,587 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppif11 amd64 11.5.1.107~11.5.1-1ubuntu1 [33.8 MB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppig11 amd64 11.5.1.107~11.5.1-1ubuntu1 [14.5 MB]\n",
            "Get:63 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-utils-550 550.163.01-0ubuntu1 [493 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppim11 amd64 11.5.1.107~11.5.1-1ubuntu1 [3,037 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppist11 amd64 11.5.1.107~11.5.1-1ubuntu1 [13.7 MB]\n",
            "Get:66 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  xserver-xorg-video-nvidia-550 550.163.01-0ubuntu1 [1,533 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppisu11 amd64 11.5.1.107~11.5.1-1ubuntu1 [177 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppitc11 amd64 11.5.1.107~11.5.1-1ubuntu1 [1,292 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnpps11 amd64 11.5.1.107~11.5.1-1ubuntu1 [7,116 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvblas11 amd64 11.7.4.6~11.5.1-1ubuntu1 [191 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvidia-ml-dev amd64 11.5.50~11.5.1-1ubuntu1 [69.1 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvjpeg11 amd64 11.5.4.107~11.5.1-1ubuntu1 [1,858 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvrtc-builtins11.5 amd64 11.5.119~11.5.1-1ubuntu1 [116 kB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvrtc11.2 amd64 11.5.119~11.5.1-1ubuntu1 [15.7 MB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvvm4 amd64 11.5.119~11.5.1-1ubuntu1 [8,675 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight-common all 3.1.9-4.1build2 [64.5 kB]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight4v5 amd64 3.1.9-4.1build2 [207 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvdpau-dev amd64 1.4-3build2 [38.7 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcvt0 amd64 0.1.1-3 [5,494 B]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-html5shiv all 3.7.3+dfsg-4 [13.6 kB]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-cuda-toolkit-doc all 11.5.1-1ubuntu1 [6,263 kB]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-xorg-core amd64 2:21.1.4-2ubuntu1.7~22.04.15 [1,477 kB]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu jammy/main amd64 nvidia-prime all 0.8.17.1 [9,956 B]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-xkit all 0.5.0ubuntu5 [18.5 kB]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu jammy/main amd64 screen-resolution-extra all 0.18.2 [4,396 B]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu jammy/main amd64 xcvt amd64 0.1.1-3 [7,140 B]\n",
            "Get:90 http://archive.ubuntu.com/ubuntu jammy/main amd64 libbabeltrace1 amd64 1.5.8-2build1 [160 kB]\n",
            "Get:91 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcupti-dev amd64 11.5.114~11.5.1-1ubuntu1 [7,915 kB]\n",
            "Get:92 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcupti-doc all 11.5.114~11.5.1-1ubuntu1 [2,373 kB]\n",
            "Get:93 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:94 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:95 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.3 [6,848 B]\n",
            "Get:96 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvtoolsext1 amd64 11.5.114~11.5.1-1ubuntu1 [28.8 kB]\n",
            "Get:97 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libthrust-dev all 1.15.0-1 [423 kB]\n",
            "Get:98 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-cuda-dev amd64 11.5.1-1ubuntu1 [667 MB]\n",
            "Get:99 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-driver-550 550.163.01-0ubuntu1 [490 kB]\n",
            "Get:100 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-settings 575.57.08-0ubuntu1 [960 kB]\n",
            "Get:101 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-cuda-gdb amd64 11.5.114~11.5.1-1ubuntu1 [3,404 kB]\n",
            "Get:102 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-profiler amd64 11.5.114~11.5.1-1ubuntu1 [1,732 kB]\n",
            "Get:103 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-cuda-toolkit amd64 11.5.1-1ubuntu1 [62.8 MB]\n",
            "Get:104 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-visual-profiler amd64 11.5.114~11.5.1-1ubuntu1 [108 MB]\n",
            "Fetched 1,776 MB in 1min 20s (22.1 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package liblocale-gettext-perl.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../liblocale-gettext-perl_1.07-4build3_amd64.deb ...\n",
            "Unpacking liblocale-gettext-perl (1.07-4build3) ...\n",
            "Selecting previously unselected package keyboard-configuration.\n",
            "Preparing to unpack .../keyboard-configuration_1.205ubuntu3_all.deb ...\n",
            "Unpacking keyboard-configuration (1.205ubuntu3) ...\n",
            "Selecting previously unselected package dkms.\n",
            "Preparing to unpack .../dkms_1%3a3.2.1-1ubuntu2_all.deb ...\n",
            "Unpacking dkms (1:3.2.1-1ubuntu2) ...\n",
            "Selecting previously unselected package libdebuginfod-common.\n",
            "Preparing to unpack .../libdebuginfod-common_0.186-1ubuntu0.1_all.deb ...\n",
            "Unpacking libdebuginfod-common (0.186-1ubuntu0.1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.16_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.16) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 126352 files and directories currently installed.)\n",
            "Preparing to unpack .../00-udev_249.11-0ubuntu3.16_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.16) ...\n",
            "Selecting previously unselected package libjansson4:amd64.\n",
            "Preparing to unpack .../01-libjansson4_2.13.1-1.1build3_amd64.deb ...\n",
            "Unpacking libjansson4:amd64 (2.13.1-1.1build3) ...\n",
            "Selecting previously unselected package libfakeroot:amd64.\n",
            "Preparing to unpack .../02-libfakeroot_1.28-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
            "Selecting previously unselected package fakeroot.\n",
            "Preparing to unpack .../03-fakeroot_1.28-1ubuntu1_amd64.deb ...\n",
            "Unpacking fakeroot (1.28-1ubuntu1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../04-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../05-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libcupti11.5:amd64.\n",
            "Preparing to unpack .../06-libcupti11.5_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcupti11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libaccinj64-11.5:amd64.\n",
            "Preparing to unpack .../07-libaccinj64-11.5_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libaccinj64-11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../08-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../09-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../10-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../11-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../12-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libcub-dev.\n",
            "Preparing to unpack .../13-libcub-dev_1.15.0-3_all.deb ...\n",
            "Unpacking libcub-dev (1.15.0-3) ...\n",
            "Selecting previously unselected package libcublaslt11:amd64.\n",
            "Preparing to unpack .../14-libcublaslt11_11.7.4.6~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcublaslt11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcublas11:amd64.\n",
            "Preparing to unpack .../15-libcublas11_11.7.4.6~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcublas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcudart11.0:amd64.\n",
            "Preparing to unpack .../16-libcudart11.0_11.5.117~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcudart11.0:amd64 (11.5.117~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcufft10:amd64.\n",
            "Preparing to unpack .../17-libcufft10_11.1.1+~10.6.0.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcufft10:amd64 (11.1.1+~10.6.0.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcufftw10:amd64.\n",
            "Preparing to unpack .../18-libcufftw10_11.1.1+~10.6.0.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcufftw10:amd64 (11.1.1+~10.6.0.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-compute-550:amd64.\n",
            "Preparing to unpack .../19-libnvidia-compute-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-compute-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package libcuinj64-11.5:amd64.\n",
            "Preparing to unpack .../20-libcuinj64-11.5_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcuinj64-11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcurand10:amd64.\n",
            "Preparing to unpack .../21-libcurand10_11.1.1+~10.2.7.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcurand10:amd64 (11.1.1+~10.2.7.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcusolver11:amd64.\n",
            "Preparing to unpack .../22-libcusolver11_11.3.2.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcusolver11:amd64 (11.3.2.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcusolvermg11:amd64.\n",
            "Preparing to unpack .../23-libcusolvermg11_11.3.2.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcusolvermg11:amd64 (11.3.2.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcusparse11:amd64.\n",
            "Preparing to unpack .../24-libcusparse11_11.7.0.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcusparse11:amd64 (11.7.0.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libdebuginfod1:amd64.\n",
            "Preparing to unpack .../25-libdebuginfod1_0.186-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libdebuginfod1:amd64 (0.186-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../26-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../27-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../28-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../29-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../30-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../31-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../32-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../33-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../34-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../35-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libipt2.\n",
            "Preparing to unpack .../36-libipt2_2.0.5-1_amd64.deb ...\n",
            "Unpacking libipt2 (2.0.5-1) ...\n",
            "Selecting previously unselected package libnppc11:amd64.\n",
            "Preparing to unpack .../37-libnppc11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppial11:amd64.\n",
            "Preparing to unpack .../38-libnppial11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppial11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppicc11:amd64.\n",
            "Preparing to unpack .../39-libnppicc11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppicc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppidei11:amd64.\n",
            "Preparing to unpack .../40-libnppidei11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppidei11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppif11:amd64.\n",
            "Preparing to unpack .../41-libnppif11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppif11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppig11:amd64.\n",
            "Preparing to unpack .../42-libnppig11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppig11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppim11:amd64.\n",
            "Preparing to unpack .../43-libnppim11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppim11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppist11:amd64.\n",
            "Preparing to unpack .../44-libnppist11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppist11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppisu11:amd64.\n",
            "Preparing to unpack .../45-libnppisu11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppisu11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppitc11:amd64.\n",
            "Preparing to unpack .../46-libnppitc11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppitc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnpps11:amd64.\n",
            "Preparing to unpack .../47-libnpps11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnpps11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvblas11:amd64.\n",
            "Preparing to unpack .../48-libnvblas11_11.7.4.6~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvblas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-cfg1-550:amd64.\n",
            "Preparing to unpack .../49-libnvidia-cfg1-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-cfg1-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-common-550.\n",
            "Preparing to unpack .../50-libnvidia-common-550_550.163.01-0ubuntu1_all.deb ...\n",
            "Unpacking libnvidia-common-550 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-decode-550:amd64.\n",
            "Preparing to unpack .../51-libnvidia-decode-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-decode-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-encode-550:amd64.\n",
            "Preparing to unpack .../52-libnvidia-encode-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-encode-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-extra-550:amd64.\n",
            "Preparing to unpack .../53-libnvidia-extra-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-extra-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-fbc1-550:amd64.\n",
            "Preparing to unpack .../54-libnvidia-fbc1-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-fbc1-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-gl-550:amd64.\n",
            "Preparing to unpack .../55-libnvidia-gl-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "\u001b[1mdpkg-query:\u001b[0m no packages found matching libnvidia-gl-535\n",
            "Unpacking libnvidia-gl-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-ml-dev:amd64.\n",
            "Preparing to unpack .../56-libnvidia-ml-dev_11.5.50~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-ml-dev:amd64 (11.5.50~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvjpeg11:amd64.\n",
            "Preparing to unpack .../57-libnvjpeg11_11.5.4.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvjpeg11:amd64 (11.5.4.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvrtc-builtins11.5:amd64.\n",
            "Preparing to unpack .../58-libnvrtc-builtins11.5_11.5.119~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvrtc-builtins11.5:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvrtc11.2:amd64.\n",
            "Preparing to unpack .../59-libnvrtc11.2_11.5.119~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvrtc11.2:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvvm4:amd64.\n",
            "Preparing to unpack .../60-libnvvm4_11.5.119~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvvm4:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../61-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../62-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libsource-highlight-common.\n",
            "Preparing to unpack .../63-libsource-highlight-common_3.1.9-4.1build2_all.deb ...\n",
            "Unpacking libsource-highlight-common (3.1.9-4.1build2) ...\n",
            "Selecting previously unselected package libsource-highlight4v5.\n",
            "Preparing to unpack .../64-libsource-highlight4v5_3.1.9-4.1build2_amd64.deb ...\n",
            "Unpacking libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
            "Selecting previously unselected package libvdpau-dev:amd64.\n",
            "Preparing to unpack .../65-libvdpau-dev_1.4-3build2_amd64.deb ...\n",
            "Unpacking libvdpau-dev:amd64 (1.4-3build2) ...\n",
            "Selecting previously unselected package libxcvt0:amd64.\n",
            "Preparing to unpack .../66-libxcvt0_0.1.1-3_amd64.deb ...\n",
            "Unpacking libxcvt0:amd64 (0.1.1-3) ...\n",
            "Selecting previously unselected package node-html5shiv.\n",
            "Preparing to unpack .../67-node-html5shiv_3.7.3+dfsg-4_all.deb ...\n",
            "Unpacking node-html5shiv (3.7.3+dfsg-4) ...\n",
            "Selecting previously unselected package nvidia-compute-utils-550.\n",
            "Preparing to unpack .../68-nvidia-compute-utils-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-compute-utils-550 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-cuda-toolkit-doc.\n",
            "Preparing to unpack .../69-nvidia-cuda-toolkit-doc_11.5.1-1ubuntu1_all.deb ...\n",
            "Unpacking nvidia-cuda-toolkit-doc (11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-kernel-source-550.\n",
            "Preparing to unpack .../70-nvidia-kernel-source-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-kernel-source-550 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-firmware-550-550.163.01.\n",
            "Preparing to unpack .../71-nvidia-firmware-550-550.163.01_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-firmware-550-550.163.01 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-kernel-common-550.\n",
            "Preparing to unpack .../72-nvidia-kernel-common-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-kernel-common-550 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-dkms-550.\n",
            "Preparing to unpack .../73-nvidia-dkms-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-dkms-550 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-utils-550.\n",
            "Preparing to unpack .../74-nvidia-utils-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-utils-550 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package xserver-xorg-core.\n",
            "Preparing to unpack .../75-xserver-xorg-core_2%3a21.1.4-2ubuntu1.7~22.04.15_amd64.deb ...\n",
            "Unpacking xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.15) ...\n",
            "Selecting previously unselected package xserver-xorg-video-nvidia-550.\n",
            "Preparing to unpack .../76-xserver-xorg-video-nvidia-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking xserver-xorg-video-nvidia-550 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-driver-550.\n",
            "Preparing to unpack .../77-nvidia-driver-550_550.163.01-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-driver-550 (550.163.01-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-prime.\n",
            "Preparing to unpack .../78-nvidia-prime_0.8.17.1_all.deb ...\n",
            "Unpacking nvidia-prime (0.8.17.1) ...\n",
            "Selecting previously unselected package python3-xkit.\n",
            "Preparing to unpack .../79-python3-xkit_0.5.0ubuntu5_all.deb ...\n",
            "Unpacking python3-xkit (0.5.0ubuntu5) ...\n",
            "Selecting previously unselected package screen-resolution-extra.\n",
            "Preparing to unpack .../80-screen-resolution-extra_0.18.2_all.deb ...\n",
            "Unpacking screen-resolution-extra (0.18.2) ...\n",
            "Selecting previously unselected package nvidia-settings.\n",
            "Preparing to unpack .../81-nvidia-settings_575.57.08-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-settings (575.57.08-0ubuntu1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../82-openjdk-8-jre-headless_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../83-openjdk-8-jre_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../84-systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Selecting previously unselected package xcvt.\n",
            "Preparing to unpack .../85-xcvt_0.1.1-3_amd64.deb ...\n",
            "Unpacking xcvt (0.1.1-3) ...\n",
            "Selecting previously unselected package libbabeltrace1:amd64.\n",
            "Preparing to unpack .../86-libbabeltrace1_1.5.8-2build1_amd64.deb ...\n",
            "Unpacking libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
            "Selecting previously unselected package libcupti-dev:amd64.\n",
            "Preparing to unpack .../87-libcupti-dev_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcupti-dev:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcupti-doc.\n",
            "Preparing to unpack .../88-libcupti-doc_11.5.114~11.5.1-1ubuntu1_all.deb ...\n",
            "Unpacking libcupti-doc (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../89-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../90-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../91-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Selecting previously unselected package libnvtoolsext1:amd64.\n",
            "Preparing to unpack .../92-libnvtoolsext1_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvtoolsext1:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libthrust-dev.\n",
            "Preparing to unpack .../93-libthrust-dev_1.15.0-1_all.deb ...\n",
            "Unpacking libthrust-dev (1.15.0-1) ...\n",
            "Selecting previously unselected package nvidia-cuda-dev:amd64.\n",
            "Preparing to unpack .../94-nvidia-cuda-dev_11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-cuda-dev:amd64 (11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-cuda-gdb.\n",
            "Preparing to unpack .../95-nvidia-cuda-gdb_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-cuda-gdb (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-profiler.\n",
            "Preparing to unpack .../96-nvidia-profiler_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-profiler (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-cuda-toolkit.\n",
            "Preparing to unpack .../97-nvidia-cuda-toolkit_11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-cuda-toolkit (11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-visual-profiler.\n",
            "Preparing to unpack .../98-nvidia-visual-profiler_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-visual-profiler (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libcusparse11:amd64 (11.7.0.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libdebuginfod-common (0.186-1ubuntu0.1) ...\n",
            "\n",
            "Creating config file /etc/profile.d/debuginfod.sh with new version\n",
            "\n",
            "Creating config file /etc/profile.d/debuginfod.csh with new version\n",
            "Setting up libnvidia-compute-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Setting up nvidia-prime (0.8.17.1) ...\n",
            "Setting up libnppc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libnvidia-common-550 (550.163.01-0ubuntu1) ...\n",
            "Setting up libdebuginfod1:amd64 (0.186-1ubuntu0.1) ...\n",
            "Setting up node-html5shiv (3.7.3+dfsg-4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libcupti-doc (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up nvidia-utils-550 (550.163.01-0ubuntu1) ...\n",
            "Setting up libnvidia-fbc1-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Setting up libnvidia-cfg1-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Setting up nvidia-compute-utils-550 (550.163.01-0ubuntu1) ...\n",
            "Warning: The home dir /nonexistent you specified can't be accessed: No such file or directory\n",
            "Adding system user `nvidia-persistenced' (UID 104) ...\n",
            "Adding new group `nvidia-persistenced' (GID 107) ...\n",
            "Adding new user `nvidia-persistenced' (UID 104) with group `nvidia-persistenced' ...\n",
            "Not creating home directory `/nonexistent'.\n",
            "Setting up libsource-highlight-common (3.1.9-4.1build2) ...\n",
            "Setting up libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
            "Setting up libcudart11.0:amd64 (11.5.117~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppisu11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libjansson4:amd64 (2.13.1-1.1build3) ...\n",
            "Setting up dkms (1:3.2.1-1ubuntu2) ...\n",
            "Setting up libnppicc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up fakeroot (1.28-1ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n",
            "Setting up libnvjpeg11:amd64 (11.5.4.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libcublaslt11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up libcupti11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up udev (249.11-0ubuntu3.16) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libipt2 (2.0.5-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
            "Setting up libnpps11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppim11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up libcufft10:amd64 (11.1.1+~10.6.0.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnvidia-gl-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libnppitc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppist11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnvidia-extra-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Setting up libxcvt0:amd64 (0.1.1-3) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up nvidia-kernel-source-550 (550.163.01-0ubuntu1) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libnvvm4:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Setting up libvdpau-dev:amd64 (1.4-3build2) ...\n",
            "Setting up libnvtoolsext1:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libcub-dev (1.15.0-3) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up nvidia-cuda-toolkit-doc (11.5.1-1ubuntu1) ...\n",
            "Setting up python3-xkit (0.5.0ubuntu5) ...\n",
            "Setting up libaccinj64-11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppig11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up liblocale-gettext-perl (1.07-4build3) ...\n",
            "Setting up libcurand10:amd64 (11.1.1+~10.2.7.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
            "Setting up libnvrtc-builtins11.5:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Setting up nvidia-firmware-550-550.163.01 (550.163.01-0ubuntu1) ...\n",
            "Setting up libnppidei11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libthrust-dev (1.15.0-1) ...\n",
            "Setting up libnppial11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppif11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libcuinj64-11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libcufftw10:amd64 (11.1.1+~10.6.0.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libcublas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Setting up libnvidia-ml-dev:amd64 (11.5.50~11.5.1-1ubuntu1) ...\n",
            "Setting up nvidia-cuda-gdb (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libnvidia-decode-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libcupti-dev:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libnvidia-encode-550:amd64 (550.163.01-0ubuntu1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up nvidia-profiler (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up xcvt (0.1.1-3) ...\n",
            "Setting up libnvblas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Setting up libcusolver11:amd64 (11.3.2.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnvrtc11.2:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Setting up libcusolvermg11:amd64 (11.3.2.107~11.5.1-1ubuntu1) ...\n",
            "Setting up screen-resolution-extra (0.18.2) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up nvidia-kernel-common-550 (550.163.01-0ubuntu1) ...\n",
            "Created symlink /etc/systemd/system/systemd-hibernate.service.wants/nvidia-hibernate.service → /lib/systemd/system/nvidia-hibernate.service.\n",
            "Created symlink /etc/systemd/system/systemd-suspend.service.wants/nvidia-resume.service → /lib/systemd/system/nvidia-resume.service.\n",
            "Created symlink /etc/systemd/system/systemd-hibernate.service.wants/nvidia-resume.service → /lib/systemd/system/nvidia-resume.service.\n",
            "Created symlink /etc/systemd/system/systemd-suspend.service.wants/nvidia-suspend.service → /lib/systemd/system/nvidia-suspend.service.\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up nvidia-settings (575.57.08-0ubuntu1) ...\n",
            "Setting up keyboard-configuration (1.205ubuntu3) ...\n",
            "Your console font configuration will be updated the next time your system\n",
            "boots. If you want to update it now, run 'setupcon' from a virtual console.\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up nvidia-cuda-dev:amd64 (11.5.1-1ubuntu1) ...\n",
            "Setting up xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.15) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up nvidia-dkms-550 (550.163.01-0ubuntu1) ...\n",
            "Loading new nvidia/550.163.01 DKMS files...\n",
            "Deprecated feature: CLEAN (/usr/src/nvidia-550.163.01/dkms.conf)\n",
            "Building for 5.15.0-144-generic\n",
            "Building for architecture x86_64\n",
            "\n",
            "Building initial module nvidia/550.163.01 for 5.15.0-144-generic\n",
            "Deprecated feature: CLEAN (/var/lib/dkms/nvidia/550.163.01/source/dkms.conf)\n",
            "Sign command: /usr/src/linux-headers-5.15.0-144-generic/scripts/sign-file\n",
            "Binary update-secureboot-policy not found, modules won't be signed\n",
            "\n",
            "Building module(s)................... done.\n",
            "Deprecated feature: CLEAN (/var/lib/dkms/nvidia/550.163.01/source/dkms.conf)\n",
            "Installing /lib/modules/5.15.0-144-generic/updates/dkms/nvidia.ko\n",
            "Installing /lib/modules/5.15.0-144-generic/updates/dkms/nvidia-modeset.ko\n",
            "Installing /lib/modules/5.15.0-144-generic/updates/dkms/nvidia-drm.ko\n",
            "Installing /lib/modules/5.15.0-144-generic/updates/dkms/nvidia-uvm.ko\n",
            "Installing /lib/modules/5.15.0-144-generic/updates/dkms/nvidia-peermem.ko\n",
            "Running depmod... done.\n",
            "Setting up openjdk-8-jre:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up nvidia-cuda-toolkit (11.5.1-1ubuntu1) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up xserver-xorg-video-nvidia-550 (550.163.01-0ubuntu1) ...\n",
            "Setting up nvidia-visual-profiler (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up nvidia-driver-550 (550.163.01-0ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ]
    }
  ]
}